{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8 Introduction to Deep Learning for Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter introduces convolutional neural networks, also known as convnets, the\n",
    " type of deep learning model that is now used almost universally in computer vision\n",
    " applications. You’ll learn to apply convnets to image-classification problems—in particular those involving small training datasets, which are the most common use case i \n",
    " you aren’t a large tech company"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Introduction to convnets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let’s take a practical look at a simple convnet example that classifies MNIST digits, a task we performed in chapter 2 using a\n",
    "densely connected network (our test accuracy then was 97.8%). Even though the\n",
    "convnet will be basic, its accuracy will blow our densely connected model from chapter 2 out of the water"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following listing shows what a basic convnet looks like. \n",
    "\n",
    "It’s a stack of Conv2D and MaxPooling2D layers. \n",
    "\n",
    "You’ll see in a minute exactly what they do. We’ll build the\n",
    "model using the Functional API, which we introduced in the previous chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28,28,1))\n",
    "\n",
    "x = layers.Conv2D(filters=32,kernel_size=3,activation='relu')(inputs)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64,kernel_size=3,activation='relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128,kernel_size=3,activation='relu')(x)\n",
    "x = layers.Flatten()(x)\n",
    "outputs = layers.Dense(10,activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs = inputs,outputs=outputs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importantly, a convnet takes as input tensors of shape __(image_height, image_width,\n",
    "image_channels)__, not including the batch dimension. \n",
    "\n",
    "In this case, we’ll configure the\n",
    "convnet to process inputs of size __(28, 28, 1)__, which is the format of MNIST images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing 8.2 Displaying the model’s summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 3, 3, 128)         73856     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1152)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                11530     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 104,202\n",
      "Trainable params: 104,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. You can see that the output of every Conv2D and MaxPooling2D layer is a rank-3 tensor\n",
    "of shape (height, width, channels). The width and height dimensions tend to\n",
    "shrink as you go deeper in the model. The number of channels is controlled by the\n",
    "first argument passed to the Conv2D layers (32, 64, or 128).\n",
    "\n",
    "\n",
    "2. After the last Conv2D layer, we end up with an output of shape (3, 3, 128)—a 3 × 3\n",
    "feature map of 128 channels. The next step is to feed this output into a densely connected classifier like those you’re already familiar with: a stack of Dense layers. These\n",
    "classifiers process vectors, which are 1D, whereas the current output is a rank-3 tensor.\n",
    "\n",
    "\n",
    "3. To bridge the gap, we flatten the 3D outputs to 1D with a Flatten layer before adding\n",
    "the Dense layers.\n",
    " \n",
    " \n",
    "4. Finally, we do 10-way classification, so our last layer has 10 outputs and a softmax\n",
    "activation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let’s train the convnet on the MNIST digits. We’ll reuse a lot of the code from\n",
    " the MNIST example in chapter 2. \n",
    " \n",
    "Because we’re doing 10-way classification with a\n",
    " softmax output, we’ll use the categorical crossentropy loss, and because our labels are\n",
    " integers, we’ll use the sparse version, sparse_categorical_crossentropy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing 8.3 Training the convnet on MNIST images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(train_images,train_labels),(test_images,test_labels) = mnist.load_data()\n",
    "train_images = train_images.reshape((60000,28,28,1))\n",
    "train_images = train_images.astype('float32')/255\n",
    "\n",
    "test_images = test_images.reshape((10000,28,28,1))\n",
    "test_images = test_images.astype('float32')/255\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 13s 8ms/step - loss: 0.1518 - accuracy: 0.9530\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.0431 - accuracy: 0.9866\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 7s 8ms/step - loss: 0.0296 - accuracy: 0.9910\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 8s 8ms/step - loss: 0.0226 - accuracy: 0.9930\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 8s 8ms/step - loss: 0.0173 - accuracy: 0.9949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17382379370>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.RMSprop(),\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(train_images,train_labels,epochs=5,batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the evaluation accuacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0258 - accuracy: 0.9916\n",
      "Test Accuracy: 0.991599977016449\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,test_labels)\n",
    "print(\"Test Accuracy: {}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.1 The convolution operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.11 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e450050b432e843bda3c41bf3272c133bfc370a7003f3e377e27f87a49ce1127"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
