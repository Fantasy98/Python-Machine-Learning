{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7 Working with Keras : A deep dive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 A spectrum of workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The design of the Keras API is guided by the principle of progressive disclosure of complexity:\n",
    "\n",
    "make it easy to get started, yet make it possible to handle high-complexity use\n",
    "cases, only requiring incremental learning at each step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As such, there’s not a single “true” way of using Keras. Rather, Keras offers a spectrum of workflows, from the very simple to the very flexible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Different ways to build Keras models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  The Sequential model, the most approachable API—it’s basically a Python list. As\n",
    "such, it’s limited to simple stacks of layers.\n",
    "\n",
    "\n",
    "2.  The Functional API, which focuses on graph-like model architectures. It represents a nice mid-point between usability and flexibility, and as such, it’s the\n",
    "most commonly used model-building API.\n",
    "\n",
    "\n",
    "3. Model subclassing, a low-level option where you write everything yourself from\n",
    "scratch. This is ideal if you want full control over every little thing. However, you\n",
    "won’t get access to many built-in Keras features, and you will be more at risk of\n",
    "making mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.1 The Sequential Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing 7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "                        layers.Dense(64,activation=\"relu\"),\n",
    "                        layers.Dense(10,activation='softmax')\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it is possible to build the same model via the __add()__ method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List 7.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(64,activation='relu'))\n",
    "model.add(layers.Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the shape of the layers' weights depends\n",
    "on the shape of their input: until the input shape is known, they can’t be created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List 7.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As such, the preceding Sequential model does not have any weights (listing 7.3)\n",
    " until you actually call it on some data, or call its build() method with an input shape\n",
    "\n",
    "\n",
    "Listing 7.4 Calling a model for the first time to build it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
       "array([-0.16043939,  0.16160363, -0.12016313, -0.1115216 , -0.02670726,\n",
       "        0.17006758, -0.1278942 , -0.2899389 ,  0.10332727, -0.23342204,\n",
       "       -0.20396397, -0.16928633,  0.00045142,  0.27283418,  0.20103699,\n",
       "        0.07552055,  0.11161286, -0.13714032, -0.0354377 ,  0.04568198,\n",
       "       -0.22649263, -0.02849546,  0.05666026, -0.05561247,  0.2342177 ,\n",
       "       -0.18396786,  0.04053369,  0.1253789 ,  0.15995851,  0.11520663,\n",
       "        0.16612884,  0.2893585 , -0.07179864,  0.15469593, -0.24424088,\n",
       "        0.16130462, -0.19766578, -0.05453105, -0.0060131 , -0.05307442,\n",
       "        0.2982496 , -0.17433208,  0.14090225,  0.09499717, -0.09303941,\n",
       "        0.14781198, -0.01072973,  0.2967198 , -0.07120231,  0.25733638,\n",
       "        0.2910149 ,  0.26713413,  0.26132244,  0.03009984, -0.04240042,\n",
       "        0.09819847, -0.08438461,  0.10523519, -0.08222805, -0.21194232,\n",
       "       -0.20960006,  0.00542068,  0.13717449, -0.20585375], dtype=float32)>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build(input_shape=(None,3))\n",
    "model.weights[0][0]\n",
    "## Builds the model . now the model will expect samples of shape(,3). \n",
    "## The None in the input shape signals that the batch size could be anything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the model has been builted , you can display its contents via __summary()__ method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing 7.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_38 (Dense)            (None, 64)                256       \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this model has a name of \"sequential_2\" You can give names to everything in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing 7.6 Naming models and layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"wyn_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " First_layer_wyn (Dense)     (None, 64)                256       \n",
      "                                                                 \n",
      " Second_layer_wyn (Dense)    (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= keras.Sequential(name=\"wyn_model\")\n",
    "model.add(layers.Dense(64,activation='relu',name = 'First_layer_wyn'))\n",
    "model.add(layers.Dense(10,activation='softmax',name = 'Second_layer_wyn'))\n",
    "\n",
    "model.build((None,3))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When building a Sequential model incrementally, it’s useful to be able to print a summary of what the current model looks like after you add each layer. \n",
    "\n",
    "But you can’t print a summary until the model is built! \n",
    "\n",
    "There’s actually a way to have your Sequential\n",
    "built on the fly: just declare the shape of the model’s inputs in advance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing 7.7 Specifying the input shape of your model in advance\n",
    "\n",
    "Use Input to declare the shape \n",
    "of the inputs. \n",
    "\n",
    "Note that the shape argument must be the \n",
    "shape of each sample, not  the shape of one batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_40 (Dense)            (None, 64)                256       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256\n",
      "Trainable params: 256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(3,)))\n",
    "model.add(layers.Dense(64,activation='relu'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_40 (Dense)            (None, 64)                256       \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Dense(10,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.2 The Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sequential model is easy to use, but its applicability is extremely limited: it can\n",
    "only express models with a single input and a single output, applying one layer after\n",
    "the other in a sequential fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In such cases, you’d build your model using the Functional API. This is what most\n",
    "Keras models you’ll encounter in the wild use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Simple Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stack of two layers we used. \n",
    "\n",
    "Its Functional API verison looks like following listing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing 7.8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,),name='my_input')\n",
    "\n",
    "features = layers.Dense(64,activation='relu')(inputs)\n",
    "\n",
    "outputs = layers.Dense(10,activation='softmax')(features)\n",
    "\n",
    "model = keras.Model(inputs= inputs,outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go it over step by step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We started by declaring an Input (note that you can also give names to these input\n",
    "objects, like everything else)\n",
    "\n",
    "The model will process batches where each sample \n",
    "has shape (3,). The number of samples per batch is \n",
    "variable (indicated by the None batch size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,),name='my_input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call such an object a symbolic tensor. \n",
    "\n",
    "It doesn’t contain any actual data, but it\n",
    "encodes the specifications of the actual tensors of data that the model will see when\n",
    "you use it. \n",
    "\n",
    "It stands for future tensors of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we created a layer and __called it on__ the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = layers.Dense(64, activation=\"relu\")(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All Keras layers can be called both on real tensors of data and on these symbolic tensors. In the latter case, they return a new symbolic tensor, with updated shape and\n",
    "dtype information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 64])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After obtaining the final outputs, we instantiated the model by specifying its inputs\n",
    "and outputs in the Model constructor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = layers.Dense(10,activation='softmax')(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = keras.Model(inputs= inputs,outputs = outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_input (InputLayer)       [(None, 3)]               0         \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 64)                256       \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "models.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MULTI-INPUT, MULTI-OUTPUT MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike this toy model, most deep learning models don’t look like lists—they look like\n",
    "graphs. They may, for instance, have multiple inputs or multiple outputs. It’s for this\n",
    "kind of model that the Functional API really shines.\n",
    "\n",
    "\n",
    "Let’s say you’re building a system to rank customer support tickets by priority and\n",
    "route them to the appropriate department. Your model has three inputs:\n",
    "1. The title of the ticket (text input)\n",
    "2. The text body of the ticket (text input)\n",
    "3. Any tags added by the user (categorical input, assumed here to be one-hot\n",
    "encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your model also has two outputs:\n",
    "1. The priority score of the ticket, a scalar between 0 and 1 (sigmoid output)\n",
    "2. The department that should handle the ticket (a softmax over the set of departments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing 7.9 A multi-input, multi-output Functional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " title (InputLayer)             [(None, 10000)]      0           []                               \n",
      "                                                                                                  \n",
      " text_body (InputLayer)         [(None, 10000)]      0           []                               \n",
      "                                                                                                  \n",
      " tags (InputLayer)              [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 20100)        0           ['title[0][0]',                  \n",
      "                                                                  'text_body[0][0]',              \n",
      "                                                                  'tags[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_46 (Dense)               (None, 64)           1286464     ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " priority (Dense)               (None, 1)            65          ['dense_46[0][0]']               \n",
      "                                                                                                  \n",
      " department (Dense)             (None, 4)            260         ['dense_46[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,286,789\n",
      "Trainable params: 1,286,789\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = 10000\n",
    "num_tags = 100\n",
    "num_departments = 4\n",
    "\n",
    "\n",
    "title = keras.Input(shape=(vocabulary_size,),name='title')\n",
    "text_body = keras.Input(shape=(vocabulary_size,),name='text_body')\n",
    "tags = keras.Input(shape=(num_tags,),name='tags')\n",
    "\n",
    "features = layers.Concatenate()([title,text_body,tags])\n",
    "features = layers.Dense(64,activation='relu')(features)\n",
    "\n",
    "priority = layers.Dense(1,activation='sigmoid',name='priority')(features)\n",
    "\n",
    "department = layers.Dense(num_departments,activation='softmax',name='department')(features)\n",
    "\n",
    "model = keras.Model(inputs=[title,text_body,tags],outputs=[priority,department])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing 7.10 Training a model by providing lists of input and target arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can train your model in much the same way as you would train a Sequential\n",
    " model, by calling fit() with __lists of input and output data__. \n",
    "\n",
    "\n",
    "These lists of data should\n",
    " be in __the same order__ as the inputs you passed to the Model constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 12ms/step - loss: 25.8086 - priority_loss: 0.0000e+00 - department_loss: 25.8086 - priority_mean_absolute_error: 0.4935 - department_accuracy: 0.2453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25a0ef2b9d0>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1280\n",
    "\n",
    "## X_train : 3 inputs\n",
    "title_data = np.random.randint(0,2,size=(num_samples,vocabulary_size))\n",
    "\n",
    "text_body_data = np.random.randint(0,2,size=(num_samples,vocabulary_size))\n",
    "\n",
    "\n",
    "tags_data = np.random.randint(0,2,size=(num_samples,num_tags))\n",
    "\n",
    "## y_train : 2 outputs\n",
    "priority_data = np.random.random(size=(num_samples,1))\n",
    "\n",
    "department_data = np.random.randint(0,2,size=(num_samples,num_departments))\n",
    "\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "                loss = keras.losses.CategoricalCrossentropy(),\n",
    "                metrics  = [['mean_absolute_error'],['accuracy']]\n",
    "                )\n",
    "\n",
    "model.fit(\n",
    "            [title_data,text_body_data,tags_data],\n",
    "            [priority_data,department_data],\n",
    "            epochs = 1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 5ms/step - loss: 34.1427 - priority_loss: 0.0000e+00 - department_loss: 34.1427 - priority_mean_absolute_error: 0.4942 - department_accuracy: 0.1344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[34.142662048339844,\n",
       " 0.0,\n",
       " 34.142662048339844,\n",
       " 0.49419766664505005,\n",
       " 0.13437500596046448]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(\n",
    "            [title_data,text_body_data,tags_data],\n",
    "            [priority_data,department_data]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 2ms/step\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[1.2384317e-12 4.4216391e-09 1.0000000e+00 8.4439983e-10]\n",
      " [6.5095459e-12 6.6097714e-09 1.0000000e+00 9.8543076e-11]\n",
      " [1.7776567e-12 2.3975562e-09 1.0000000e+00 2.1206913e-10]\n",
      " ...\n",
      " [6.7806633e-13 1.6777527e-09 1.0000000e+00 3.1215783e-10]\n",
      " [2.1869555e-12 1.6907051e-09 1.0000000e+00 3.2584330e-10]\n",
      " [2.2038389e-12 4.6194364e-09 1.0000000e+00 1.6804744e-10]]\n"
     ]
    }
   ],
   "source": [
    "priority_predicts , department_predicts = model.predict([title_data,text_body_data,tags_data])\n",
    "print(priority_predicts)\n",
    "print(department_predicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don’t want to rely on input order (for instance, because you have many inputs\n",
    "or outputs), you can also leverage the names you gave to the Input objects and the\n",
    "output layers, and pass data via dictionaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing 7.11 Training a model by providing dicts of input and target arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 9ms/step - loss: 41.5559 - priority_loss: 0.3297 - department_loss: 41.2263 - priority_mean_absolute_error: 0.4942 - department_accuracy: 0.2812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x259ffd4fb20>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "            optimizer = keras.optimizers.RMSprop(),\n",
    "            loss = {'priority':keras.losses.MeanSquaredError(),\"department\":keras.losses.CategoricalCrossentropy()  },\n",
    "            metrics = {'priority':['mean_absolute_error'],\"department\":['accuracy']  },\n",
    "            \n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    {\"text_body\":text_body_data,'title':title_data,'tags':tags_data},\n",
    "    {\"department\":department_data,\"priority\":priority_data}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 6ms/step - loss: 33.2248 - priority_loss: 0.3297 - department_loss: 32.8952 - priority_mean_absolute_error: 0.4942 - department_accuracy: 0.2664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[33.22483825683594,\n",
       " 0.3296578824520111,\n",
       " 32.895179748535156,\n",
       " 0.49419766664505005,\n",
       " 0.26640623807907104]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(\n",
    "            \n",
    "    {\"text_body\":text_body_data,'title':title_data,'tags':tags_data},\n",
    "    {\"department\":department_data,\"priority\":priority_data}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]], dtype=float32),\n",
       " array([[2.8929740e-06, 2.7313715e-01, 7.2685999e-01, 7.1691092e-23],\n",
       "        [2.9793136e-05, 8.0551261e-01, 1.9445761e-01, 5.4032523e-24],\n",
       "        [1.0464366e-05, 4.2909589e-01, 5.7089359e-01, 5.7784150e-23],\n",
       "        ...,\n",
       "        [3.8515691e-06, 4.6289614e-01, 5.3710008e-01, 1.0757531e-22],\n",
       "        [1.8599145e-05, 3.6414874e-01, 6.3583267e-01, 6.4672098e-23],\n",
       "        [7.0158417e-06, 7.6670337e-01, 2.3328960e-01, 4.4308954e-23]],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\n",
    "           \n",
    "    {\"text_body\":text_body_data,'title':title_data,'tags':tags_data},\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### THE POWER OF THE FUNCTIONAL API: ACCESS TO LAYER CONNECTIVITY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Functional model is an explicit graph data structure. This makes it possible to\n",
    "inspect how layers are connected and reuse previous graph nodes (which are layer\n",
    "outputs) as part of new models. \n",
    "\n",
    "It also nicely fits the “mental model” that most researchers use when thinking about a deep neural network: a graph of layers. This enables\n",
    "two important use cases: model visualization and feature extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s visualize the connectivity of the model we just defined (the topology of the\n",
    "model).\n",
    "\n",
    "\n",
    "You can plot a Functional model as a graph with the __plot_model()__ utility (see\n",
    "figure 7.2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(model,'Ticket_Classifier.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also let it show the shape information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(model,'Ticket_Classifier_with_shape.png',show_shapes=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access to layer connectivity also means that you can inspect and reuse individual\n",
    " nodes (layer calls) in the graph. \n",
    " \n",
    " The __model.layers__ model property provides the list\n",
    " of layers that make up the model, and for each layer you can query __layer.input__ and\n",
    " __layer.output__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x25a2dd18df0>,\n",
       " <keras.engine.input_layer.InputLayer at 0x25a2dd18d90>,\n",
       " <keras.engine.input_layer.InputLayer at 0x25a2dd18790>,\n",
       " <keras.layers.merging.concatenate.Concatenate at 0x25a2dd18520>,\n",
       " <keras.layers.core.dense.Dense at 0x25a2dcf6940>,\n",
       " <keras.layers.core.dense.Dense at 0x25a2dd035b0>,\n",
       " <keras.layers.core.dense.Dense at 0x25a2dd13c70>]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See that the __model.layer[3]__ is concatenate, we can check what's in it by __layers.input__ and __layers.output__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'title')>,\n",
       " <KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'text_body')>,\n",
       " <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'tags')>]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 20100) dtype=float32 (created by layer 'concatenate_2')>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s say you want to add another output to the previous model—you want to estimate how long a given issue ticket will take to resolve, a kind of difficulty rating. \n",
    "\n",
    "You could do this via a classification layer over three categories: “quick,” “medium,” and\n",
    "“difficult.”\n",
    "\n",
    "You don’t need to recreate and retrain a model from scratch. You can start\n",
    "from the intermediate features of your previous model, since you have access to them,\n",
    "like this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing 7.13 Creating a new model by reusing intermediate layer outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "features= model.layers[4].output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__layers[4]__ is our intermediate \n",
    "Dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "difficulty = layers.Dense(4,activation='softmax',name='difficulty')(features)\n",
    "\n",
    "new_model = keras.Model(\n",
    "          inputs=[title,text_body,tags],outputs=[priority,department,difficulty]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(new_model,'New_model_with_difficulties.png',show_shapes=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  7.2.3 Subclassing the Model Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last model-building pattern you should know about is the most advanced one:\n",
    "\n",
    "Model subclassing. You learned in chapter 3 how to subclass the Layer class to create\n",
    "custom layers. Subclassing Model is pretty similar:\n",
    "\n",
    "1. In the __\"__init__()\"__ method, define the layers the model will use.\n",
    "\n",
    "2. In the __call()__ method, define the forward pass of the model, reusing the layers\n",
    "previously created.\n",
    "\n",
    "3. Instantiate your subclass, and call it on data to create its weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REWRITING OUR PREVIOUS EXAMPLE AS A SUBCLASSED MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing 7.14 A simple subclassed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CostomerTicketModel(keras.Model):\n",
    "    def __init__(self,num_departments:int):\n",
    "        super().__init__()\n",
    "        self.concat_layer = layers.Concatenate()\n",
    "        self.mixing_layer = layers.Dense(64,activation='relu')\n",
    "        self.priority_scorer = layers.Dense(1,activation='sigmoid')\n",
    "        self.department_classifier = layers.Dense(num_departments,activation='softmax')\n",
    "    \n",
    "    def call(self,inputs:dict):\n",
    "        title = inputs[\"title\"]\n",
    "        text_body = inputs['text_body']\n",
    "        tags = inputs['tags']\n",
    "\n",
    "        features = self.concat_layer([title,text_body,tags])\n",
    "        features = self.mixing_layer(features)\n",
    "        priority = self.priority_scorer(features)\n",
    "        department = self.department_classifier(features)\n",
    "        return priority,department"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's __init__ the model as this class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CostomerTicketModel(num_departments=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's __call__ the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "priority,department = model.call(inputs=        \n",
    "    {\"text_body\":text_body_data,'title':title_data,'tags':tags_data},\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can __call__ in this way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "priority,department = model(inputs=        \n",
    "    {\"text_body\":text_body_data,'title':title_data,'tags':tags_data},\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, everything looks very similar to Layer subclassing, a workflow you encountered\n",
    "in chapter 3. What, then, is the difference between a Layer subclass and a Model subclass? It’s simple: a “layer” is a building block you use to create models, and a “model”\n",
    "is the top-level object that you will actually train, export for inference, etc. \n",
    "\n",
    "In short, a\n",
    "Model has fit(), evaluate(), and predict() methods. Layers don’t. Other than that,\n",
    "the two classes are virtually identical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's review that how the model bulit before:\n",
    "\n",
    "\"model = keras.Model(inputs=[title,text_body,tags],outputs=[priority,department])\"\n",
    "\n",
    "which means our __call()__method has the same function as \"inputs=\",but the difference is that we sepcified the output rather than defining it by ourselves in __Model()__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After figuring it out , now we can treat the class as a common model \n",
    "\n",
    "\n",
    "You can __compile()__ and train the __model__ just like before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "                loss = [keras.losses.MeanSquaredError(),keras.losses.CategoricalCrossentropy()],\n",
    "                metrics = [['mean_absolute_error'],['accuracy']]\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of the target \n",
    "data must match exactly what is \n",
    "returned by the call() method—\n",
    "here, a list of two elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 13ms/step - loss: 21.7433 - output_1_loss: 0.3263 - output_2_loss: 21.4170 - output_1_mean_absolute_error: 0.4914 - output_2_accuracy: 0.3180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x259fffcddc0>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(  \n",
    "    {\"text_body\":text_body_data,'title':title_data,'tags':tags_data},\n",
    "    [priority_data,department_data],epochs = 1\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "priority_preds, department_preds = model.predict({\"title\": title_data,\n",
    " \"text_body\": text_body_data,\n",
    " \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BEWARE: WHAT SUBCLASSED MODELS DON’T SUPPORT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This freedom comes at a cost: with subclassed models, you are responsible for more of\n",
    "the model logic, which means your potential error surface is much larger. \n",
    "\n",
    "As a result,\n",
    "you will have more debugging work to do. You are developing a new Python object,\n",
    "not just snapping together LEGO bricks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, because the way layers are connected to each other is hidden inside\n",
    " the body of the __call()__ method, you cannot access that information. Calling __summary()__ will not display layer connectivity, and you cannot plot the model topology via\n",
    " __plot_model()__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.4 Mixing and Matching different components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All models in the Keras API\n",
    "can smoothly interoperate with each other, whether they’re Sequential models, Func\u0002tional models, or subclassed models written from scratch. \n",
    "\n",
    "They’re all part of the same spectrum of workflows.\n",
    " \n",
    " \n",
    "For instance, you can use a subclassed layer or model in a Functional model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing 7.15 Creating a Functional model that includes a subclassed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(keras.Model):\n",
    "    def __init__(self,num_class=2):\n",
    "        super().__init__()\n",
    "        if num_class == 2:\n",
    "            num_units = 1\n",
    "            activation = 'sigmoid'\n",
    "        else :\n",
    "            num_units = num_class\n",
    "            activation = 'softmax'\n",
    "        \n",
    "        self.dense = layers.Dense(num_units,activation=activation)\n",
    "    \n",
    "    def call(self,inputs):\n",
    "        return self.dense(inputs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,))\n",
    "features = layers.Dense(64,activation='relu')(inputs)\n",
    "outputs = Classifier(num_class=10)(features)\n",
    "model  =keras.Model(inputs= inputs,outputs= outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inversely, you can use a Functional model as part of a subclassed layer or model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing 7.16 Creating a subclassed model that includes a Functional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(64,))\n",
    "outputs = layers.Dense(1,activation='sigmoid')(inputs)\n",
    "binary_classifier = keras.Model(inputs=inputs,outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(keras.Model):\n",
    "    def __init__(self,num_class = 2):\n",
    "        super().__init__()\n",
    "        self.dense = layers.Dense(64,activation='relu')\n",
    "        self.classifier= binary_classifier\n",
    "    def call(self,inputs):\n",
    "        features = self.dense(inputs)\n",
    "        return self.classifier(features)\n",
    "\n",
    "model = MyModel()(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the book it was typed as \n",
    "\n",
    "model = MyModel()\n",
    "\n",
    "but I suggusted it should be \n",
    "\n",
    "model = Mymodel()(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.5 Remember: Use the right tool for the job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In general, the Functional API provides you with a pretty good trade-off between\n",
    "ease of use and flexibility. \n",
    "\n",
    "It also gives you direct access to layer connectivity, which is\n",
    "very powerful for use cases such as model plotting or feature extraction. If you can use\n",
    "the Functional API—that is, if your model can be expressed as a directed acyclic graph\n",
    "of layers—I recommend using it over model subclassing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Going forward, all examples in this book will use the Functional API, simply\n",
    "because all the models we will work with are expressible as graphs of layers. We will,\n",
    "however, make frequent use of subclassed layers. \n",
    "\n",
    "\n",
    "In general, using Functional models\n",
    "that include subclassed layers provides the best of both worlds: high development flexibility while retaining the advantages of the Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Using built-in training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras provides you with different workflows for training models. \n",
    "\n",
    "They can be as simple as calling fit() on your data, or as advanced as writing a new training algorithm from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing 7.17 The standard workflow: compile(), fit(), evaluate(), predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "def get_mnist_model():\n",
    "    inputs = keras.Input(shape=(28*28,))\n",
    "    features = layers.Dense(512,activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10,activation='softmax')(features)\n",
    "    model = keras.Model(inputs=inputs,outputs=outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "(images,labels),(test_images,test_labels) = mnist.load_data()\n",
    "\n",
    "images = images.reshape((60000,28*28))\n",
    "images = images.astype('float32')/255\n",
    "\n",
    "\n",
    "test_images = test_images.reshape((10000,28*28))\n",
    "test_images = test_images.astype('float32')/255\n",
    "\n",
    "train_images,val_images = images[10000:],images[:10000]\n",
    "\n",
    "\n",
    "train_labels,val_labels = labels[10000:],labels[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(\n",
    "            optimizer = keras.optimizers.RMSprop(),\n",
    "            loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "            metrics = ['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.2965 - accuracy: 0.9114 - val_loss: 0.1451 - val_accuracy: 0.9588\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1655 - accuracy: 0.9529 - val_loss: 0.1196 - val_accuracy: 0.9672\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 0.1388 - accuracy: 0.9630 - val_loss: 0.1128 - val_accuracy: 0.9705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25a011497f0>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images,train_labels,\n",
    "            epochs = 3,\n",
    "            validation_data = (val_images,val_labels)\n",
    "            \n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1071 - accuracy: 0.9713\n"
     ]
    }
   ],
   "source": [
    "test_metric = model.evaluate(test_images,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple of ways you can customize this simple workflow:\n",
    "\n",
    "1.  Provide your own custom metrics.\n",
    "2.  Pass callbacks to the fit() method to schedule actions to be taken at specific\n",
    "points during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.1 Writing your own metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commonly used metrics for classification and regression are\n",
    "already part of the built-in keras.metrics module, and most of the time that’s what\n",
    "you will use. But if you’re doing anything out of the ordinary, you will need to be able\n",
    "to write your own metrics. It’s simple!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Keras metric is a subclass of the keras.metrics.Metric class. Like layers, a metric has an internal state stored in TensorFlow variables. \n",
    "\n",
    "Unlike layers, these variables aren’t updated via backpropagation, so you have to write the state-update logic yourself, which happens in the __update_state()__ method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing 7.18 Implementing a custom metric by subclassing the Metric class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "class RootMeanSquaredError(keras.metrics.Metric):\n",
    "    ## Define the state variables in theconstructor. Like for layers, you have access to\n",
    "    ##the add_weight() method.\n",
    "    def __init__(self,name = 'rmse',**kwargs):\n",
    "        super().__init__(name=name,**kwargs)\n",
    "        self.mse_sum = self.add_weight(name='mse_sum',initializer = 'zeros')\n",
    "        self.total_samples = self.add_weight( name='total_samples',initializer='zeros',dtype ='int32' )\n",
    "\n",
    "\n",
    "### To match MNIST model, we expect categorical predictions and integer labels\n",
    "    def update_state(self,y_true,y_pred,sample_weight = None):\n",
    "        y_true = tf.one_hot(y_true,depth=tf.shape(y_pred)[1])\n",
    "        mse = tf.reduce_sum(tf.square(y_true-y_pred ))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = tf.shape(y_pred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "###Implement the state update logic in update_state(). The y_true argument\n",
    "##is the targets (or labels) for one batch, while y_pred represents the\n",
    "# corresponding predictions from the model. You can ignore the\n",
    "# sample_weight argument—we won’t use it here.\n",
    "\n",
    "    def result(self):\n",
    "        return tf.sqrt(self.mse_sum/tf.cast( self.total_samples ,tf.float32))\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meanwhile, you also need to expose a way to reset the metric state without having to\n",
    "reinstantiate it—this enables the same metric objects to be used across different\n",
    "epochs of training or across both training and evaluation. \n",
    "\n",
    "You do this with the\n",
    "__reset_state()__ method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be used like built-in one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.2945 - accuracy: 0.9128 - rmse: 7.1830 - val_loss: 0.1450 - val_accuracy: 0.9587 - val_rmse: 7.3607\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1658 - accuracy: 0.9535 - rmse: 7.3540 - val_loss: 0.1196 - val_accuracy: 0.9671 - val_rmse: 7.4045\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1397 - accuracy: 0.9621 - rmse: 7.3876 - val_loss: 0.1082 - val_accuracy: 0.9713 - val_rmse: 7.4210\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0990 - accuracy: 0.9733 - rmse: 7.4345\n"
     ]
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    " loss=\"sparse_categorical_crossentropy\",\n",
    " metrics=[\"accuracy\", RootMeanSquaredError()])\n",
    "model.fit(train_images, train_labels,\n",
    " epochs=3,\n",
    " validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.2 Using callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to avoid bad outcomes (and\n",
    "thus wasted paper airplanes), it’s smarter to use, not a paper plane, but a drone that\n",
    "can sense its environment, send data back to its operator, and automatically make steering decisions based on its current state. \n",
    "\n",
    "The Keras __callbacks__ API will help you\n",
    "transform your call to model.fit() from a paper airplane into a smart, autonomous\n",
    "drone that can self-introspect and dynamically take action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A callback is an object (a class instance implementing specific methods) that is\n",
    "passed to the model in the call to fit() and that is called by the model at various\n",
    "points during training. \n",
    "\n",
    "It has access to all the available data about the state of the\n",
    "model and its performance, and it can take action: interrupt training, save a model,\n",
    "load a different weight set, or otherwise alter the state of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some examples of ways you can use callbacks:\n",
    "+ $Model checkpointing$—Saving the current state of the model at different points\n",
    "during training.\n",
    "\n",
    "+ $Early stopping$—Interrupting training when the validation loss is no longer\n",
    "improving (and of course, saving the best model obtained during training).\n",
    "\n",
    "+ $Dynamically-adjusting-the-value-of-certain-parameters-during-training$—Such as the\n",
    "learning rate of the optimizer.\n",
    "\n",
    "+ $Logging-training-and-validation-metrics-during-training,-or-visualizing-the-representations-learned-by-the-model-as they’re-updated$ —The fit() progress bar that you’re\n",
    "familiar with is in fact a callback!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The keras.callbacks module includes a number of built-in callbacks (this is not an\n",
    "exhaustive list):\n",
    "\n",
    "keras.callbacks.ModelCheckpoint\n",
    "\n",
    "keras.callbacks.EarlyStopping\n",
    "\n",
    "keras.callbacks.LearningRateScheduler\n",
    "\n",
    "keras.callbacks.ReduceLROnPlateau\n",
    "\n",
    "keras.callbacks.CSVLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### THE EARLYSTOPPING AND MODELCHECKPOINT CALLBACKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A much better way to\n",
    " handle this is to stop training when you measure that the validation loss is no longer\n",
    " improving. This can be achieved using the EarlyStopping callback\n",
    "\n",
    "The EarlyStopping callback interrupts training once a target metric being monitored has stopped improving for a fixed number of epochs.\n",
    "\n",
    "For instance, this callback\n",
    "allows you to interrupt training as soon as you start overfitting, thus avoiding having to\n",
    "retrain your model for a smaller number of epochs.\n",
    "\n",
    "\n",
    "This callback is typically used in combination with __ModelCheckpoint__, which lets you continually save the model during\n",
    "training (and, optionally, save only the current best model so far: the version of the\n",
    "model that achieved the best performance at the end of an epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing 7.19 Using the callbacks argument in the fit() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Callbacks are passed to the model via the\n",
    "# callbacks argument in fit(), which takes a list of\n",
    "# callbacks. You can pass any number of callbacks.\n",
    "callbacks_list = [\n",
    "    # Interrupts training when improvement stops\n",
    "    keras.callbacks.EarlyStopping(\n",
    "    #  Monitors the model’s validation accuracy\n",
    "        monitor = 'val_accuracy',\n",
    "    # Interrupts training when accuracy has stopped improving for two epochs\n",
    "        patience = 2\n",
    "    ),\n",
    "\n",
    "    #Saves the current weights after every epoch\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        #Path to the destination model file\n",
    "        filepath = 'checkpoint_path.keras',\n",
    "        # These two arguments mean you won’t overwrite the model file unless val_loss \n",
    "        # has improved, which allows you to keep the best model seen during training\n",
    "        monitor = 'val_accuracy',\n",
    "        save_best_only = True\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.2928 - accuracy: 0.9153 - val_loss: 0.1681 - val_accuracy: 0.9512\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1649 - accuracy: 0.9536 - val_loss: 0.1240 - val_accuracy: 0.9689\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1393 - accuracy: 0.9626 - val_loss: 0.1147 - val_accuracy: 0.9693\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1259 - accuracy: 0.9673 - val_loss: 0.1067 - val_accuracy: 0.9749\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1169 - accuracy: 0.9707 - val_loss: 0.1144 - val_accuracy: 0.9745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25a013f9c40>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    " loss=\"sparse_categorical_crossentropy\",\n",
    " metrics=[\"accuracy\"]) \n",
    "\n",
    "model.fit(train_images, train_labels, \n",
    " epochs=5, \n",
    " callbacks=callbacks_list, \n",
    " validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can always save models manually after training as well—just call\n",
    "\n",
    "__model.save('my_checkpoint_path')__ \n",
    "\n",
    "To reload the model you’ve saved, just use \n",
    "\n",
    "\n",
    "__model = keras.models.load_model(\"checkpoint_path.keras\")__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.3 Writing your own callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to take a specific action during training that isn’t covered by one of the\n",
    "built-in callbacks, you can write your own callback. \n",
    "\n",
    "\n",
    "Callbacks are implemented by subclassing the keras.callbacks.Callback class.\n",
    "\n",
    "You can then implement any number\n",
    "of the following transparently named methods, which are called at various points\n",
    "during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on_epoch_begin(epoch, logs) \n",
    "\n",
    "on_epoch_end(epoch, logs) \n",
    "\n",
    "on_batch_begin(batch, logs) \n",
    "\n",
    "on_batch_end(batch, logs) \n",
    "\n",
    "on_train_begin(logs) \n",
    "\n",
    "on_train_end(logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These methods are all called with a logs argument, which is a dictionary containing\n",
    "information about the previous batch, epoch, or training run—training and validation metrics, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Here’s a simple example that saves a list of per-batch loss values during training\n",
    "and saves a graph of these values at the end of each epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing 7.20 Creating a custom callback by subclassing the Callback class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self,logs):\n",
    "        self.per_batch_losses = []\n",
    "\n",
    "    def on_batch_end(self,batch,logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
    "    \n",
    "    def on_epoch_end(self,epoch,logs):\n",
    "        plt.clf()\n",
    "        plt.plot(range(len(self.per_batch_losses)),self.per_batch_losses,label ='Training Loss for each batch' )\n",
    "        plt.xlabel(f'Batch (epoch{epoch})')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.savefig(f'Batch (epoch{epoch})')\n",
    "        self.per_batch_losses = []\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.2960 - accuracy: 0.9124 - val_loss: 0.1483 - val_accuracy: 0.9554\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1610 - accuracy: 0.9546 - val_loss: 0.1294 - val_accuracy: 0.9666\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1384 - accuracy: 0.9627 - val_loss: 0.1103 - val_accuracy: 0.9713\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1237 - accuracy: 0.9679 - val_loss: 0.1070 - val_accuracy: 0.9728\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1178 - accuracy: 0.9711 - val_loss: 0.1044 - val_accuracy: 0.9756\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1072 - accuracy: 0.9737 - val_loss: 0.1197 - val_accuracy: 0.9746\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1049 - accuracy: 0.9750 - val_loss: 0.1151 - val_accuracy: 0.9751\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1018 - accuracy: 0.9771 - val_loss: 0.1135 - val_accuracy: 0.9773\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0992 - accuracy: 0.9778 - val_loss: 0.1102 - val_accuracy: 0.9767\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0907 - accuracy: 0.9785 - val_loss: 0.1229 - val_accuracy: 0.9770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25a2dac4f70>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "                loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "                metrics= ['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(train_images,train_labels,epochs=10,callbacks=[LossHistory()],validation_data=(val_images,val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.4 Monitoring and visualization with TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making progress is an iterative process, a loop—you start with\n",
    "an idea and express it as an experiment, attempting to validate or invalidate your idea.\n",
    "You run this experiment and process the information it generates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras helps you go from idea to experiment in the least\n",
    "possible time, and fast GPUs can help you get from experiment to result as quickly as\n",
    "possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorBoard (www.tensorflow.org/tensorboard) is a browser-based application that\n",
    "you can run locally. It’s the best way to monitor everything that goes on inside your\n",
    "model during training. With TensorBoard, you can\n",
    "\n",
    "\n",
    "1. Visually monitor metrics during training\n",
    "2. Visualize your model architecture\n",
    "3. Visualize histograms of activations and gradients\n",
    "4. Explore embeddings in 3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The easiest way to use TensorBoard with a Keras model and the __fit()__ method is to\n",
    "use the __keras.callbacks.TensorBoard__ callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.2921 - accuracy: 0.9138 - val_loss: 0.1464 - val_accuracy: 0.9574\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1657 - accuracy: 0.9536 - val_loss: 0.1235 - val_accuracy: 0.9674\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1382 - accuracy: 0.9625 - val_loss: 0.1166 - val_accuracy: 0.9709\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1267 - accuracy: 0.9670 - val_loss: 0.1096 - val_accuracy: 0.9750\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1215 - accuracy: 0.9699 - val_loss: 0.1107 - val_accuracy: 0.9757\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1083 - accuracy: 0.9730 - val_loss: 0.1133 - val_accuracy: 0.9760\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1034 - accuracy: 0.9754 - val_loss: 0.1127 - val_accuracy: 0.9766\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0990 - accuracy: 0.9769 - val_loss: 0.1019 - val_accuracy: 0.9785\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0995 - accuracy: 0.9779 - val_loss: 0.1113 - val_accuracy: 0.9795\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0935 - accuracy: 0.9788 - val_loss: 0.1181 - val_accuracy: 0.9793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25a0138db80>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "                loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "                metrics= ['accuracy']\n",
    ")\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir='E:\\\\Python-Machine-Learning\\\\Deep_Learning_With_python\\\\Tensorboard\\\\')\n",
    "\n",
    "model.fit(train_images,train_labels,epochs=10,callbacks=[tensorboard],validation_data=(val_images,val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the VSCODE, you have installed a plug-in for tensorboard, However, you should change the path you load file every time.\n",
    "\n",
    "The way to change the folde is \n",
    "\n",
    "1.  ctrl+shift+p \n",
    "\n",
    "2.  type: Python : Launch TensorBoard\n",
    "\n",
    "3. Choose the folder or type the path \n",
    "\n",
    "4. Then the tensorboard window will appear!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 Writing your own training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit() workflow strikes a nice balance between ease of use and flexibility. It’s what\n",
    "you will use most of the time. However, it isn’t meant to support everything a deep\n",
    "learning researcher may want to do, even with custom metrics, custom losses, and custom callbacks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " After all, the built-in fit() workflow is solely focused on supervised learning: a setup\n",
    "where there are known targets (also called labels or annotations) associated with your\n",
    "input data, and where you compute your loss as a function of these targets and the\n",
    "model’s predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " After all, the built-in fit() workflow is solely focused on supervised learning: a setup\n",
    "where there are known targets (also called labels or annotations) associated with your\n",
    "input data, and where you compute your loss as a function of these targets and the\n",
    "model’s predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other setups where no explicit targets are present, such as generative learning (which we will discuss in chapter 12), self-supervised learning (where targets\n",
    "are obtained from the inputs), and reinforcement learning (where learning is driven by\n",
    "occasional “rewards,” much like training a dog). Even if you’re doing regular supervised learning, as a researcher, you may want to add some novel bells and whistles that\n",
    "require low-level flexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reminder, the contents of a typical training loop look like this:\n",
    "\n",
    "1. Run the forward pass (compute the model’s output) inside a gradient tape to\n",
    "obtain a loss value for the current batch of data.\n",
    "\n",
    "2. Retrieve the gradients of the loss with regard to the model’s weights.\n",
    "\n",
    "3. Update the model’s weights so as to lower the loss value on the current batch\n",
    "of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.1 Training versus inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the low-level training loop examples you’ve seen so far, \n",
    "\n",
    "step 1 (the forward pass) was done via __predictions = model(inputs)__\n",
    "\n",
    "step 2 (retrieving the gradients\n",
    " computed by the gradient tape) was done via __gradients = tape.gradient(loss,\n",
    " model.weights)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to pass __training\n",
    " =True__ when you call a Keras model during the forward pass! \n",
    " \n",
    " Our forward pass thus\n",
    " becomes __predictions = model(inputs, training=True)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, note that when you retrieve the gradients of the weights of your\n",
    " model, you should not use tape.gradients(loss, model.weights), \n",
    " \n",
    "but rather __tape\n",
    " .gradients(loss, model.trainable_weights)__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Trainable weights—These are meant to be updated via backpropagation to minimize the loss of the model, such as the kernel and bias of a Dense layer.\n",
    "\n",
    "\n",
    "2. Non-trainable weights—These are meant to be updated during the forward pass\n",
    "by the layers that own them. \n",
    "\n",
    "For instance, if you wanted a custom layer to keep\n",
    "a counter of how many batches it has processed so far, that information would\n",
    "be stored in a non-trainable weight, and at each batch, your layer would increment the counter by one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among Keras built-in layers, the only layer that features __non-trainable__ weights is the\n",
    " __BatchNormalization__ layer, which we will discuss in chapter 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A supervised-learning training step ends up looking like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(inputs,targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs,training=True)\n",
    "        loss = loss_fn(tragets,predictions)\n",
    "    gradients = tape.gradient(loss,model.trainable_weights)\n",
    "    optimizer.apply_gradients( zip(model.trainable_weights,gradients) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.2 Low-Level usage of metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a low-level training loop, you will probably want to leverage Keras metrics (whether\n",
    "custom ones or the built-in ones). \n",
    "\n",
    "You’ve already learned about the metrics API: simply call update_state(y_true, y_pred) for each batch of targets and predictions, and\n",
    "then use result() to query the current metric value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 0.6666666865348816\n"
     ]
    }
   ],
   "source": [
    "metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "targets = [0,1,2]\n",
    "predictions = [[0.9,0.1,0.92],[0,1,0],[0,0,1]]\n",
    "metric.update_state(targets,predictions)\n",
    "current_result = metric.result()\n",
    "print(f\"result: { current_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 2.0\n"
     ]
    }
   ],
   "source": [
    "mean_tracker = keras.metrics.Mean()\n",
    "\n",
    "\n",
    "values = [0,1,2,3,4]\n",
    "for value in values:\n",
    "    mean_tracker.update_state(value)\n",
    "\n",
    "\n",
    "current_result = mean_tracker.result()\n",
    "print(f\"result: { current_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.3 A complete training and evaluation loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s combine the forward pass, backward pass, and metrics tracking into a fit()-like\n",
    "training step function that takes a batch of data and targets and returns the logs that\n",
    "would get displayed by the fit() progress bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing 7.21 Writing a step-by-step training loop: the training step function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.RMSprop()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "\n",
    "#Prepare a Mean Metric tracker to keep track of the loss average\n",
    "loss_tracking_metric = keras.metrics.Mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(inputs,targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs,training = True)\n",
    "        loss = loss_fn(targets,predictions)\n",
    "    gradients = tape.gradient(loss,model.trainable_weights)\n",
    "    optimizer.apply_gradients( zip(gradients,model.trainable_weights) )\n",
    "    \n",
    "    logs = {}\n",
    "\n",
    "    for metric in metrics:\n",
    "        ##Extract the keras.metrics.Accuracy() from the list\n",
    "        metric.update_state(targets,predictions)\n",
    "        ## logs = {\"accuracy\":reults}\n",
    "        logs[metric.name] =metric.result()\n",
    "    \n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs['loss'] = loss_tracking_metric.result()\n",
    "\n",
    "    return logs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to reset the state of our metrics at the start of each epoch and before running evaluation. Here’s a utility function to do it.``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing 7.22 Writing a step-by-step training loop: resetting the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_metrics ():\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()\n",
    "    \n",
    "    loss_tracking_metric.reset_state()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now lay out our complete training loop. \n",
    "\n",
    "Note that we use a tf.data.Dataset\n",
    "object to turn our NumPy data into an iterator that iterates over the data in batches of\n",
    "__size 32__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing 7.23 Writing a step-by-step training loop: the loop itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.uint8, name=None))>\n"
     ]
    }
   ],
   "source": [
    "(images,labels),(test_images,test_labels) = mnist.load_data()\n",
    "\n",
    "images = images.reshape((60000,28*28))\n",
    "images = images.astype('float32')/255\n",
    "\n",
    "\n",
    "test_images = test_images.reshape((10000,28*28))\n",
    "test_images = test_images.astype('float32')/255\n",
    "\n",
    "train_images,val_images = images[10000:],images[:10000]\n",
    "\n",
    "\n",
    "train_labels,val_labels = labels[10000:],labels[:10000]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "training_dataset = tf.data.Dataset.from_tensor_slices(  (train_images,train_labels)   )\n",
    "\n",
    "training_dataset = training_dataset.batch(32)\n",
    "print(training_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.0625 \n",
      " loss = 2.6221 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.1719 \n",
      " loss = 2.4378 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.1979 \n",
      " loss = 2.3944 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.2891 \n",
      " loss = 2.2014 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.3375 \n",
      " loss = 2.0867 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.3594 \n",
      " loss = 2.0051 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.3750 \n",
      " loss = 1.9512 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.3906 \n",
      " loss = 1.8847 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.4201 \n",
      " loss = 1.8131 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.4344 \n",
      " loss = 1.7607 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.4688 \n",
      " loss = 1.6906 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.4896 \n",
      " loss = 1.6296 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.5048 \n",
      " loss = 1.5854 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.5223 \n",
      " loss = 1.5468 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.5417 \n",
      " loss = 1.4926 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.5566 \n",
      " loss = 1.4567 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.5717 \n",
      " loss = 1.4193 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.5851 \n",
      " loss = 1.3838 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.5921 \n",
      " loss = 1.3521 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.6016 \n",
      " loss = 1.3220 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.6101 \n",
      " loss = 1.2982 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.6250 \n",
      " loss = 1.2663 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.6304 \n",
      " loss = 1.2461 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.6380 \n",
      " loss = 1.2313 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.6438 \n",
      " loss = 1.2114 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.6526 \n",
      " loss = 1.1874 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.6620 \n",
      " loss = 1.1665 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.6652 \n",
      " loss = 1.1512 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.6724 \n",
      " loss = 1.1298 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.6771 \n",
      " loss = 1.1156 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.6835 \n",
      " loss = 1.0972 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.6914 \n",
      " loss = 1.0749 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.6960 \n",
      " loss = 1.0578 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.6994 \n",
      " loss = 1.0458 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7036 \n",
      " loss = 1.0340 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7057 \n",
      " loss = 1.0260 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7103 \n",
      " loss = 1.0128 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7081 \n",
      " loss = 1.0132 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7075 \n",
      " loss = 1.0088 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7117 \n",
      " loss = 0.9952 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7165 \n",
      " loss = 0.9813 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7195 \n",
      " loss = 0.9689 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7224 \n",
      " loss = 0.9580 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7237 \n",
      " loss = 0.9525 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7278 \n",
      " loss = 0.9409 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7289 \n",
      " loss = 0.9331 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7320 \n",
      " loss = 0.9222 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7357 \n",
      " loss = 0.9133 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7360 \n",
      " loss = 0.9079 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7344 \n",
      " loss = 0.9120 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7359 \n",
      " loss = 0.9097 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7356 \n",
      " loss = 0.9064 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7364 \n",
      " loss = 0.9005 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7355 \n",
      " loss = 0.8987 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7375 \n",
      " loss = 0.8923 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7377 \n",
      " loss = 0.8880 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7407 \n",
      " loss = 0.8815 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7425 \n",
      " loss = 0.8771 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7436 \n",
      " loss = 0.8730 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7469 \n",
      " loss = 0.8632 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7485 \n",
      " loss = 0.8607 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7515 \n",
      " loss = 0.8527 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7520 \n",
      " loss = 0.8483 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7529 \n",
      " loss = 0.8426 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7534 \n",
      " loss = 0.8386 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7557 \n",
      " loss = 0.8304 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7579 \n",
      " loss = 0.8232 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7597 \n",
      " loss = 0.8163 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7595 \n",
      " loss = 0.8135 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7603 \n",
      " loss = 0.8104 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7610 \n",
      " loss = 0.8062 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7613 \n",
      " loss = 0.8045 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7633 \n",
      " loss = 0.8000 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7639 \n",
      " loss = 0.7967 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7646 \n",
      " loss = 0.7944 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7660 \n",
      " loss = 0.7906 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7670 \n",
      " loss = 0.7860 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7656 \n",
      " loss = 0.7890 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7666 \n",
      " loss = 0.7858 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7680 \n",
      " loss = 0.7826 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7681 \n",
      " loss = 0.7808 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7671 \n",
      " loss = 0.7807 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7673 \n",
      " loss = 0.7801 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7682 \n",
      " loss = 0.7809 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7691 \n",
      " loss = 0.7775 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7714 \n",
      " loss = 0.7709 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7719 \n",
      " loss = 0.7691 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7713 \n",
      " loss = 0.7689 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7718 \n",
      " loss = 0.7668 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7736 \n",
      " loss = 0.7610 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7734 \n",
      " loss = 0.7606 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7734 \n",
      " loss = 0.7582 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7735 \n",
      " loss = 0.7570 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7733 \n",
      " loss = 0.7558 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7720 \n",
      " loss = 0.7579 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7728 \n",
      " loss = 0.7541 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7716 \n",
      " loss = 0.7549 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7723 \n",
      " loss = 0.7513 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7721 \n",
      " loss = 0.7519 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7728 \n",
      " loss = 0.7506 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7751 \n",
      " loss = 0.7447 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7751 \n",
      " loss = 0.7434 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7764 \n",
      " loss = 0.7390 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7776 \n",
      " loss = 0.7348 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7783 \n",
      " loss = 0.7332 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7792 \n",
      " loss = 0.7307 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7792 \n",
      " loss = 0.7272 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7804 \n",
      " loss = 0.7250 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7818 \n",
      " loss = 0.7205 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7835 \n",
      " loss = 0.7165 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7835 \n",
      " loss = 0.7148 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7849 \n",
      " loss = 0.7106 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7860 \n",
      " loss = 0.7069 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7870 \n",
      " loss = 0.7050 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7872 \n",
      " loss = 0.7056 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7877 \n",
      " loss = 0.7043 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7877 \n",
      " loss = 0.7045 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7881 \n",
      " loss = 0.7019 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7894 \n",
      " loss = 0.6987 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7898 \n",
      " loss = 0.6972 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7903 \n",
      " loss = 0.6951 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7905 \n",
      " loss = 0.6932 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7907 \n",
      " loss = 0.6925 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7903 \n",
      " loss = 0.6911 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7903 \n",
      " loss = 0.6935 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7904 \n",
      " loss = 0.6925 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7911 \n",
      " loss = 0.6897 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7913 \n",
      " loss = 0.6902 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7914 \n",
      " loss = 0.6887 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7913 \n",
      " loss = 0.6871 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7915 \n",
      " loss = 0.6851 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7921 \n",
      " loss = 0.6827 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7930 \n",
      " loss = 0.6801 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7922 \n",
      " loss = 0.6799 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7926 \n",
      " loss = 0.6791 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7925 \n",
      " loss = 0.6797 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7924 \n",
      " loss = 0.6809 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7928 \n",
      " loss = 0.6795 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7934 \n",
      " loss = 0.6777 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7946 \n",
      " loss = 0.6741 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7952 \n",
      " loss = 0.6721 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7951 \n",
      " loss = 0.6716 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7959 \n",
      " loss = 0.6693 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7967 \n",
      " loss = 0.6674 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7961 \n",
      " loss = 0.6685 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7954 \n",
      " loss = 0.6695 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7955 \n",
      " loss = 0.6691 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7958 \n",
      " loss = 0.6680 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7964 \n",
      " loss = 0.6690 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7969 \n",
      " loss = 0.6684 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7972 \n",
      " loss = 0.6675 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7973 \n",
      " loss = 0.6664 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7980 \n",
      " loss = 0.6645 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7987 \n",
      " loss = 0.6619 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7994 \n",
      " loss = 0.6596 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.7999 \n",
      " loss = 0.6576 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8004 \n",
      " loss = 0.6553 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8012 \n",
      " loss = 0.6531 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8013 \n",
      " loss = 0.6521 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8014 \n",
      " loss = 0.6524 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8018 \n",
      " loss = 0.6507 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8017 \n",
      " loss = 0.6499 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8018 \n",
      " loss = 0.6489 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8022 \n",
      " loss = 0.6472 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8028 \n",
      " loss = 0.6457 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8035 \n",
      " loss = 0.6438 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8041 \n",
      " loss = 0.6421 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8047 \n",
      " loss = 0.6406 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8053 \n",
      " loss = 0.6397 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8059 \n",
      " loss = 0.6384 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8063 \n",
      " loss = 0.6361 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8070 \n",
      " loss = 0.6343 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8073 \n",
      " loss = 0.6338 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8075 \n",
      " loss = 0.6327 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8082 \n",
      " loss = 0.6305 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8088 \n",
      " loss = 0.6286 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8095 \n",
      " loss = 0.6262 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8102 \n",
      " loss = 0.6242 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8106 \n",
      " loss = 0.6230 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8101 \n",
      " loss = 0.6235 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8103 \n",
      " loss = 0.6230 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8110 \n",
      " loss = 0.6207 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8111 \n",
      " loss = 0.6199 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8108 \n",
      " loss = 0.6194 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8113 \n",
      " loss = 0.6182 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8108 \n",
      " loss = 0.6193 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8108 \n",
      " loss = 0.6181 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8110 \n",
      " loss = 0.6179 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8105 \n",
      " loss = 0.6207 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8104 \n",
      " loss = 0.6200 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8109 \n",
      " loss = 0.6187 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8117 \n",
      " loss = 0.6166 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8119 \n",
      " loss = 0.6153 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8122 \n",
      " loss = 0.6142 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8127 \n",
      " loss = 0.6126 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8130 \n",
      " loss = 0.6112 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8133 \n",
      " loss = 0.6096 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8141 \n",
      " loss = 0.6070 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8150 \n",
      " loss = 0.6048 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8153 \n",
      " loss = 0.6039 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8158 \n",
      " loss = 0.6024 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8159 \n",
      " loss = 0.6015 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8162 \n",
      " loss = 0.6008 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8166 \n",
      " loss = 0.5988 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8171 \n",
      " loss = 0.5976 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8175 \n",
      " loss = 0.5974 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8179 \n",
      " loss = 0.5964 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8184 \n",
      " loss = 0.5959 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8189 \n",
      " loss = 0.5948 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8192 \n",
      " loss = 0.5936 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8198 \n",
      " loss = 0.5918 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8200 \n",
      " loss = 0.5916 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8203 \n",
      " loss = 0.5905 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8207 \n",
      " loss = 0.5890 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8212 \n",
      " loss = 0.5878 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8213 \n",
      " loss = 0.5866 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8217 \n",
      " loss = 0.5856 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8221 \n",
      " loss = 0.5848 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8223 \n",
      " loss = 0.5839 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8226 \n",
      " loss = 0.5831 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8230 \n",
      " loss = 0.5822 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8229 \n",
      " loss = 0.5818 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8232 \n",
      " loss = 0.5818 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8237 \n",
      " loss = 0.5801 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8239 \n",
      " loss = 0.5797 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8240 \n",
      " loss = 0.5790 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8243 \n",
      " loss = 0.5781 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8246 \n",
      " loss = 0.5773 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8251 \n",
      " loss = 0.5760 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8258 \n",
      " loss = 0.5738 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8260 \n",
      " loss = 0.5727 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8257 \n",
      " loss = 0.5727 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8260 \n",
      " loss = 0.5716 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8260 \n",
      " loss = 0.5713 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8259 \n",
      " loss = 0.5712 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8261 \n",
      " loss = 0.5711 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8263 \n",
      " loss = 0.5704 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8264 \n",
      " loss = 0.5705 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8268 \n",
      " loss = 0.5694 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8271 \n",
      " loss = 0.5683 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8270 \n",
      " loss = 0.5686 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8274 \n",
      " loss = 0.5678 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8278 \n",
      " loss = 0.5668 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8277 \n",
      " loss = 0.5660 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8277 \n",
      " loss = 0.5658 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8280 \n",
      " loss = 0.5650 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8281 \n",
      " loss = 0.5645 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8283 \n",
      " loss = 0.5639 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8283 \n",
      " loss = 0.5635 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8289 \n",
      " loss = 0.5619 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8291 \n",
      " loss = 0.5614 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8294 \n",
      " loss = 0.5605 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8299 \n",
      " loss = 0.5590 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8303 \n",
      " loss = 0.5579 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8309 \n",
      " loss = 0.5563 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8314 \n",
      " loss = 0.5552 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8320 \n",
      " loss = 0.5536 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8322 \n",
      " loss = 0.5526 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8329 \n",
      " loss = 0.5507 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8333 \n",
      " loss = 0.5494 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8337 \n",
      " loss = 0.5487 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8340 \n",
      " loss = 0.5473 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8344 \n",
      " loss = 0.5461 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8346 \n",
      " loss = 0.5456 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8351 \n",
      " loss = 0.5442 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8353 \n",
      " loss = 0.5436 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8356 \n",
      " loss = 0.5425 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8359 \n",
      " loss = 0.5409 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8363 \n",
      " loss = 0.5412 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8367 \n",
      " loss = 0.5398 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8372 \n",
      " loss = 0.5387 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8374 \n",
      " loss = 0.5375 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8376 \n",
      " loss = 0.5377 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8379 \n",
      " loss = 0.5370 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8384 \n",
      " loss = 0.5355 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8385 \n",
      " loss = 0.5353 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8388 \n",
      " loss = 0.5341 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8394 \n",
      " loss = 0.5325 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8396 \n",
      " loss = 0.5314 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8401 \n",
      " loss = 0.5301 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8403 \n",
      " loss = 0.5291 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8405 \n",
      " loss = 0.5280 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8407 \n",
      " loss = 0.5277 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8410 \n",
      " loss = 0.5268 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8412 \n",
      " loss = 0.5265 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8415 \n",
      " loss = 0.5257 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8419 \n",
      " loss = 0.5247 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8423 \n",
      " loss = 0.5236 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8425 \n",
      " loss = 0.5239 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8428 \n",
      " loss = 0.5234 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8433 \n",
      " loss = 0.5220 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8435 \n",
      " loss = 0.5219 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8438 \n",
      " loss = 0.5217 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8442 \n",
      " loss = 0.5204 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8444 \n",
      " loss = 0.5196 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8447 \n",
      " loss = 0.5185 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8446 \n",
      " loss = 0.5189 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8450 \n",
      " loss = 0.5176 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8449 \n",
      " loss = 0.5176 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8452 \n",
      " loss = 0.5167 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8453 \n",
      " loss = 0.5157 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8456 \n",
      " loss = 0.5148 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8460 \n",
      " loss = 0.5135 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8464 \n",
      " loss = 0.5123 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8467 \n",
      " loss = 0.5114 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8471 \n",
      " loss = 0.5104 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8475 \n",
      " loss = 0.5092 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8475 \n",
      " loss = 0.5094 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8478 \n",
      " loss = 0.5086 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8478 \n",
      " loss = 0.5085 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8478 \n",
      " loss = 0.5081 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8482 \n",
      " loss = 0.5068 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8483 \n",
      " loss = 0.5059 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8484 \n",
      " loss = 0.5059 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8487 \n",
      " loss = 0.5055 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8484 \n",
      " loss = 0.5060 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8489 \n",
      " loss = 0.5046 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8487 \n",
      " loss = 0.5052 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8488 \n",
      " loss = 0.5050 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8490 \n",
      " loss = 0.5043 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8494 \n",
      " loss = 0.5033 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8498 \n",
      " loss = 0.5024 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8500 \n",
      " loss = 0.5017 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8502 \n",
      " loss = 0.5010 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8507 \n",
      " loss = 0.4997 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8509 \n",
      " loss = 0.4989 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8511 \n",
      " loss = 0.4980 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8513 \n",
      " loss = 0.4971 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8515 \n",
      " loss = 0.4963 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8516 \n",
      " loss = 0.4961 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8518 \n",
      " loss = 0.4962 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8519 \n",
      " loss = 0.4956 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8519 \n",
      " loss = 0.4954 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8522 \n",
      " loss = 0.4954 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8523 \n",
      " loss = 0.4946 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8524 \n",
      " loss = 0.4946 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8525 \n",
      " loss = 0.4942 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8525 \n",
      " loss = 0.4947 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8527 \n",
      " loss = 0.4940 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8528 \n",
      " loss = 0.4942 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8530 \n",
      " loss = 0.4938 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8530 \n",
      " loss = 0.4937 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8530 \n",
      " loss = 0.4938 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8528 \n",
      " loss = 0.4939 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8529 \n",
      " loss = 0.4933 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8531 \n",
      " loss = 0.4934 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8532 \n",
      " loss = 0.4927 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8534 \n",
      " loss = 0.4923 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8536 \n",
      " loss = 0.4913 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8537 \n",
      " loss = 0.4909 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8539 \n",
      " loss = 0.4905 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8541 \n",
      " loss = 0.4894 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8545 \n",
      " loss = 0.4885 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8544 \n",
      " loss = 0.4882 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8546 \n",
      " loss = 0.4878 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8547 \n",
      " loss = 0.4873 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8550 \n",
      " loss = 0.4865 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8548 \n",
      " loss = 0.4863 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8552 \n",
      " loss = 0.4851 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8555 \n",
      " loss = 0.4842 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8555 \n",
      " loss = 0.4835 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8557 \n",
      " loss = 0.4829 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8556 \n",
      " loss = 0.4834 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8559 \n",
      " loss = 0.4826 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8562 \n",
      " loss = 0.4816 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8562 \n",
      " loss = 0.4812 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8564 \n",
      " loss = 0.4807 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8568 \n",
      " loss = 0.4796 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8571 \n",
      " loss = 0.4786 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8574 \n",
      " loss = 0.4777 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8576 \n",
      " loss = 0.4767 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8579 \n",
      " loss = 0.4759 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8581 \n",
      " loss = 0.4751 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8582 \n",
      " loss = 0.4745 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8583 \n",
      " loss = 0.4741 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8586 \n",
      " loss = 0.4731 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8589 \n",
      " loss = 0.4721 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8591 \n",
      " loss = 0.4715 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8592 \n",
      " loss = 0.4711 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8590 \n",
      " loss = 0.4715 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8591 \n",
      " loss = 0.4711 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8591 \n",
      " loss = 0.4718 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8593 \n",
      " loss = 0.4713 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8595 \n",
      " loss = 0.4708 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8597 \n",
      " loss = 0.4700 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8600 \n",
      " loss = 0.4693 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8603 \n",
      " loss = 0.4683 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8605 \n",
      " loss = 0.4675 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8607 \n",
      " loss = 0.4668 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8609 \n",
      " loss = 0.4661 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8605 \n",
      " loss = 0.4673 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8600 \n",
      " loss = 0.4680 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8599 \n",
      " loss = 0.4688 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8597 \n",
      " loss = 0.4688 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8598 \n",
      " loss = 0.4687 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8599 \n",
      " loss = 0.4685 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8600 \n",
      " loss = 0.4680 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8601 \n",
      " loss = 0.4677 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8600 \n",
      " loss = 0.4673 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8600 \n",
      " loss = 0.4670 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8600 \n",
      " loss = 0.4671 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8602 \n",
      " loss = 0.4662 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8603 \n",
      " loss = 0.4657 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8605 \n",
      " loss = 0.4650 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8609 \n",
      " loss = 0.4640 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8612 \n",
      " loss = 0.4631 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8614 \n",
      " loss = 0.4626 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8616 \n",
      " loss = 0.4621 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8616 \n",
      " loss = 0.4621 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8617 \n",
      " loss = 0.4623 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8619 \n",
      " loss = 0.4616 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8621 \n",
      " loss = 0.4609 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8621 \n",
      " loss = 0.4606 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8624 \n",
      " loss = 0.4598 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8627 \n",
      " loss = 0.4588 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8630 \n",
      " loss = 0.4579 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8632 \n",
      " loss = 0.4572 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8633 \n",
      " loss = 0.4567 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8634 \n",
      " loss = 0.4564 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8637 \n",
      " loss = 0.4556 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8638 \n",
      " loss = 0.4551 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8640 \n",
      " loss = 0.4546 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8640 \n",
      " loss = 0.4542 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8641 \n",
      " loss = 0.4536 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8642 \n",
      " loss = 0.4529 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8644 \n",
      " loss = 0.4525 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8646 \n",
      " loss = 0.4518 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8647 \n",
      " loss = 0.4512 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8647 \n",
      " loss = 0.4514 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8648 \n",
      " loss = 0.4514 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8649 \n",
      " loss = 0.4509 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8651 \n",
      " loss = 0.4503 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8651 \n",
      " loss = 0.4501 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8651 \n",
      " loss = 0.4500 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8652 \n",
      " loss = 0.4493 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8653 \n",
      " loss = 0.4489 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8654 \n",
      " loss = 0.4494 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8655 \n",
      " loss = 0.4488 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8657 \n",
      " loss = 0.4485 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8656 \n",
      " loss = 0.4482 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8657 \n",
      " loss = 0.4476 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8659 \n",
      " loss = 0.4471 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8658 \n",
      " loss = 0.4469 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8660 \n",
      " loss = 0.4463 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8662 \n",
      " loss = 0.4461 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8660 \n",
      " loss = 0.4460 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8660 \n",
      " loss = 0.4463 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8662 \n",
      " loss = 0.4456 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8664 \n",
      " loss = 0.4450 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8666 \n",
      " loss = 0.4442 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8666 \n",
      " loss = 0.4438 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8666 \n",
      " loss = 0.4437 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8666 \n",
      " loss = 0.4433 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8667 \n",
      " loss = 0.4430 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8670 \n",
      " loss = 0.4427 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8672 \n",
      " loss = 0.4420 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8671 \n",
      " loss = 0.4420 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8672 \n",
      " loss = 0.4416 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8672 \n",
      " loss = 0.4416 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8672 \n",
      " loss = 0.4412 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8673 \n",
      " loss = 0.4411 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8674 \n",
      " loss = 0.4408 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8676 \n",
      " loss = 0.4407 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8676 \n",
      " loss = 0.4402 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8676 \n",
      " loss = 0.4400 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8677 \n",
      " loss = 0.4396 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8676 \n",
      " loss = 0.4396 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8678 \n",
      " loss = 0.4389 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8680 \n",
      " loss = 0.4387 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8683 \n",
      " loss = 0.4380 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8686 \n",
      " loss = 0.4372 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8686 \n",
      " loss = 0.4370 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8689 \n",
      " loss = 0.4363 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8691 \n",
      " loss = 0.4357 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8692 \n",
      " loss = 0.4355 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8693 \n",
      " loss = 0.4350 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8694 \n",
      " loss = 0.4346 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8696 \n",
      " loss = 0.4339 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8695 \n",
      " loss = 0.4342 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8697 \n",
      " loss = 0.4335 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8699 \n",
      " loss = 0.4329 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8701 \n",
      " loss = 0.4321 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8703 \n",
      " loss = 0.4314 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8704 \n",
      " loss = 0.4313 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8707 \n",
      " loss = 0.4306 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8708 \n",
      " loss = 0.4304 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8709 \n",
      " loss = 0.4300 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8710 \n",
      " loss = 0.4294 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8712 \n",
      " loss = 0.4288 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8713 \n",
      " loss = 0.4285 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8715 \n",
      " loss = 0.4278 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8716 \n",
      " loss = 0.4273 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8718 \n",
      " loss = 0.4268 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8718 \n",
      " loss = 0.4270 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8718 \n",
      " loss = 0.4265 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8720 \n",
      " loss = 0.4259 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8721 \n",
      " loss = 0.4253 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8723 \n",
      " loss = 0.4247 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8723 \n",
      " loss = 0.4246 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8723 \n",
      " loss = 0.4245 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8724 \n",
      " loss = 0.4243 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8726 \n",
      " loss = 0.4236 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8727 \n",
      " loss = 0.4232 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8728 \n",
      " loss = 0.4226 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8729 \n",
      " loss = 0.4225 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8731 \n",
      " loss = 0.4220 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8732 \n",
      " loss = 0.4218 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8733 \n",
      " loss = 0.4211 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8734 \n",
      " loss = 0.4210 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8735 \n",
      " loss = 0.4208 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8737 \n",
      " loss = 0.4201 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8737 \n",
      " loss = 0.4211 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8737 \n",
      " loss = 0.4212 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8737 \n",
      " loss = 0.4209 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8736 \n",
      " loss = 0.4207 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8737 \n",
      " loss = 0.4208 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8738 \n",
      " loss = 0.4204 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8739 \n",
      " loss = 0.4203 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8740 \n",
      " loss = 0.4198 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8740 \n",
      " loss = 0.4207 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8740 \n",
      " loss = 0.4204 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8741 \n",
      " loss = 0.4200 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8741 \n",
      " loss = 0.4200 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8739 \n",
      " loss = 0.4209 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8740 \n",
      " loss = 0.4204 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8743 \n",
      " loss = 0.4198 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8744 \n",
      " loss = 0.4195 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8745 \n",
      " loss = 0.4198 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8745 \n",
      " loss = 0.4195 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8746 \n",
      " loss = 0.4191 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8749 \n",
      " loss = 0.4184 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8751 \n",
      " loss = 0.4178 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8752 \n",
      " loss = 0.4174 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8753 \n",
      " loss = 0.4169 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8754 \n",
      " loss = 0.4164 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8755 \n",
      " loss = 0.4162 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8752 \n",
      " loss = 0.4178 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8753 \n",
      " loss = 0.4174 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8755 \n",
      " loss = 0.4170 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8756 \n",
      " loss = 0.4166 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8758 \n",
      " loss = 0.4161 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8759 \n",
      " loss = 0.4155 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8760 \n",
      " loss = 0.4151 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8762 \n",
      " loss = 0.4145 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8761 \n",
      " loss = 0.4143 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8761 \n",
      " loss = 0.4145 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8761 \n",
      " loss = 0.4145 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8763 \n",
      " loss = 0.4141 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8765 \n",
      " loss = 0.4135 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8765 \n",
      " loss = 0.4130 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8765 \n",
      " loss = 0.4127 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8766 \n",
      " loss = 0.4125 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8768 \n",
      " loss = 0.4121 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8767 \n",
      " loss = 0.4118 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8768 \n",
      " loss = 0.4115 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8769 \n",
      " loss = 0.4111 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8769 \n",
      " loss = 0.4111 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8771 \n",
      " loss = 0.4106 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8772 \n",
      " loss = 0.4101 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8774 \n",
      " loss = 0.4095 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8776 \n",
      " loss = 0.4089 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8776 \n",
      " loss = 0.4087 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8776 \n",
      " loss = 0.4084 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8778 \n",
      " loss = 0.4078 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8780 \n",
      " loss = 0.4072 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8781 \n",
      " loss = 0.4068 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8782 \n",
      " loss = 0.4067 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8783 \n",
      " loss = 0.4066 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8784 \n",
      " loss = 0.4064 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8784 \n",
      " loss = 0.4059 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8785 \n",
      " loss = 0.4055 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8786 \n",
      " loss = 0.4052 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8787 \n",
      " loss = 0.4046 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8788 \n",
      " loss = 0.4048 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8788 \n",
      " loss = 0.4053 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8788 \n",
      " loss = 0.4051 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8790 \n",
      " loss = 0.4044 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8791 \n",
      " loss = 0.4043 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8793 \n",
      " loss = 0.4038 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8794 \n",
      " loss = 0.4039 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8795 \n",
      " loss = 0.4034 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8795 \n",
      " loss = 0.4035 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8793 \n",
      " loss = 0.4039 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8794 \n",
      " loss = 0.4036 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8795 \n",
      " loss = 0.4034 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8797 \n",
      " loss = 0.4028 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8797 \n",
      " loss = 0.4026 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8798 \n",
      " loss = 0.4024 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8799 \n",
      " loss = 0.4020 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8800 \n",
      " loss = 0.4017 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8801 \n",
      " loss = 0.4012 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8802 \n",
      " loss = 0.4008 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8803 \n",
      " loss = 0.4003 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8803 \n",
      " loss = 0.4002 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8805 \n",
      " loss = 0.3997 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8806 \n",
      " loss = 0.3995 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8806 \n",
      " loss = 0.3992 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8806 \n",
      " loss = 0.3994 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8807 \n",
      " loss = 0.3990 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8807 \n",
      " loss = 0.3987 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8807 \n",
      " loss = 0.3987 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8808 \n",
      " loss = 0.3985 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8809 \n",
      " loss = 0.3983 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8807 \n",
      " loss = 0.3987 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8808 \n",
      " loss = 0.3984 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8807 \n",
      " loss = 0.3982 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8809 \n",
      " loss = 0.3976 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8811 \n",
      " loss = 0.3976 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8812 \n",
      " loss = 0.3975 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8811 \n",
      " loss = 0.3973 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8812 \n",
      " loss = 0.3969 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8813 \n",
      " loss = 0.3966 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8815 \n",
      " loss = 0.3962 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8816 \n",
      " loss = 0.3958 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8815 \n",
      " loss = 0.3959 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8815 \n",
      " loss = 0.3960 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8816 \n",
      " loss = 0.3959 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8817 \n",
      " loss = 0.3958 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8819 \n",
      " loss = 0.3953 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8818 \n",
      " loss = 0.3956 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8818 \n",
      " loss = 0.3952 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8818 \n",
      " loss = 0.3951 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8818 \n",
      " loss = 0.3951 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8817 \n",
      " loss = 0.3953 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8819 \n",
      " loss = 0.3950 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8819 \n",
      " loss = 0.3947 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8819 \n",
      " loss = 0.3947 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8820 \n",
      " loss = 0.3943 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8820 \n",
      " loss = 0.3941 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8820 \n",
      " loss = 0.3942 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8820 \n",
      " loss = 0.3941 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8821 \n",
      " loss = 0.3940 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8823 \n",
      " loss = 0.3935 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8823 \n",
      " loss = 0.3932 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8824 \n",
      " loss = 0.3928 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8825 \n",
      " loss = 0.3924 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8827 \n",
      " loss = 0.3919 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8828 \n",
      " loss = 0.3914 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8829 \n",
      " loss = 0.3911 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8830 \n",
      " loss = 0.3909 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8831 \n",
      " loss = 0.3906 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8831 \n",
      " loss = 0.3904 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8832 \n",
      " loss = 0.3901 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8832 \n",
      " loss = 0.3901 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8832 \n",
      " loss = 0.3898 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8831 \n",
      " loss = 0.3900 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8832 \n",
      " loss = 0.3899 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8832 \n",
      " loss = 0.3897 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8833 \n",
      " loss = 0.3896 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8835 \n",
      " loss = 0.3891 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8835 \n",
      " loss = 0.3889 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8835 \n",
      " loss = 0.3888 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8836 \n",
      " loss = 0.3887 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8836 \n",
      " loss = 0.3886 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8837 \n",
      " loss = 0.3883 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8836 \n",
      " loss = 0.3884 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8836 \n",
      " loss = 0.3881 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8837 \n",
      " loss = 0.3879 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8839 \n",
      " loss = 0.3874 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8839 \n",
      " loss = 0.3874 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8839 \n",
      " loss = 0.3878 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8841 \n",
      " loss = 0.3873 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8840 \n",
      " loss = 0.3878 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8841 \n",
      " loss = 0.3875 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8841 \n",
      " loss = 0.3873 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8840 \n",
      " loss = 0.3879 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8841 \n",
      " loss = 0.3875 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8839 \n",
      " loss = 0.3880 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8838 \n",
      " loss = 0.3880 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8839 \n",
      " loss = 0.3879 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8838 \n",
      " loss = 0.3878 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8839 \n",
      " loss = 0.3875 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8840 \n",
      " loss = 0.3872 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8840 \n",
      " loss = 0.3869 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8841 \n",
      " loss = 0.3868 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8841 \n",
      " loss = 0.3866 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8841 \n",
      " loss = 0.3865 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8841 \n",
      " loss = 0.3866 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8840 \n",
      " loss = 0.3869 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8841 \n",
      " loss = 0.3867 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8842 \n",
      " loss = 0.3864 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8842 \n",
      " loss = 0.3862 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8842 \n",
      " loss = 0.3863 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8842 \n",
      " loss = 0.3860 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8844 \n",
      " loss = 0.3856 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8845 \n",
      " loss = 0.3852 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8846 \n",
      " loss = 0.3851 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8846 \n",
      " loss = 0.3848 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8846 \n",
      " loss = 0.3850 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8846 \n",
      " loss = 0.3850 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8847 \n",
      " loss = 0.3847 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8848 \n",
      " loss = 0.3844 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8849 \n",
      " loss = 0.3842 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8850 \n",
      " loss = 0.3841 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8851 \n",
      " loss = 0.3837 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8852 \n",
      " loss = 0.3835 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8853 \n",
      " loss = 0.3835 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8853 \n",
      " loss = 0.3834 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8851 \n",
      " loss = 0.3837 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8852 \n",
      " loss = 0.3835 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8851 \n",
      " loss = 0.3839 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8851 \n",
      " loss = 0.3838 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8852 \n",
      " loss = 0.3835 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8853 \n",
      " loss = 0.3833 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8854 \n",
      " loss = 0.3830 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8855 \n",
      " loss = 0.3826 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8857 \n",
      " loss = 0.3821 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8858 \n",
      " loss = 0.3816 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8857 \n",
      " loss = 0.3820 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8859 \n",
      " loss = 0.3815 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8859 \n",
      " loss = 0.3813 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8859 \n",
      " loss = 0.3815 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8860 \n",
      " loss = 0.3813 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8860 \n",
      " loss = 0.3812 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8860 \n",
      " loss = 0.3810 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8861 \n",
      " loss = 0.3809 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8862 \n",
      " loss = 0.3808 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8863 \n",
      " loss = 0.3804 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8864 \n",
      " loss = 0.3799 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8865 \n",
      " loss = 0.3796 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8865 \n",
      " loss = 0.3799 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8866 \n",
      " loss = 0.3794 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8867 \n",
      " loss = 0.3792 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8867 \n",
      " loss = 0.3791 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8869 \n",
      " loss = 0.3787 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8869 \n",
      " loss = 0.3784 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8869 \n",
      " loss = 0.3784 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8869 \n",
      " loss = 0.3782 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8870 \n",
      " loss = 0.3779 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8870 \n",
      " loss = 0.3779 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8869 \n",
      " loss = 0.3784 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8870 \n",
      " loss = 0.3781 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8870 \n",
      " loss = 0.3779 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8870 \n",
      " loss = 0.3776 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8871 \n",
      " loss = 0.3774 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8872 \n",
      " loss = 0.3770 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8873 \n",
      " loss = 0.3767 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8873 \n",
      " loss = 0.3764 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8874 \n",
      " loss = 0.3761 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8875 \n",
      " loss = 0.3757 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8876 \n",
      " loss = 0.3756 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8877 \n",
      " loss = 0.3752 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8877 \n",
      " loss = 0.3755 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8878 \n",
      " loss = 0.3752 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8879 \n",
      " loss = 0.3748 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8880 \n",
      " loss = 0.3745 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8881 \n",
      " loss = 0.3740 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8883 \n",
      " loss = 0.3736 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8884 \n",
      " loss = 0.3733 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8885 \n",
      " loss = 0.3729 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8886 \n",
      " loss = 0.3727 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8887 \n",
      " loss = 0.3727 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8887 \n",
      " loss = 0.3724 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8888 \n",
      " loss = 0.3722 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8889 \n",
      " loss = 0.3718 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8889 \n",
      " loss = 0.3714 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8890 \n",
      " loss = 0.3710 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8891 \n",
      " loss = 0.3707 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8892 \n",
      " loss = 0.3703 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8893 \n",
      " loss = 0.3700 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8895 \n",
      " loss = 0.3695 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8895 \n",
      " loss = 0.3692 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8895 \n",
      " loss = 0.3696 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8895 \n",
      " loss = 0.3694 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8896 \n",
      " loss = 0.3690 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8897 \n",
      " loss = 0.3689 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8897 \n",
      " loss = 0.3690 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8896 \n",
      " loss = 0.3688 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8897 \n",
      " loss = 0.3687 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8897 \n",
      " loss = 0.3684 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8898 \n",
      " loss = 0.3683 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8898 \n",
      " loss = 0.3684 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8898 \n",
      " loss = 0.3684 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8899 \n",
      " loss = 0.3684 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8900 \n",
      " loss = 0.3680 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8899 \n",
      " loss = 0.3684 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8899 \n",
      " loss = 0.3685 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8899 \n",
      " loss = 0.3683 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8899 \n",
      " loss = 0.3683 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8899 \n",
      " loss = 0.3680 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8900 \n",
      " loss = 0.3678 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8901 \n",
      " loss = 0.3674 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8901 \n",
      " loss = 0.3671 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8901 \n",
      " loss = 0.3669 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8902 \n",
      " loss = 0.3667 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8903 \n",
      " loss = 0.3666 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8904 \n",
      " loss = 0.3664 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8905 \n",
      " loss = 0.3662 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8905 \n",
      " loss = 0.3664 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8906 \n",
      " loss = 0.3660 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8908 \n",
      " loss = 0.3656 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8908 \n",
      " loss = 0.3654 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8909 \n",
      " loss = 0.3651 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8909 \n",
      " loss = 0.3651 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8909 \n",
      " loss = 0.3649 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8910 \n",
      " loss = 0.3646 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8909 \n",
      " loss = 0.3648 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8910 \n",
      " loss = 0.3645 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8911 \n",
      " loss = 0.3642 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8912 \n",
      " loss = 0.3637 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8913 \n",
      " loss = 0.3636 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8914 \n",
      " loss = 0.3633 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8913 \n",
      " loss = 0.3635 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8914 \n",
      " loss = 0.3632 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8915 \n",
      " loss = 0.3629 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8915 \n",
      " loss = 0.3627 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8916 \n",
      " loss = 0.3623 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8917 \n",
      " loss = 0.3620 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8917 \n",
      " loss = 0.3619 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8918 \n",
      " loss = 0.3616 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8919 \n",
      " loss = 0.3614 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8919 \n",
      " loss = 0.3612 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8918 \n",
      " loss = 0.3613 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8919 \n",
      " loss = 0.3611 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8919 \n",
      " loss = 0.3611 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8920 \n",
      " loss = 0.3609 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8920 \n",
      " loss = 0.3609 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8921 \n",
      " loss = 0.3606 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8922 \n",
      " loss = 0.3602 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8922 \n",
      " loss = 0.3601 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8922 \n",
      " loss = 0.3599 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8924 \n",
      " loss = 0.3594 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8925 \n",
      " loss = 0.3592 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8926 \n",
      " loss = 0.3589 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8926 \n",
      " loss = 0.3586 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8926 \n",
      " loss = 0.3589 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8926 \n",
      " loss = 0.3587 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8927 \n",
      " loss = 0.3585 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8927 \n",
      " loss = 0.3584 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8928 \n",
      " loss = 0.3583 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8929 \n",
      " loss = 0.3579 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8930 \n",
      " loss = 0.3578 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8931 \n",
      " loss = 0.3575 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8932 \n",
      " loss = 0.3572 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8932 \n",
      " loss = 0.3570 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8932 \n",
      " loss = 0.3569 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8933 \n",
      " loss = 0.3568 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8933 \n",
      " loss = 0.3566 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8933 \n",
      " loss = 0.3566 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8933 \n",
      " loss = 0.3566 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8933 \n",
      " loss = 0.3564 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8934 \n",
      " loss = 0.3562 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8935 \n",
      " loss = 0.3558 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8936 \n",
      " loss = 0.3556 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8936 \n",
      " loss = 0.3556 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8936 \n",
      " loss = 0.3556 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8937 \n",
      " loss = 0.3553 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8936 \n",
      " loss = 0.3555 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8936 \n",
      " loss = 0.3553 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8937 \n",
      " loss = 0.3553 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8937 \n",
      " loss = 0.3551 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8936 \n",
      " loss = 0.3550 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8935 \n",
      " loss = 0.3554 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8936 \n",
      " loss = 0.3553 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8936 \n",
      " loss = 0.3552 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8936 \n",
      " loss = 0.3557 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8936 \n",
      " loss = 0.3560 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8935 \n",
      " loss = 0.3559 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8936 \n",
      " loss = 0.3559 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8936 \n",
      " loss = 0.3557 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8936 \n",
      " loss = 0.3556 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8936 \n",
      " loss = 0.3557 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8936 \n",
      " loss = 0.3555 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8938 \n",
      " loss = 0.3552 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8939 \n",
      " loss = 0.3549 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8939 \n",
      " loss = 0.3547 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8939 \n",
      " loss = 0.3548 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8939 \n",
      " loss = 0.3546 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8940 \n",
      " loss = 0.3543 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8940 \n",
      " loss = 0.3548 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8940 \n",
      " loss = 0.3545 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8941 \n",
      " loss = 0.3542 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8941 \n",
      " loss = 0.3541 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8942 \n",
      " loss = 0.3538 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8942 \n",
      " loss = 0.3537 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8943 \n",
      " loss = 0.3537 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8943 \n",
      " loss = 0.3534 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8945 \n",
      " loss = 0.3531 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8946 \n",
      " loss = 0.3527 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8947 \n",
      " loss = 0.3524 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8948 \n",
      " loss = 0.3522 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8948 \n",
      " loss = 0.3520 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8948 \n",
      " loss = 0.3519 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8949 \n",
      " loss = 0.3518 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8949 \n",
      " loss = 0.3517 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8949 \n",
      " loss = 0.3516 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8949 \n",
      " loss = 0.3517 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8950 \n",
      " loss = 0.3516 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8951 \n",
      " loss = 0.3512 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8952 \n",
      " loss = 0.3509 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8953 \n",
      " loss = 0.3506 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8953 \n",
      " loss = 0.3507 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8954 \n",
      " loss = 0.3504 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8953 \n",
      " loss = 0.3506 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8954 \n",
      " loss = 0.3504 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8954 \n",
      " loss = 0.3503 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8953 \n",
      " loss = 0.3504 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8954 \n",
      " loss = 0.3501 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8955 \n",
      " loss = 0.3501 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8955 \n",
      " loss = 0.3501 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8956 \n",
      " loss = 0.3498 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8957 \n",
      " loss = 0.3494 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8958 \n",
      " loss = 0.3491 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8958 \n",
      " loss = 0.3490 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8959 \n",
      " loss = 0.3487 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8959 \n",
      " loss = 0.3486 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8960 \n",
      " loss = 0.3482 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8961 \n",
      " loss = 0.3482 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8962 \n",
      " loss = 0.3478 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8962 \n",
      " loss = 0.3476 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8963 \n",
      " loss = 0.3474 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8963 \n",
      " loss = 0.3473 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8964 \n",
      " loss = 0.3474 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8964 \n",
      " loss = 0.3472 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8964 \n",
      " loss = 0.3471 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8964 \n",
      " loss = 0.3470 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8964 \n",
      " loss = 0.3474 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8964 \n",
      " loss = 0.3472 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8964 \n",
      " loss = 0.3471 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8964 \n",
      " loss = 0.3471 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8965 \n",
      " loss = 0.3467 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8966 \n",
      " loss = 0.3466 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8966 \n",
      " loss = 0.3463 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8967 \n",
      " loss = 0.3463 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8967 \n",
      " loss = 0.3460 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8967 \n",
      " loss = 0.3459 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8967 \n",
      " loss = 0.3460 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8968 \n",
      " loss = 0.3457 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8969 \n",
      " loss = 0.3455 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8969 \n",
      " loss = 0.3454 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8970 \n",
      " loss = 0.3453 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8970 \n",
      " loss = 0.3451 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8971 \n",
      " loss = 0.3448 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8972 \n",
      " loss = 0.3446 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8973 \n",
      " loss = 0.3443 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8972 \n",
      " loss = 0.3444 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8972 \n",
      " loss = 0.3443 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8973 \n",
      " loss = 0.3442 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8972 \n",
      " loss = 0.3440 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8973 \n",
      " loss = 0.3439 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8973 \n",
      " loss = 0.3437 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8973 \n",
      " loss = 0.3436 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8974 \n",
      " loss = 0.3434 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8974 \n",
      " loss = 0.3432 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8975 \n",
      " loss = 0.3430 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8976 \n",
      " loss = 0.3427 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8976 \n",
      " loss = 0.3424 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8976 \n",
      " loss = 0.3423 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8977 \n",
      " loss = 0.3420 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8977 \n",
      " loss = 0.3421 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8978 \n",
      " loss = 0.3418 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8979 \n",
      " loss = 0.3417 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8979 \n",
      " loss = 0.3418 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8980 \n",
      " loss = 0.3416 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8980 \n",
      " loss = 0.3415 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8980 \n",
      " loss = 0.3413 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8981 \n",
      " loss = 0.3410 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8981 \n",
      " loss = 0.3411 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8981 \n",
      " loss = 0.3410 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8982 \n",
      " loss = 0.3408 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8982 \n",
      " loss = 0.3406 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8983 \n",
      " loss = 0.3407 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8983 \n",
      " loss = 0.3404 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8984 \n",
      " loss = 0.3402 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8985 \n",
      " loss = 0.3400 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8985 \n",
      " loss = 0.3399 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8986 \n",
      " loss = 0.3396 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8987 \n",
      " loss = 0.3394 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8987 \n",
      " loss = 0.3393 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8987 \n",
      " loss = 0.3394 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8988 \n",
      " loss = 0.3392 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8988 \n",
      " loss = 0.3392 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8988 \n",
      " loss = 0.3391 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8989 \n",
      " loss = 0.3388 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8989 \n",
      " loss = 0.3387 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8989 \n",
      " loss = 0.3386 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8989 \n",
      " loss = 0.3383 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8989 \n",
      " loss = 0.3385 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8989 \n",
      " loss = 0.3384 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8989 \n",
      " loss = 0.3385 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8989 \n",
      " loss = 0.3384 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8989 \n",
      " loss = 0.3383 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8989 \n",
      " loss = 0.3386 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8989 \n",
      " loss = 0.3385 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8988 \n",
      " loss = 0.3385 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8989 \n",
      " loss = 0.3385 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8988 \n",
      " loss = 0.3384 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8988 \n",
      " loss = 0.3382 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8989 \n",
      " loss = 0.3381 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8990 \n",
      " loss = 0.3378 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8991 \n",
      " loss = 0.3376 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8991 \n",
      " loss = 0.3374 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8992 \n",
      " loss = 0.3371 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8993 \n",
      " loss = 0.3369 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8992 \n",
      " loss = 0.3368 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8993 \n",
      " loss = 0.3365 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8994 \n",
      " loss = 0.3363 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8993 \n",
      " loss = 0.3364 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8993 \n",
      " loss = 0.3363 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8993 \n",
      " loss = 0.3362 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8994 \n",
      " loss = 0.3362 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8994 \n",
      " loss = 0.3360 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8995 \n",
      " loss = 0.3359 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8995 \n",
      " loss = 0.3358 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8995 \n",
      " loss = 0.3357 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8996 \n",
      " loss = 0.3355 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8996 \n",
      " loss = 0.3354 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8996 \n",
      " loss = 0.3352 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8997 \n",
      " loss = 0.3349 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8998 \n",
      " loss = 0.3347 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8998 \n",
      " loss = 0.3346 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8998 \n",
      " loss = 0.3347 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8998 \n",
      " loss = 0.3346 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8998 \n",
      " loss = 0.3349 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8998 \n",
      " loss = 0.3349 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8997 \n",
      " loss = 0.3354 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8998 \n",
      " loss = 0.3353 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8998 \n",
      " loss = 0.3352 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8999 \n",
      " loss = 0.3349 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8999 \n",
      " loss = 0.3347 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8999 \n",
      " loss = 0.3347 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8998 \n",
      " loss = 0.3347 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8999 \n",
      " loss = 0.3345 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8999 \n",
      " loss = 0.3343 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.8999 \n",
      " loss = 0.3344 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9000 \n",
      " loss = 0.3343 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9000 \n",
      " loss = 0.3343 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9000 \n",
      " loss = 0.3343 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9001 \n",
      " loss = 0.3341 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9001 \n",
      " loss = 0.3343 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9000 \n",
      " loss = 0.3345 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9001 \n",
      " loss = 0.3344 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9001 \n",
      " loss = 0.3343 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9001 \n",
      " loss = 0.3341 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9001 \n",
      " loss = 0.3341 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9002 \n",
      " loss = 0.3339 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9002 \n",
      " loss = 0.3338 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9001 \n",
      " loss = 0.3341 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9001 \n",
      " loss = 0.3339 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9002 \n",
      " loss = 0.3338 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9002 \n",
      " loss = 0.3335 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9003 \n",
      " loss = 0.3332 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9003 \n",
      " loss = 0.3331 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9004 \n",
      " loss = 0.3328 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9005 \n",
      " loss = 0.3326 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9005 \n",
      " loss = 0.3323 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9006 \n",
      " loss = 0.3321 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9006 \n",
      " loss = 0.3320 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9006 \n",
      " loss = 0.3321 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9007 \n",
      " loss = 0.3318 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9007 \n",
      " loss = 0.3316 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9008 \n",
      " loss = 0.3316 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9008 \n",
      " loss = 0.3314 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9009 \n",
      " loss = 0.3312 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9010 \n",
      " loss = 0.3310 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9010 \n",
      " loss = 0.3308 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9010 \n",
      " loss = 0.3308 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9011 \n",
      " loss = 0.3305 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9012 \n",
      " loss = 0.3303 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9012 \n",
      " loss = 0.3304 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9012 \n",
      " loss = 0.3303 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9013 \n",
      " loss = 0.3301 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9013 \n",
      " loss = 0.3301 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9014 \n",
      " loss = 0.3299 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9014 \n",
      " loss = 0.3296 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9014 \n",
      " loss = 0.3296 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9014 \n",
      " loss = 0.3294 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9015 \n",
      " loss = 0.3293 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9016 \n",
      " loss = 0.3290 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9016 \n",
      " loss = 0.3288 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9016 \n",
      " loss = 0.3288 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9016 \n",
      " loss = 0.3286 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9016 \n",
      " loss = 0.3286 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9017 \n",
      " loss = 0.3285 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9017 \n",
      " loss = 0.3285 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9018 \n",
      " loss = 0.3283 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9018 \n",
      " loss = 0.3285 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9018 \n",
      " loss = 0.3284 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9018 \n",
      " loss = 0.3281 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9019 \n",
      " loss = 0.3279 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9020 \n",
      " loss = 0.3277 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9021 \n",
      " loss = 0.3274 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9021 \n",
      " loss = 0.3272 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9022 \n",
      " loss = 0.3270 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9022 \n",
      " loss = 0.3269 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9023 \n",
      " loss = 0.3268 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9023 \n",
      " loss = 0.3267 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9024 \n",
      " loss = 0.3264 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9024 \n",
      " loss = 0.3262 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9024 \n",
      " loss = 0.3267 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9024 \n",
      " loss = 0.3266 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9024 \n",
      " loss = 0.3264 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9024 \n",
      " loss = 0.3265 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9024 \n",
      " loss = 0.3264 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9024 \n",
      " loss = 0.3263 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9025 \n",
      " loss = 0.3263 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9025 \n",
      " loss = 0.3263 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9026 \n",
      " loss = 0.3261 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9026 \n",
      " loss = 0.3261 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9026 \n",
      " loss = 0.3259 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9026 \n",
      " loss = 0.3258 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9026 \n",
      " loss = 0.3258 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9027 \n",
      " loss = 0.3256 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9028 \n",
      " loss = 0.3253 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9028 \n",
      " loss = 0.3251 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9029 \n",
      " loss = 0.3249 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9029 \n",
      " loss = 0.3249 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9029 \n",
      " loss = 0.3249 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9029 \n",
      " loss = 0.3249 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9029 \n",
      " loss = 0.3249 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9028 \n",
      " loss = 0.3249 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9029 \n",
      " loss = 0.3248 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9029 \n",
      " loss = 0.3249 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9029 \n",
      " loss = 0.3248 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9029 \n",
      " loss = 0.3246 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9030 \n",
      " loss = 0.3244 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9030 \n",
      " loss = 0.3243 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9030 \n",
      " loss = 0.3242 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9030 \n",
      " loss = 0.3246 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9030 \n",
      " loss = 0.3244 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9030 \n",
      " loss = 0.3244 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9030 \n",
      " loss = 0.3244 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9030 \n",
      " loss = 0.3244 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9030 \n",
      " loss = 0.3242 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9031 \n",
      " loss = 0.3241 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9031 \n",
      " loss = 0.3240 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9031 \n",
      " loss = 0.3238 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9031 \n",
      " loss = 0.3239 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9031 \n",
      " loss = 0.3239 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9031 \n",
      " loss = 0.3237 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9031 \n",
      " loss = 0.3237 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9032 \n",
      " loss = 0.3234 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9032 \n",
      " loss = 0.3236 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9031 \n",
      " loss = 0.3237 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9031 \n",
      " loss = 0.3238 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9031 \n",
      " loss = 0.3237 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9031 \n",
      " loss = 0.3238 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9031 \n",
      " loss = 0.3239 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9031 \n",
      " loss = 0.3241 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9032 \n",
      " loss = 0.3238 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9033 \n",
      " loss = 0.3236 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9034 \n",
      " loss = 0.3234 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9034 \n",
      " loss = 0.3232 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9035 \n",
      " loss = 0.3231 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9035 \n",
      " loss = 0.3229 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9036 \n",
      " loss = 0.3227 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9036 \n",
      " loss = 0.3226 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9036 \n",
      " loss = 0.3227 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9036 \n",
      " loss = 0.3225 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9037 \n",
      " loss = 0.3224 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9037 \n",
      " loss = 0.3222 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9038 \n",
      " loss = 0.3220 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9038 \n",
      " loss = 0.3218 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9039 \n",
      " loss = 0.3216 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9039 \n",
      " loss = 0.3214 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9040 \n",
      " loss = 0.3212 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9040 \n",
      " loss = 0.3211 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9041 \n",
      " loss = 0.3210 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9041 \n",
      " loss = 0.3208 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9041 \n",
      " loss = 0.3206 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9042 \n",
      " loss = 0.3204 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9042 \n",
      " loss = 0.3203 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9043 \n",
      " loss = 0.3201 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9042 \n",
      " loss = 0.3203 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9042 \n",
      " loss = 0.3202 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9042 \n",
      " loss = 0.3201 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9042 \n",
      " loss = 0.3202 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9043 \n",
      " loss = 0.3201 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9043 \n",
      " loss = 0.3201 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9043 \n",
      " loss = 0.3200 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9044 \n",
      " loss = 0.3198 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9044 \n",
      " loss = 0.3199 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9044 \n",
      " loss = 0.3197 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9044 \n",
      " loss = 0.3196 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9044 \n",
      " loss = 0.3198 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9044 \n",
      " loss = 0.3197 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9044 \n",
      " loss = 0.3195 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9044 \n",
      " loss = 0.3196 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9045 \n",
      " loss = 0.3194 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9045 \n",
      " loss = 0.3195 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9045 \n",
      " loss = 0.3194 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9046 \n",
      " loss = 0.3191 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9046 \n",
      " loss = 0.3189 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9047 \n",
      " loss = 0.3187 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9047 \n",
      " loss = 0.3187 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9046 \n",
      " loss = 0.3189 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9046 \n",
      " loss = 0.3188 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9047 \n",
      " loss = 0.3186 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9047 \n",
      " loss = 0.3185 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9048 \n",
      " loss = 0.3184 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9047 \n",
      " loss = 0.3185 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9048 \n",
      " loss = 0.3182 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9048 \n",
      " loss = 0.3181 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9049 \n",
      " loss = 0.3178 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9050 \n",
      " loss = 0.3176 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9050 \n",
      " loss = 0.3175 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9051 \n",
      " loss = 0.3174 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9051 \n",
      " loss = 0.3172 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9051 \n",
      " loss = 0.3173 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9051 \n",
      " loss = 0.3174 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9052 \n",
      " loss = 0.3171 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9052 \n",
      " loss = 0.3169 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9053 \n",
      " loss = 0.3168 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9053 \n",
      " loss = 0.3169 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9053 \n",
      " loss = 0.3167 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9053 \n",
      " loss = 0.3167 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9053 \n",
      " loss = 0.3165 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9053 \n",
      " loss = 0.3166 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9053 \n",
      " loss = 0.3165 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9054 \n",
      " loss = 0.3164 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9054 \n",
      " loss = 0.3161 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9055 \n",
      " loss = 0.3159 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9056 \n",
      " loss = 0.3157 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9056 \n",
      " loss = 0.3155 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9056 \n",
      " loss = 0.3154 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9056 \n",
      " loss = 0.3154 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9056 \n",
      " loss = 0.3154 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9056 \n",
      " loss = 0.3157 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9056 \n",
      " loss = 0.3157 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9056 \n",
      " loss = 0.3158 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9055 \n",
      " loss = 0.3159 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9056 \n",
      " loss = 0.3157 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9056 \n",
      " loss = 0.3156 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9056 \n",
      " loss = 0.3154 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9056 \n",
      " loss = 0.3153 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9056 \n",
      " loss = 0.3153 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9056 \n",
      " loss = 0.3153 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9057 \n",
      " loss = 0.3151 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9057 \n",
      " loss = 0.3150 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9058 \n",
      " loss = 0.3148 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9058 \n",
      " loss = 0.3146 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9059 \n",
      " loss = 0.3144 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9059 \n",
      " loss = 0.3143 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9059 \n",
      " loss = 0.3142 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9058 \n",
      " loss = 0.3145 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9058 \n",
      " loss = 0.3146 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9059 \n",
      " loss = 0.3146 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9059 \n",
      " loss = 0.3147 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9059 \n",
      " loss = 0.3145 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9059 \n",
      " loss = 0.3145 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9059 \n",
      " loss = 0.3144 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9060 \n",
      " loss = 0.3144 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9060 \n",
      " loss = 0.3142 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9061 \n",
      " loss = 0.3140 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9061 \n",
      " loss = 0.3139 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9061 \n",
      " loss = 0.3138 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9061 \n",
      " loss = 0.3143 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9061 \n",
      " loss = 0.3142 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9062 \n",
      " loss = 0.3141 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9062 \n",
      " loss = 0.3140 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9063 \n",
      " loss = 0.3138 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9063 \n",
      " loss = 0.3136 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9062 \n",
      " loss = 0.3137 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9063 \n",
      " loss = 0.3136 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9063 \n",
      " loss = 0.3134 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9064 \n",
      " loss = 0.3132 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9064 \n",
      " loss = 0.3132 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9063 \n",
      " loss = 0.3135 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9064 \n",
      " loss = 0.3133 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9064 \n",
      " loss = 0.3132 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9064 \n",
      " loss = 0.3132 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9063 \n",
      " loss = 0.3134 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9062 \n",
      " loss = 0.3136 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9062 \n",
      " loss = 0.3138 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9063 \n",
      " loss = 0.3136 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9063 \n",
      " loss = 0.3134 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9063 \n",
      " loss = 0.3137 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9064 \n",
      " loss = 0.3138 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9064 \n",
      " loss = 0.3137 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9064 \n",
      " loss = 0.3137 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9065 \n",
      " loss = 0.3135 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9065 \n",
      " loss = 0.3133 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9066 \n",
      " loss = 0.3133 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9066 \n",
      " loss = 0.3132 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9066 \n",
      " loss = 0.3131 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9066 \n",
      " loss = 0.3130 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9067 \n",
      " loss = 0.3128 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9067 \n",
      " loss = 0.3126 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9068 \n",
      " loss = 0.3125 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9068 \n",
      " loss = 0.3123 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9069 \n",
      " loss = 0.3121 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9070 \n",
      " loss = 0.3119 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9070 \n",
      " loss = 0.3117 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9071 \n",
      " loss = 0.3114 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9071 \n",
      " loss = 0.3113 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9072 \n",
      " loss = 0.3111 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9072 \n",
      " loss = 0.3110 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9073 \n",
      " loss = 0.3109 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9073 \n",
      " loss = 0.3107 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9074 \n",
      " loss = 0.3106 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9074 \n",
      " loss = 0.3107 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9074 \n",
      " loss = 0.3105 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9074 \n",
      " loss = 0.3104 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9075 \n",
      " loss = 0.3102 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9075 \n",
      " loss = 0.3101 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9075 \n",
      " loss = 0.3101 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9076 \n",
      " loss = 0.3100 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9076 \n",
      " loss = 0.3099 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9076 \n",
      " loss = 0.3098 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9077 \n",
      " loss = 0.3096 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9077 \n",
      " loss = 0.3096 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9078 \n",
      " loss = 0.3094 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9078 \n",
      " loss = 0.3092 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9078 \n",
      " loss = 0.3091 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9078 \n",
      " loss = 0.3092 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9079 \n",
      " loss = 0.3093 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9079 \n",
      " loss = 0.3091 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9080 \n",
      " loss = 0.3089 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9081 \n",
      " loss = 0.3088 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9081 \n",
      " loss = 0.3086 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9081 \n",
      " loss = 0.3085 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9081 \n",
      " loss = 0.3084 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9081 \n",
      " loss = 0.3086 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9081 \n",
      " loss = 0.3084 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9081 \n",
      " loss = 0.3083 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9080 \n",
      " loss = 0.3085 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9080 \n",
      " loss = 0.3086 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9079 \n",
      " loss = 0.3087 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9080 \n",
      " loss = 0.3085 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9080 \n",
      " loss = 0.3086 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9080 \n",
      " loss = 0.3086 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9080 \n",
      " loss = 0.3085 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9080 \n",
      " loss = 0.3085 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9081 \n",
      " loss = 0.3083 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9080 \n",
      " loss = 0.3083 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9081 \n",
      " loss = 0.3081 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9081 \n",
      " loss = 0.3080 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9082 \n",
      " loss = 0.3079 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9082 \n",
      " loss = 0.3077 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9082 \n",
      " loss = 0.3076 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9082 \n",
      " loss = 0.3074 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9083 \n",
      " loss = 0.3072 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9083 \n",
      " loss = 0.3071 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9083 \n",
      " loss = 0.3072 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9083 \n",
      " loss = 0.3071 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9083 \n",
      " loss = 0.3071 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9084 \n",
      " loss = 0.3069 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9084 \n",
      " loss = 0.3070 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9084 \n",
      " loss = 0.3068 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9084 \n",
      " loss = 0.3068 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9084 \n",
      " loss = 0.3069 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9083 \n",
      " loss = 0.3073 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9083 \n",
      " loss = 0.3074 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9083 \n",
      " loss = 0.3075 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9084 \n",
      " loss = 0.3073 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9084 \n",
      " loss = 0.3072 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9085 \n",
      " loss = 0.3070 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9085 \n",
      " loss = 0.3069 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9085 \n",
      " loss = 0.3069 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9086 \n",
      " loss = 0.3068 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9086 \n",
      " loss = 0.3068 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9087 \n",
      " loss = 0.3065 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9087 \n",
      " loss = 0.3064 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9087 \n",
      " loss = 0.3063 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9088 \n",
      " loss = 0.3061 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9089 \n",
      " loss = 0.3059 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9089 \n",
      " loss = 0.3057 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9090 \n",
      " loss = 0.3055 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9090 \n",
      " loss = 0.3056 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9090 \n",
      " loss = 0.3055 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9091 \n",
      " loss = 0.3053 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9090 \n",
      " loss = 0.3055 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9091 \n",
      " loss = 0.3054 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9091 \n",
      " loss = 0.3053 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9092 \n",
      " loss = 0.3052 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9092 \n",
      " loss = 0.3051 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9092 \n",
      " loss = 0.3051 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9092 \n",
      " loss = 0.3050 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9092 \n",
      " loss = 0.3049 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9093 \n",
      " loss = 0.3047 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9093 \n",
      " loss = 0.3047 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9093 \n",
      " loss = 0.3048 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9093 \n",
      " loss = 0.3047 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9094 \n",
      " loss = 0.3046 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9093 \n",
      " loss = 0.3048 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9094 \n",
      " loss = 0.3047 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9094 \n",
      " loss = 0.3046 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9094 \n",
      " loss = 0.3044 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9094 \n",
      " loss = 0.3044 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9095 \n",
      " loss = 0.3042 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9094 \n",
      " loss = 0.3044 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9095 \n",
      " loss = 0.3042 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9095 \n",
      " loss = 0.3041 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9096 \n",
      " loss = 0.3039 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9096 \n",
      " loss = 0.3039 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9097 \n",
      " loss = 0.3037 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9097 \n",
      " loss = 0.3037 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9097 \n",
      " loss = 0.3036 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9098 \n",
      " loss = 0.3034 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9098 \n",
      " loss = 0.3032 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9098 \n",
      " loss = 0.3032 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9099 \n",
      " loss = 0.3031 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9099 \n",
      " loss = 0.3030 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9099 \n",
      " loss = 0.3030 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9100 \n",
      " loss = 0.3028 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9100 \n",
      " loss = 0.3027 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9100 \n",
      " loss = 0.3026 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9101 \n",
      " loss = 0.3024 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9101 \n",
      " loss = 0.3022 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9101 \n",
      " loss = 0.3022 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9102 \n",
      " loss = 0.3022 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9101 \n",
      " loss = 0.3021 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9101 \n",
      " loss = 0.3022 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9101 \n",
      " loss = 0.3023 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9101 \n",
      " loss = 0.3024 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9101 \n",
      " loss = 0.3023 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9101 \n",
      " loss = 0.3022 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9101 \n",
      " loss = 0.3021 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9102 \n",
      " loss = 0.3019 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9102 \n",
      " loss = 0.3018 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9102 \n",
      " loss = 0.3017 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9103 \n",
      " loss = 0.3016 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9103 \n",
      " loss = 0.3018 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9103 \n",
      " loss = 0.3016 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9104 \n",
      " loss = 0.3015 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9104 \n",
      " loss = 0.3014 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9104 \n",
      " loss = 0.3015 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9104 \n",
      " loss = 0.3013 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9105 \n",
      " loss = 0.3011 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9105 \n",
      " loss = 0.3011 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9105 \n",
      " loss = 0.3009 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9105 \n",
      " loss = 0.3008 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9105 \n",
      " loss = 0.3008 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9106 \n",
      " loss = 0.3006 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9106 \n",
      " loss = 0.3004 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9107 \n",
      " loss = 0.3003 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9107 \n",
      " loss = 0.3001 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9108 \n",
      " loss = 0.2999 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9108 \n",
      " loss = 0.2998 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9108 \n",
      " loss = 0.3000 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9108 \n",
      " loss = 0.2998 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9108 \n",
      " loss = 0.2998 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9109 \n",
      " loss = 0.2997 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9109 \n",
      " loss = 0.2997 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9109 \n",
      " loss = 0.2998 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9110 \n",
      " loss = 0.2996 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9110 \n",
      " loss = 0.2994 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9110 \n",
      " loss = 0.2994 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9111 \n",
      " loss = 0.2992 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9111 \n",
      " loss = 0.2991 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9111 \n",
      " loss = 0.2990 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9112 \n",
      " loss = 0.2988 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9113 \n",
      " loss = 0.2986 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9113 \n",
      " loss = 0.2985 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9112 \n",
      " loss = 0.2987 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9113 \n",
      " loss = 0.2986 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9113 \n",
      " loss = 0.2985 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9114 \n",
      " loss = 0.2983 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9114 \n",
      " loss = 0.2982 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9114 \n",
      " loss = 0.2982 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9114 \n",
      " loss = 0.2981 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9114 \n",
      " loss = 0.2981 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9114 \n",
      " loss = 0.2983 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9115 \n",
      " loss = 0.2981 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9115 \n",
      " loss = 0.2980 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9115 \n",
      " loss = 0.2979 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9115 \n",
      " loss = 0.2979 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9115 \n",
      " loss = 0.2978 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9115 \n",
      " loss = 0.2977 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9115 \n",
      " loss = 0.2976 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9116 \n",
      " loss = 0.2974 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9116 \n",
      " loss = 0.2973 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9117 \n",
      " loss = 0.2972 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9117 \n",
      " loss = 0.2971 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9118 \n",
      " loss = 0.2969 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9118 \n",
      " loss = 0.2967 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9118 \n",
      " loss = 0.2966 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9119 \n",
      " loss = 0.2965 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9119 \n",
      " loss = 0.2963 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9119 \n",
      " loss = 0.2962 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9119 \n",
      " loss = 0.2962 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9120 \n",
      " loss = 0.2961 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9120 \n",
      " loss = 0.2960 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9121 \n",
      " loss = 0.2958 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9122 \n",
      " loss = 0.2956 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9122 \n",
      " loss = 0.2955 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9122 \n",
      " loss = 0.2953 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9122 \n",
      " loss = 0.2953 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9123 \n",
      " loss = 0.2952 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9123 \n",
      " loss = 0.2952 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9123 \n",
      " loss = 0.2950 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9123 \n",
      " loss = 0.2949 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9124 \n",
      " loss = 0.2947 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9124 \n",
      " loss = 0.2947 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9124 \n",
      " loss = 0.2946 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9124 \n",
      " loss = 0.2946 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9125 \n",
      " loss = 0.2944 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9125 \n",
      " loss = 0.2943 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9125 \n",
      " loss = 0.2942 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9125 \n",
      " loss = 0.2943 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9126 \n",
      " loss = 0.2942 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9125 \n",
      " loss = 0.2944 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9126 \n",
      " loss = 0.2942 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9126 \n",
      " loss = 0.2940 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9126 \n",
      " loss = 0.2940 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9127 \n",
      " loss = 0.2938 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9128 \n",
      " loss = 0.2936 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9128 \n",
      " loss = 0.2935 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9129 \n",
      " loss = 0.2933 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9129 \n",
      " loss = 0.2932 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9130 \n",
      " loss = 0.2930 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9129 \n",
      " loss = 0.2930 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9129 \n",
      " loss = 0.2929 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9130 \n",
      " loss = 0.2928 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9130 \n",
      " loss = 0.2927 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9131 \n",
      " loss = 0.2926 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9131 \n",
      " loss = 0.2924 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9132 \n",
      " loss = 0.2922 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9132 \n",
      " loss = 0.2921 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9132 \n",
      " loss = 0.2919 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9133 \n",
      " loss = 0.2918 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9133 \n",
      " loss = 0.2916 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9134 \n",
      " loss = 0.2915 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9134 \n",
      " loss = 0.2913 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9135 \n",
      " loss = 0.2912 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9135 \n",
      " loss = 0.2910 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9135 \n",
      " loss = 0.2909 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9135 \n",
      " loss = 0.2908 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9136 \n",
      " loss = 0.2907 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9136 \n",
      " loss = 0.2905 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9136 \n",
      " loss = 0.2904 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9137 \n",
      " loss = 0.2902 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9138 \n",
      " loss = 0.2901 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9138 \n",
      " loss = 0.2899 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9138 \n",
      " loss = 0.2898 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9138 \n",
      " loss = 0.2898 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9138 \n",
      " loss = 0.2898 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9139 \n",
      " loss = 0.2897 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9139 \n",
      " loss = 0.2896 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9140 \n",
      " loss = 0.2894 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9140 \n",
      " loss = 0.2892 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9141 \n",
      " loss = 0.2890 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9141 \n",
      " loss = 0.2889 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9142 \n",
      " loss = 0.2887 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9142 \n",
      " loss = 0.2885 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9143 \n",
      " loss = 0.2883 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9143 \n",
      " loss = 0.2881 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9144 \n",
      " loss = 0.2880 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9144 \n",
      " loss = 0.2878 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9145 \n",
      " loss = 0.2876 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9144 \n",
      " loss = 0.2879 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9145 \n",
      " loss = 0.2878 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9144 \n",
      " loss = 0.2879 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9144 \n",
      " loss = 0.2878 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9144 \n",
      " loss = 0.2878 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9145 \n",
      " loss = 0.2876 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9145 \n",
      " loss = 0.2874 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9146 \n",
      " loss = 0.2873 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9146 \n",
      " loss = 0.2871 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9146 \n",
      " loss = 0.2869 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9147 \n",
      " loss = 0.2868 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9147 \n",
      " loss = 0.2867 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9148 \n",
      " loss = 0.2865 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9147 \n",
      " loss = 0.2873 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9147 \n",
      " loss = 0.2875 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9147 \n",
      " loss = 0.2874 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9148 \n",
      " loss = 0.2872 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9148 \n",
      " loss = 0.2870 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9149 \n",
      " loss = 0.2869 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9149 \n",
      " loss = 0.2872 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9149 \n",
      " loss = 0.2871 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9150 \n",
      " loss = 0.2869 \n",
      "Results at at the end of epoch 0\n",
      " sparse_categorical_accuracy = 0.9150 \n",
      " loss = 0.2867 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 1.0000 \n",
      " loss = 0.0240 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9688 \n",
      " loss = 0.0658 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9479 \n",
      " loss = 0.1522 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9531 \n",
      " loss = 0.1671 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9375 \n",
      " loss = 0.2047 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9375 \n",
      " loss = 0.2221 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9286 \n",
      " loss = 0.3002 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9297 \n",
      " loss = 0.2819 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9306 \n",
      " loss = 0.2920 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9344 \n",
      " loss = 0.2856 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9375 \n",
      " loss = 0.2633 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9375 \n",
      " loss = 0.2714 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9399 \n",
      " loss = 0.2535 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9375 \n",
      " loss = 0.2556 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9417 \n",
      " loss = 0.2401 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9453 \n",
      " loss = 0.2285 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9485 \n",
      " loss = 0.2160 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9497 \n",
      " loss = 0.2089 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1999 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9516 \n",
      " loss = 0.1934 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1933 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9545 \n",
      " loss = 0.1856 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9538 \n",
      " loss = 0.1856 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9505 \n",
      " loss = 0.1970 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9500 \n",
      " loss = 0.1953 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9507 \n",
      " loss = 0.1907 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9502 \n",
      " loss = 0.1943 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9498 \n",
      " loss = 0.1920 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9515 \n",
      " loss = 0.1858 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9510 \n",
      " loss = 0.1844 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1801 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9531 \n",
      " loss = 0.1816 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9536 \n",
      " loss = 0.1819 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9540 \n",
      " loss = 0.1787 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9545 \n",
      " loss = 0.1766 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9549 \n",
      " loss = 0.1744 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9561 \n",
      " loss = 0.1709 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9539 \n",
      " loss = 0.1766 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9551 \n",
      " loss = 0.1737 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9563 \n",
      " loss = 0.1700 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9566 \n",
      " loss = 0.1678 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9576 \n",
      " loss = 0.1647 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9578 \n",
      " loss = 0.1626 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9574 \n",
      " loss = 0.1623 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9583 \n",
      " loss = 0.1593 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9579 \n",
      " loss = 0.1585 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9574 \n",
      " loss = 0.1600 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9577 \n",
      " loss = 0.1600 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9573 \n",
      " loss = 0.1600 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9550 \n",
      " loss = 0.1684 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9547 \n",
      " loss = 0.1692 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1733 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9534 \n",
      " loss = 0.1711 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1766 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1757 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1755 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1749 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9515 \n",
      " loss = 0.1757 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9502 \n",
      " loss = 0.1804 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9510 \n",
      " loss = 0.1777 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1807 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9511 \n",
      " loss = 0.1778 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9509 \n",
      " loss = 0.1774 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9502 \n",
      " loss = 0.1792 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9500 \n",
      " loss = 0.1813 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9508 \n",
      " loss = 0.1786 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9515 \n",
      " loss = 0.1770 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9517 \n",
      " loss = 0.1754 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9515 \n",
      " loss = 0.1763 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9509 \n",
      " loss = 0.1784 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9511 \n",
      " loss = 0.1775 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9501 \n",
      " loss = 0.1800 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1790 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9506 \n",
      " loss = 0.1778 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9492 \n",
      " loss = 0.1794 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9490 \n",
      " loss = 0.1782 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9497 \n",
      " loss = 0.1766 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9495 \n",
      " loss = 0.1779 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9490 \n",
      " loss = 0.1802 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9484 \n",
      " loss = 0.1840 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9483 \n",
      " loss = 0.1844 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9470 \n",
      " loss = 0.1899 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9462 \n",
      " loss = 0.1979 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9457 \n",
      " loss = 0.2016 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9456 \n",
      " loss = 0.2031 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9459 \n",
      " loss = 0.2022 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9465 \n",
      " loss = 0.2008 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9464 \n",
      " loss = 0.2001 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9459 \n",
      " loss = 0.2002 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9462 \n",
      " loss = 0.1991 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9468 \n",
      " loss = 0.1978 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9470 \n",
      " loss = 0.1973 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9466 \n",
      " loss = 0.1969 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9468 \n",
      " loss = 0.1965 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9461 \n",
      " loss = 0.1982 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9466 \n",
      " loss = 0.1963 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9459 \n",
      " loss = 0.1979 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9458 \n",
      " loss = 0.1970 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9454 \n",
      " loss = 0.1980 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9450 \n",
      " loss = 0.1983 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9455 \n",
      " loss = 0.1965 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9458 \n",
      " loss = 0.1983 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9463 \n",
      " loss = 0.1966 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9468 \n",
      " loss = 0.1952 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9467 \n",
      " loss = 0.1948 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9469 \n",
      " loss = 0.1947 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9466 \n",
      " loss = 0.1947 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9462 \n",
      " loss = 0.1954 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9467 \n",
      " loss = 0.1937 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9469 \n",
      " loss = 0.1937 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9468 \n",
      " loss = 0.1943 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9473 \n",
      " loss = 0.1927 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9477 \n",
      " loss = 0.1911 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9479 \n",
      " loss = 0.1902 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9476 \n",
      " loss = 0.1931 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9472 \n",
      " loss = 0.1933 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9468 \n",
      " loss = 0.1933 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9468 \n",
      " loss = 0.1935 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9470 \n",
      " loss = 0.1931 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9471 \n",
      " loss = 0.1924 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9473 \n",
      " loss = 0.1919 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9475 \n",
      " loss = 0.1908 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9472 \n",
      " loss = 0.1917 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9473 \n",
      " loss = 0.1912 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9470 \n",
      " loss = 0.1945 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9469 \n",
      " loss = 0.1941 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9473 \n",
      " loss = 0.1930 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9470 \n",
      " loss = 0.1943 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9469 \n",
      " loss = 0.1943 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9471 \n",
      " loss = 0.1944 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9473 \n",
      " loss = 0.1933 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9472 \n",
      " loss = 0.1937 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9471 \n",
      " loss = 0.1928 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9464 \n",
      " loss = 0.1936 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9463 \n",
      " loss = 0.1932 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9455 \n",
      " loss = 0.1942 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9446 \n",
      " loss = 0.1975 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9445 \n",
      " loss = 0.1971 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9447 \n",
      " loss = 0.1960 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9449 \n",
      " loss = 0.1952 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9446 \n",
      " loss = 0.1949 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9448 \n",
      " loss = 0.1946 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9449 \n",
      " loss = 0.1936 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9447 \n",
      " loss = 0.1946 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9446 \n",
      " loss = 0.1946 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9439 \n",
      " loss = 0.1955 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9441 \n",
      " loss = 0.1955 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9438 \n",
      " loss = 0.1955 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9434 \n",
      " loss = 0.1976 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9431 \n",
      " loss = 0.2016 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9433 \n",
      " loss = 0.2010 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9433 \n",
      " loss = 0.2007 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9432 \n",
      " loss = 0.2003 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9436 \n",
      " loss = 0.1992 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9440 \n",
      " loss = 0.1982 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9439 \n",
      " loss = 0.1978 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9443 \n",
      " loss = 0.1968 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9444 \n",
      " loss = 0.1965 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9444 \n",
      " loss = 0.1963 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9441 \n",
      " loss = 0.1978 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9445 \n",
      " loss = 0.1968 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9439 \n",
      " loss = 0.1980 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9436 \n",
      " loss = 0.1979 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9436 \n",
      " loss = 0.1979 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9436 \n",
      " loss = 0.1983 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9439 \n",
      " loss = 0.1972 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9440 \n",
      " loss = 0.1968 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9440 \n",
      " loss = 0.1968 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9440 \n",
      " loss = 0.1964 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9439 \n",
      " loss = 0.1969 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9439 \n",
      " loss = 0.1963 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9439 \n",
      " loss = 0.1967 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9440 \n",
      " loss = 0.1968 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9441 \n",
      " loss = 0.1962 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9443 \n",
      " loss = 0.1953 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9441 \n",
      " loss = 0.1955 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9444 \n",
      " loss = 0.1945 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9447 \n",
      " loss = 0.1935 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9447 \n",
      " loss = 0.1935 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9444 \n",
      " loss = 0.1942 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9439 \n",
      " loss = 0.1949 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9440 \n",
      " loss = 0.1942 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9440 \n",
      " loss = 0.1941 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9440 \n",
      " loss = 0.1942 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9438 \n",
      " loss = 0.1949 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9437 \n",
      " loss = 0.1973 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9439 \n",
      " loss = 0.1967 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9438 \n",
      " loss = 0.1967 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9430 \n",
      " loss = 0.1979 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9431 \n",
      " loss = 0.1972 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9431 \n",
      " loss = 0.1972 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9432 \n",
      " loss = 0.1964 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9433 \n",
      " loss = 0.1958 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9433 \n",
      " loss = 0.1958 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9436 \n",
      " loss = 0.1949 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9439 \n",
      " loss = 0.1940 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9440 \n",
      " loss = 0.1936 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9441 \n",
      " loss = 0.1928 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9444 \n",
      " loss = 0.1919 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9445 \n",
      " loss = 0.1920 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9448 \n",
      " loss = 0.1911 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9448 \n",
      " loss = 0.1911 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9447 \n",
      " loss = 0.1924 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9450 \n",
      " loss = 0.1916 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9450 \n",
      " loss = 0.1911 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9448 \n",
      " loss = 0.1927 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9447 \n",
      " loss = 0.1923 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9446 \n",
      " loss = 0.1925 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9445 \n",
      " loss = 0.1924 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9445 \n",
      " loss = 0.1927 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9446 \n",
      " loss = 0.1922 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9443 \n",
      " loss = 0.1935 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9442 \n",
      " loss = 0.1937 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9444 \n",
      " loss = 0.1931 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9442 \n",
      " loss = 0.1935 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9443 \n",
      " loss = 0.1933 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9441 \n",
      " loss = 0.1933 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9441 \n",
      " loss = 0.1931 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9439 \n",
      " loss = 0.1932 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9439 \n",
      " loss = 0.1933 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9439 \n",
      " loss = 0.1939 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9440 \n",
      " loss = 0.1937 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9439 \n",
      " loss = 0.1944 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9442 \n",
      " loss = 0.1935 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9442 \n",
      " loss = 0.1936 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9439 \n",
      " loss = 0.1939 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9438 \n",
      " loss = 0.1936 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9441 \n",
      " loss = 0.1930 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9442 \n",
      " loss = 0.1926 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9444 \n",
      " loss = 0.1918 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9445 \n",
      " loss = 0.1913 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9444 \n",
      " loss = 0.1920 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9445 \n",
      " loss = 0.1915 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9444 \n",
      " loss = 0.1914 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9441 \n",
      " loss = 0.1923 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9443 \n",
      " loss = 0.1926 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9444 \n",
      " loss = 0.1920 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9441 \n",
      " loss = 0.1927 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9442 \n",
      " loss = 0.1922 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9440 \n",
      " loss = 0.1920 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9439 \n",
      " loss = 0.1924 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9436 \n",
      " loss = 0.1928 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9437 \n",
      " loss = 0.1929 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9438 \n",
      " loss = 0.1927 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9436 \n",
      " loss = 0.1930 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9437 \n",
      " loss = 0.1926 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9438 \n",
      " loss = 0.1922 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9438 \n",
      " loss = 0.1920 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9438 \n",
      " loss = 0.1920 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9439 \n",
      " loss = 0.1916 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9438 \n",
      " loss = 0.1926 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9439 \n",
      " loss = 0.1925 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9440 \n",
      " loss = 0.1923 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9439 \n",
      " loss = 0.1921 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9440 \n",
      " loss = 0.1915 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9441 \n",
      " loss = 0.1916 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9442 \n",
      " loss = 0.1912 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9443 \n",
      " loss = 0.1907 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9445 \n",
      " loss = 0.1900 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9446 \n",
      " loss = 0.1902 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9444 \n",
      " loss = 0.1909 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9444 \n",
      " loss = 0.1906 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9444 \n",
      " loss = 0.1907 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9444 \n",
      " loss = 0.1909 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9445 \n",
      " loss = 0.1905 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9443 \n",
      " loss = 0.1911 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9445 \n",
      " loss = 0.1905 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9447 \n",
      " loss = 0.1899 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9447 \n",
      " loss = 0.1914 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9447 \n",
      " loss = 0.1914 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9448 \n",
      " loss = 0.1909 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9447 \n",
      " loss = 0.1906 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9447 \n",
      " loss = 0.1913 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9448 \n",
      " loss = 0.1916 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9450 \n",
      " loss = 0.1909 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9451 \n",
      " loss = 0.1906 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9452 \n",
      " loss = 0.1903 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9454 \n",
      " loss = 0.1897 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9455 \n",
      " loss = 0.1893 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9455 \n",
      " loss = 0.1889 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9455 \n",
      " loss = 0.1887 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9455 \n",
      " loss = 0.1887 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9456 \n",
      " loss = 0.1892 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9456 \n",
      " loss = 0.1889 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9455 \n",
      " loss = 0.1896 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9454 \n",
      " loss = 0.1899 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9456 \n",
      " loss = 0.1894 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9455 \n",
      " loss = 0.1892 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9456 \n",
      " loss = 0.1900 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9457 \n",
      " loss = 0.1898 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9459 \n",
      " loss = 0.1893 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9458 \n",
      " loss = 0.1895 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9457 \n",
      " loss = 0.1896 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9459 \n",
      " loss = 0.1891 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9460 \n",
      " loss = 0.1887 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9462 \n",
      " loss = 0.1882 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9461 \n",
      " loss = 0.1883 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9462 \n",
      " loss = 0.1878 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9461 \n",
      " loss = 0.1886 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9461 \n",
      " loss = 0.1887 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9462 \n",
      " loss = 0.1883 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9463 \n",
      " loss = 0.1880 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9464 \n",
      " loss = 0.1878 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9464 \n",
      " loss = 0.1874 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9466 \n",
      " loss = 0.1870 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9467 \n",
      " loss = 0.1873 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9468 \n",
      " loss = 0.1871 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9467 \n",
      " loss = 0.1877 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9467 \n",
      " loss = 0.1877 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9469 \n",
      " loss = 0.1873 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9469 \n",
      " loss = 0.1870 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9470 \n",
      " loss = 0.1865 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9472 \n",
      " loss = 0.1861 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9472 \n",
      " loss = 0.1862 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9472 \n",
      " loss = 0.1863 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9472 \n",
      " loss = 0.1864 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9474 \n",
      " loss = 0.1858 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9471 \n",
      " loss = 0.1866 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9471 \n",
      " loss = 0.1869 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9471 \n",
      " loss = 0.1870 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9471 \n",
      " loss = 0.1868 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9472 \n",
      " loss = 0.1863 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9472 \n",
      " loss = 0.1862 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9472 \n",
      " loss = 0.1863 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9474 \n",
      " loss = 0.1858 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9475 \n",
      " loss = 0.1857 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9474 \n",
      " loss = 0.1858 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9476 \n",
      " loss = 0.1853 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9476 \n",
      " loss = 0.1851 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9476 \n",
      " loss = 0.1847 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9477 \n",
      " loss = 0.1848 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9479 \n",
      " loss = 0.1844 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9477 \n",
      " loss = 0.1850 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9477 \n",
      " loss = 0.1860 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9478 \n",
      " loss = 0.1857 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9477 \n",
      " loss = 0.1856 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9476 \n",
      " loss = 0.1865 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9474 \n",
      " loss = 0.1870 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9475 \n",
      " loss = 0.1872 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9474 \n",
      " loss = 0.1873 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9473 \n",
      " loss = 0.1877 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9474 \n",
      " loss = 0.1876 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9472 \n",
      " loss = 0.1877 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9472 \n",
      " loss = 0.1878 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9473 \n",
      " loss = 0.1877 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9473 \n",
      " loss = 0.1882 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9473 \n",
      " loss = 0.1879 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9473 \n",
      " loss = 0.1883 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9473 \n",
      " loss = 0.1881 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9474 \n",
      " loss = 0.1878 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9473 \n",
      " loss = 0.1880 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9474 \n",
      " loss = 0.1876 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9475 \n",
      " loss = 0.1875 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9475 \n",
      " loss = 0.1873 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9474 \n",
      " loss = 0.1874 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9475 \n",
      " loss = 0.1874 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9475 \n",
      " loss = 0.1871 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9474 \n",
      " loss = 0.1870 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9474 \n",
      " loss = 0.1866 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9475 \n",
      " loss = 0.1863 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9475 \n",
      " loss = 0.1861 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9474 \n",
      " loss = 0.1862 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9471 \n",
      " loss = 0.1876 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9472 \n",
      " loss = 0.1874 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9472 \n",
      " loss = 0.1871 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9471 \n",
      " loss = 0.1872 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9472 \n",
      " loss = 0.1872 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9474 \n",
      " loss = 0.1867 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9475 \n",
      " loss = 0.1864 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9475 \n",
      " loss = 0.1862 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9476 \n",
      " loss = 0.1857 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9476 \n",
      " loss = 0.1855 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9477 \n",
      " loss = 0.1851 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9477 \n",
      " loss = 0.1850 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9477 \n",
      " loss = 0.1850 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9477 \n",
      " loss = 0.1849 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9479 \n",
      " loss = 0.1845 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9480 \n",
      " loss = 0.1840 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9480 \n",
      " loss = 0.1839 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9477 \n",
      " loss = 0.1841 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9478 \n",
      " loss = 0.1839 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9476 \n",
      " loss = 0.1853 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9476 \n",
      " loss = 0.1851 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9478 \n",
      " loss = 0.1848 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9479 \n",
      " loss = 0.1844 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9480 \n",
      " loss = 0.1840 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9481 \n",
      " loss = 0.1837 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9481 \n",
      " loss = 0.1834 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9483 \n",
      " loss = 0.1831 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9483 \n",
      " loss = 0.1827 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9478 \n",
      " loss = 0.1837 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9476 \n",
      " loss = 0.1841 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9473 \n",
      " loss = 0.1859 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9470 \n",
      " loss = 0.1860 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9471 \n",
      " loss = 0.1865 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9470 \n",
      " loss = 0.1866 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9470 \n",
      " loss = 0.1862 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9471 \n",
      " loss = 0.1860 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9471 \n",
      " loss = 0.1857 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9472 \n",
      " loss = 0.1854 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9472 \n",
      " loss = 0.1854 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9473 \n",
      " loss = 0.1850 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9472 \n",
      " loss = 0.1851 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9472 \n",
      " loss = 0.1848 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9473 \n",
      " loss = 0.1844 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9474 \n",
      " loss = 0.1841 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9473 \n",
      " loss = 0.1843 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9473 \n",
      " loss = 0.1844 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9473 \n",
      " loss = 0.1845 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9473 \n",
      " loss = 0.1848 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9474 \n",
      " loss = 0.1844 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9475 \n",
      " loss = 0.1840 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9475 \n",
      " loss = 0.1844 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9476 \n",
      " loss = 0.1839 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9477 \n",
      " loss = 0.1836 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9478 \n",
      " loss = 0.1832 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9479 \n",
      " loss = 0.1828 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9480 \n",
      " loss = 0.1825 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9480 \n",
      " loss = 0.1825 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9481 \n",
      " loss = 0.1822 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9481 \n",
      " loss = 0.1820 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9482 \n",
      " loss = 0.1821 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9482 \n",
      " loss = 0.1819 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9483 \n",
      " loss = 0.1817 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9482 \n",
      " loss = 0.1819 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9482 \n",
      " loss = 0.1822 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9483 \n",
      " loss = 0.1818 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9483 \n",
      " loss = 0.1818 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9481 \n",
      " loss = 0.1820 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9480 \n",
      " loss = 0.1821 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9481 \n",
      " loss = 0.1818 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9482 \n",
      " loss = 0.1814 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9482 \n",
      " loss = 0.1813 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9481 \n",
      " loss = 0.1815 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9481 \n",
      " loss = 0.1815 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9483 \n",
      " loss = 0.1812 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9482 \n",
      " loss = 0.1825 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9482 \n",
      " loss = 0.1824 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9482 \n",
      " loss = 0.1824 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9483 \n",
      " loss = 0.1822 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9483 \n",
      " loss = 0.1821 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9484 \n",
      " loss = 0.1820 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9484 \n",
      " loss = 0.1819 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9484 \n",
      " loss = 0.1817 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9485 \n",
      " loss = 0.1817 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9484 \n",
      " loss = 0.1818 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9483 \n",
      " loss = 0.1823 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9483 \n",
      " loss = 0.1821 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9484 \n",
      " loss = 0.1819 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9485 \n",
      " loss = 0.1815 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9485 \n",
      " loss = 0.1814 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9485 \n",
      " loss = 0.1813 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9485 \n",
      " loss = 0.1812 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9484 \n",
      " loss = 0.1814 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9484 \n",
      " loss = 0.1814 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9485 \n",
      " loss = 0.1812 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9483 \n",
      " loss = 0.1816 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9483 \n",
      " loss = 0.1817 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9483 \n",
      " loss = 0.1816 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9482 \n",
      " loss = 0.1815 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9482 \n",
      " loss = 0.1813 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9483 \n",
      " loss = 0.1812 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9482 \n",
      " loss = 0.1821 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9483 \n",
      " loss = 0.1818 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9484 \n",
      " loss = 0.1816 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9485 \n",
      " loss = 0.1813 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9483 \n",
      " loss = 0.1814 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9485 \n",
      " loss = 0.1811 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9484 \n",
      " loss = 0.1811 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9485 \n",
      " loss = 0.1807 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9486 \n",
      " loss = 0.1804 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9486 \n",
      " loss = 0.1805 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9486 \n",
      " loss = 0.1804 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9486 \n",
      " loss = 0.1803 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9486 \n",
      " loss = 0.1803 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9487 \n",
      " loss = 0.1800 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9488 \n",
      " loss = 0.1799 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9489 \n",
      " loss = 0.1796 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9489 \n",
      " loss = 0.1795 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9490 \n",
      " loss = 0.1792 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9489 \n",
      " loss = 0.1793 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9490 \n",
      " loss = 0.1789 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9491 \n",
      " loss = 0.1787 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9491 \n",
      " loss = 0.1787 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9492 \n",
      " loss = 0.1784 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9492 \n",
      " loss = 0.1791 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9491 \n",
      " loss = 0.1794 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9492 \n",
      " loss = 0.1791 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9493 \n",
      " loss = 0.1788 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9492 \n",
      " loss = 0.1797 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9493 \n",
      " loss = 0.1793 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9494 \n",
      " loss = 0.1791 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9495 \n",
      " loss = 0.1788 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9493 \n",
      " loss = 0.1800 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9493 \n",
      " loss = 0.1798 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9494 \n",
      " loss = 0.1795 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9494 \n",
      " loss = 0.1794 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9495 \n",
      " loss = 0.1791 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9495 \n",
      " loss = 0.1791 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9495 \n",
      " loss = 0.1789 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9496 \n",
      " loss = 0.1786 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9497 \n",
      " loss = 0.1783 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9497 \n",
      " loss = 0.1783 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9498 \n",
      " loss = 0.1781 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9498 \n",
      " loss = 0.1780 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9498 \n",
      " loss = 0.1779 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9498 \n",
      " loss = 0.1777 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9498 \n",
      " loss = 0.1777 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9498 \n",
      " loss = 0.1776 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9498 \n",
      " loss = 0.1777 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9499 \n",
      " loss = 0.1774 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9498 \n",
      " loss = 0.1782 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9497 \n",
      " loss = 0.1784 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9497 \n",
      " loss = 0.1782 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9496 \n",
      " loss = 0.1782 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9496 \n",
      " loss = 0.1791 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9495 \n",
      " loss = 0.1793 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9494 \n",
      " loss = 0.1798 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9495 \n",
      " loss = 0.1795 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9495 \n",
      " loss = 0.1805 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9494 \n",
      " loss = 0.1806 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9495 \n",
      " loss = 0.1804 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9492 \n",
      " loss = 0.1810 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9492 \n",
      " loss = 0.1814 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9492 \n",
      " loss = 0.1812 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9493 \n",
      " loss = 0.1809 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9494 \n",
      " loss = 0.1811 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9494 \n",
      " loss = 0.1822 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9494 \n",
      " loss = 0.1820 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9495 \n",
      " loss = 0.1817 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9496 \n",
      " loss = 0.1814 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9497 \n",
      " loss = 0.1811 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9497 \n",
      " loss = 0.1809 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9497 \n",
      " loss = 0.1808 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9497 \n",
      " loss = 0.1807 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9497 \n",
      " loss = 0.1805 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9495 \n",
      " loss = 0.1816 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9496 \n",
      " loss = 0.1813 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9496 \n",
      " loss = 0.1813 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9495 \n",
      " loss = 0.1815 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9496 \n",
      " loss = 0.1812 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9497 \n",
      " loss = 0.1810 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9496 \n",
      " loss = 0.1808 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9497 \n",
      " loss = 0.1805 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9498 \n",
      " loss = 0.1803 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9497 \n",
      " loss = 0.1802 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9497 \n",
      " loss = 0.1802 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9496 \n",
      " loss = 0.1803 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9497 \n",
      " loss = 0.1800 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9497 \n",
      " loss = 0.1800 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9496 \n",
      " loss = 0.1800 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9496 \n",
      " loss = 0.1800 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9496 \n",
      " loss = 0.1799 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9495 \n",
      " loss = 0.1804 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9495 \n",
      " loss = 0.1803 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9494 \n",
      " loss = 0.1802 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9495 \n",
      " loss = 0.1800 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9495 \n",
      " loss = 0.1803 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9495 \n",
      " loss = 0.1801 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9496 \n",
      " loss = 0.1802 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9496 \n",
      " loss = 0.1799 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9497 \n",
      " loss = 0.1797 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9498 \n",
      " loss = 0.1795 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9499 \n",
      " loss = 0.1791 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9499 \n",
      " loss = 0.1789 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9499 \n",
      " loss = 0.1789 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9499 \n",
      " loss = 0.1789 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9499 \n",
      " loss = 0.1787 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9500 \n",
      " loss = 0.1785 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9499 \n",
      " loss = 0.1784 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9500 \n",
      " loss = 0.1782 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9500 \n",
      " loss = 0.1782 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9500 \n",
      " loss = 0.1779 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9500 \n",
      " loss = 0.1783 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9499 \n",
      " loss = 0.1789 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9498 \n",
      " loss = 0.1790 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9499 \n",
      " loss = 0.1787 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9499 \n",
      " loss = 0.1786 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9500 \n",
      " loss = 0.1783 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9500 \n",
      " loss = 0.1786 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9501 \n",
      " loss = 0.1784 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9501 \n",
      " loss = 0.1784 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9500 \n",
      " loss = 0.1789 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9500 \n",
      " loss = 0.1788 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9499 \n",
      " loss = 0.1789 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9500 \n",
      " loss = 0.1786 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9500 \n",
      " loss = 0.1786 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9500 \n",
      " loss = 0.1786 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9501 \n",
      " loss = 0.1784 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9502 \n",
      " loss = 0.1781 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9502 \n",
      " loss = 0.1779 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1778 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9504 \n",
      " loss = 0.1776 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9504 \n",
      " loss = 0.1774 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9505 \n",
      " loss = 0.1771 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9505 \n",
      " loss = 0.1770 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9505 \n",
      " loss = 0.1769 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9505 \n",
      " loss = 0.1770 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9505 \n",
      " loss = 0.1769 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9504 \n",
      " loss = 0.1771 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9502 \n",
      " loss = 0.1776 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1774 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9502 \n",
      " loss = 0.1773 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9501 \n",
      " loss = 0.1778 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9502 \n",
      " loss = 0.1777 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9501 \n",
      " loss = 0.1776 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9502 \n",
      " loss = 0.1774 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9502 \n",
      " loss = 0.1777 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1775 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1773 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9502 \n",
      " loss = 0.1774 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9502 \n",
      " loss = 0.1772 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9502 \n",
      " loss = 0.1771 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1768 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1769 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9502 \n",
      " loss = 0.1770 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9502 \n",
      " loss = 0.1776 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9502 \n",
      " loss = 0.1777 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9502 \n",
      " loss = 0.1775 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9502 \n",
      " loss = 0.1774 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9502 \n",
      " loss = 0.1773 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1773 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1771 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9502 \n",
      " loss = 0.1776 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1776 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1774 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9502 \n",
      " loss = 0.1781 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9502 \n",
      " loss = 0.1780 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9502 \n",
      " loss = 0.1781 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9502 \n",
      " loss = 0.1782 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1781 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1779 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1777 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1777 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1775 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1774 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9504 \n",
      " loss = 0.1772 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9505 \n",
      " loss = 0.1769 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9505 \n",
      " loss = 0.1768 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9504 \n",
      " loss = 0.1769 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1771 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1771 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9504 \n",
      " loss = 0.1769 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1769 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1767 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1769 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1768 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1767 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9502 \n",
      " loss = 0.1767 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9502 \n",
      " loss = 0.1765 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1763 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9502 \n",
      " loss = 0.1764 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9502 \n",
      " loss = 0.1764 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1764 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1761 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9502 \n",
      " loss = 0.1763 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1761 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9504 \n",
      " loss = 0.1759 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9504 \n",
      " loss = 0.1757 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1758 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9504 \n",
      " loss = 0.1764 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9504 \n",
      " loss = 0.1761 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1772 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1770 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1771 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9501 \n",
      " loss = 0.1776 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9502 \n",
      " loss = 0.1773 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9501 \n",
      " loss = 0.1777 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9501 \n",
      " loss = 0.1776 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9501 \n",
      " loss = 0.1776 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9500 \n",
      " loss = 0.1776 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9501 \n",
      " loss = 0.1774 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9500 \n",
      " loss = 0.1775 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9500 \n",
      " loss = 0.1776 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9500 \n",
      " loss = 0.1776 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9500 \n",
      " loss = 0.1777 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9499 \n",
      " loss = 0.1779 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9499 \n",
      " loss = 0.1782 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9498 \n",
      " loss = 0.1788 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9498 \n",
      " loss = 0.1789 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9499 \n",
      " loss = 0.1787 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9498 \n",
      " loss = 0.1786 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9498 \n",
      " loss = 0.1788 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9498 \n",
      " loss = 0.1787 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9499 \n",
      " loss = 0.1785 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9499 \n",
      " loss = 0.1784 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9499 \n",
      " loss = 0.1785 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9499 \n",
      " loss = 0.1784 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9499 \n",
      " loss = 0.1786 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9500 \n",
      " loss = 0.1784 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9500 \n",
      " loss = 0.1784 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9500 \n",
      " loss = 0.1783 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9500 \n",
      " loss = 0.1782 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9500 \n",
      " loss = 0.1784 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9500 \n",
      " loss = 0.1782 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9501 \n",
      " loss = 0.1781 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9501 \n",
      " loss = 0.1784 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9501 \n",
      " loss = 0.1782 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9500 \n",
      " loss = 0.1783 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9500 \n",
      " loss = 0.1783 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9499 \n",
      " loss = 0.1785 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9500 \n",
      " loss = 0.1784 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9500 \n",
      " loss = 0.1783 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9500 \n",
      " loss = 0.1782 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9501 \n",
      " loss = 0.1780 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9501 \n",
      " loss = 0.1781 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9502 \n",
      " loss = 0.1778 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9502 \n",
      " loss = 0.1778 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9501 \n",
      " loss = 0.1783 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9502 \n",
      " loss = 0.1781 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9502 \n",
      " loss = 0.1780 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1784 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1783 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1782 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1780 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1781 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9503 \n",
      " loss = 0.1781 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9504 \n",
      " loss = 0.1779 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9504 \n",
      " loss = 0.1778 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9505 \n",
      " loss = 0.1775 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9504 \n",
      " loss = 0.1782 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9504 \n",
      " loss = 0.1782 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9505 \n",
      " loss = 0.1780 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9504 \n",
      " loss = 0.1781 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9505 \n",
      " loss = 0.1779 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9506 \n",
      " loss = 0.1776 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9506 \n",
      " loss = 0.1776 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9506 \n",
      " loss = 0.1775 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9507 \n",
      " loss = 0.1775 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9506 \n",
      " loss = 0.1775 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9506 \n",
      " loss = 0.1777 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9506 \n",
      " loss = 0.1775 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9507 \n",
      " loss = 0.1774 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9507 \n",
      " loss = 0.1772 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9507 \n",
      " loss = 0.1771 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9507 \n",
      " loss = 0.1769 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9508 \n",
      " loss = 0.1768 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9508 \n",
      " loss = 0.1767 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9508 \n",
      " loss = 0.1766 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9508 \n",
      " loss = 0.1764 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9509 \n",
      " loss = 0.1765 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9509 \n",
      " loss = 0.1763 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9509 \n",
      " loss = 0.1766 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9509 \n",
      " loss = 0.1766 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9510 \n",
      " loss = 0.1764 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9510 \n",
      " loss = 0.1762 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9511 \n",
      " loss = 0.1760 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9511 \n",
      " loss = 0.1758 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9511 \n",
      " loss = 0.1757 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9512 \n",
      " loss = 0.1754 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9512 \n",
      " loss = 0.1755 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9512 \n",
      " loss = 0.1756 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9512 \n",
      " loss = 0.1755 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9513 \n",
      " loss = 0.1753 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9513 \n",
      " loss = 0.1751 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9513 \n",
      " loss = 0.1750 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9513 \n",
      " loss = 0.1749 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9514 \n",
      " loss = 0.1747 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9515 \n",
      " loss = 0.1745 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9514 \n",
      " loss = 0.1744 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9515 \n",
      " loss = 0.1742 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9515 \n",
      " loss = 0.1741 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9514 \n",
      " loss = 0.1745 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9514 \n",
      " loss = 0.1743 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9515 \n",
      " loss = 0.1741 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9515 \n",
      " loss = 0.1743 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9514 \n",
      " loss = 0.1743 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9514 \n",
      " loss = 0.1743 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9514 \n",
      " loss = 0.1744 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9514 \n",
      " loss = 0.1743 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9514 \n",
      " loss = 0.1743 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9514 \n",
      " loss = 0.1746 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9514 \n",
      " loss = 0.1745 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9513 \n",
      " loss = 0.1745 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9514 \n",
      " loss = 0.1744 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9512 \n",
      " loss = 0.1750 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9511 \n",
      " loss = 0.1753 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9511 \n",
      " loss = 0.1752 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9511 \n",
      " loss = 0.1754 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9510 \n",
      " loss = 0.1754 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9510 \n",
      " loss = 0.1753 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9511 \n",
      " loss = 0.1751 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9511 \n",
      " loss = 0.1750 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9511 \n",
      " loss = 0.1750 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9511 \n",
      " loss = 0.1749 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9511 \n",
      " loss = 0.1750 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9512 \n",
      " loss = 0.1749 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9511 \n",
      " loss = 0.1750 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9511 \n",
      " loss = 0.1754 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9511 \n",
      " loss = 0.1752 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9511 \n",
      " loss = 0.1751 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9511 \n",
      " loss = 0.1751 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9511 \n",
      " loss = 0.1749 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9511 \n",
      " loss = 0.1749 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9511 \n",
      " loss = 0.1748 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9511 \n",
      " loss = 0.1750 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9511 \n",
      " loss = 0.1753 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9511 \n",
      " loss = 0.1752 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9511 \n",
      " loss = 0.1750 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9512 \n",
      " loss = 0.1748 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9512 \n",
      " loss = 0.1749 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9512 \n",
      " loss = 0.1749 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9511 \n",
      " loss = 0.1750 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9511 \n",
      " loss = 0.1748 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9512 \n",
      " loss = 0.1747 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9511 \n",
      " loss = 0.1746 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9512 \n",
      " loss = 0.1744 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9512 \n",
      " loss = 0.1743 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9513 \n",
      " loss = 0.1742 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9513 \n",
      " loss = 0.1742 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9513 \n",
      " loss = 0.1741 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9513 \n",
      " loss = 0.1740 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9513 \n",
      " loss = 0.1739 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9513 \n",
      " loss = 0.1740 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9513 \n",
      " loss = 0.1742 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9514 \n",
      " loss = 0.1744 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9513 \n",
      " loss = 0.1747 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9513 \n",
      " loss = 0.1746 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9514 \n",
      " loss = 0.1744 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9514 \n",
      " loss = 0.1745 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9513 \n",
      " loss = 0.1748 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9514 \n",
      " loss = 0.1746 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9514 \n",
      " loss = 0.1744 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9515 \n",
      " loss = 0.1742 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9515 \n",
      " loss = 0.1741 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9514 \n",
      " loss = 0.1743 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9514 \n",
      " loss = 0.1744 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9514 \n",
      " loss = 0.1745 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9514 \n",
      " loss = 0.1743 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9514 \n",
      " loss = 0.1743 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9515 \n",
      " loss = 0.1741 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9515 \n",
      " loss = 0.1741 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9515 \n",
      " loss = 0.1740 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9516 \n",
      " loss = 0.1738 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9516 \n",
      " loss = 0.1738 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9516 \n",
      " loss = 0.1738 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9516 \n",
      " loss = 0.1737 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9517 \n",
      " loss = 0.1735 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9516 \n",
      " loss = 0.1737 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9516 \n",
      " loss = 0.1738 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9515 \n",
      " loss = 0.1738 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9515 \n",
      " loss = 0.1738 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9516 \n",
      " loss = 0.1736 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9515 \n",
      " loss = 0.1736 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9515 \n",
      " loss = 0.1738 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9514 \n",
      " loss = 0.1742 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9514 \n",
      " loss = 0.1742 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9513 \n",
      " loss = 0.1744 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9513 \n",
      " loss = 0.1745 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9513 \n",
      " loss = 0.1744 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9513 \n",
      " loss = 0.1744 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9513 \n",
      " loss = 0.1743 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9512 \n",
      " loss = 0.1747 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9513 \n",
      " loss = 0.1745 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9512 \n",
      " loss = 0.1746 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9512 \n",
      " loss = 0.1752 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9512 \n",
      " loss = 0.1756 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9512 \n",
      " loss = 0.1757 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9511 \n",
      " loss = 0.1760 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9512 \n",
      " loss = 0.1758 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9511 \n",
      " loss = 0.1760 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9510 \n",
      " loss = 0.1763 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9511 \n",
      " loss = 0.1761 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9511 \n",
      " loss = 0.1760 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9512 \n",
      " loss = 0.1759 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9512 \n",
      " loss = 0.1759 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9512 \n",
      " loss = 0.1760 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9512 \n",
      " loss = 0.1758 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9512 \n",
      " loss = 0.1757 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9511 \n",
      " loss = 0.1763 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9512 \n",
      " loss = 0.1761 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9512 \n",
      " loss = 0.1761 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9512 \n",
      " loss = 0.1760 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9513 \n",
      " loss = 0.1759 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9513 \n",
      " loss = 0.1760 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9513 \n",
      " loss = 0.1759 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9513 \n",
      " loss = 0.1758 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9514 \n",
      " loss = 0.1756 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9514 \n",
      " loss = 0.1754 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9515 \n",
      " loss = 0.1753 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9515 \n",
      " loss = 0.1751 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9516 \n",
      " loss = 0.1750 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9516 \n",
      " loss = 0.1749 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9516 \n",
      " loss = 0.1750 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9516 \n",
      " loss = 0.1750 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9516 \n",
      " loss = 0.1749 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9516 \n",
      " loss = 0.1750 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9516 \n",
      " loss = 0.1751 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9516 \n",
      " loss = 0.1750 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9516 \n",
      " loss = 0.1749 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9517 \n",
      " loss = 0.1747 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9517 \n",
      " loss = 0.1748 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9517 \n",
      " loss = 0.1747 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9517 \n",
      " loss = 0.1749 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9517 \n",
      " loss = 0.1747 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9518 \n",
      " loss = 0.1746 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9517 \n",
      " loss = 0.1749 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9517 \n",
      " loss = 0.1750 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9518 \n",
      " loss = 0.1750 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9517 \n",
      " loss = 0.1750 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9518 \n",
      " loss = 0.1748 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9518 \n",
      " loss = 0.1746 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9519 \n",
      " loss = 0.1745 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9518 \n",
      " loss = 0.1746 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9519 \n",
      " loss = 0.1745 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9519 \n",
      " loss = 0.1744 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9519 \n",
      " loss = 0.1742 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9519 \n",
      " loss = 0.1744 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9520 \n",
      " loss = 0.1742 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9520 \n",
      " loss = 0.1740 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9521 \n",
      " loss = 0.1739 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9521 \n",
      " loss = 0.1738 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9521 \n",
      " loss = 0.1740 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9521 \n",
      " loss = 0.1739 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9522 \n",
      " loss = 0.1738 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9520 \n",
      " loss = 0.1740 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9519 \n",
      " loss = 0.1746 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9519 \n",
      " loss = 0.1747 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9518 \n",
      " loss = 0.1750 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9517 \n",
      " loss = 0.1752 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9517 \n",
      " loss = 0.1752 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9517 \n",
      " loss = 0.1752 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9518 \n",
      " loss = 0.1751 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9517 \n",
      " loss = 0.1752 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9518 \n",
      " loss = 0.1751 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9518 \n",
      " loss = 0.1751 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9518 \n",
      " loss = 0.1753 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9518 \n",
      " loss = 0.1752 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9519 \n",
      " loss = 0.1751 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9519 \n",
      " loss = 0.1749 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9519 \n",
      " loss = 0.1750 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9519 \n",
      " loss = 0.1750 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9519 \n",
      " loss = 0.1748 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9520 \n",
      " loss = 0.1747 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9520 \n",
      " loss = 0.1746 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9520 \n",
      " loss = 0.1746 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9520 \n",
      " loss = 0.1745 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9520 \n",
      " loss = 0.1744 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9520 \n",
      " loss = 0.1744 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9520 \n",
      " loss = 0.1743 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9521 \n",
      " loss = 0.1741 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9521 \n",
      " loss = 0.1739 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9521 \n",
      " loss = 0.1739 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9522 \n",
      " loss = 0.1738 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9522 \n",
      " loss = 0.1736 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9522 \n",
      " loss = 0.1735 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1734 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9522 \n",
      " loss = 0.1734 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1732 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9522 \n",
      " loss = 0.1736 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1734 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1732 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1733 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1731 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1733 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1732 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1731 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1732 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1731 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1730 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1729 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1729 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1728 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1729 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1727 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1726 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1726 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1725 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1726 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1728 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1727 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1727 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1726 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1725 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1724 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1727 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1725 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1727 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1726 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1727 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1727 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1726 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1732 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1733 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1734 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1735 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1734 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1733 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1732 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1731 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1731 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1730 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1729 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1728 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1728 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1726 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1725 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1727 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9522 \n",
      " loss = 0.1729 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9522 \n",
      " loss = 0.1730 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9522 \n",
      " loss = 0.1730 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9522 \n",
      " loss = 0.1729 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1728 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1727 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1726 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1726 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1725 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1724 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1723 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1722 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1721 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1724 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1723 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1727 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1727 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9522 \n",
      " loss = 0.1735 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9522 \n",
      " loss = 0.1735 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1735 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1734 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1733 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1733 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9522 \n",
      " loss = 0.1734 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9522 \n",
      " loss = 0.1732 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1731 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1732 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1732 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1733 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9522 \n",
      " loss = 0.1734 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1733 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9522 \n",
      " loss = 0.1736 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9521 \n",
      " loss = 0.1739 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9521 \n",
      " loss = 0.1738 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9521 \n",
      " loss = 0.1738 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9521 \n",
      " loss = 0.1737 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9521 \n",
      " loss = 0.1738 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9521 \n",
      " loss = 0.1737 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9521 \n",
      " loss = 0.1736 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9520 \n",
      " loss = 0.1737 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9520 \n",
      " loss = 0.1737 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9520 \n",
      " loss = 0.1736 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9521 \n",
      " loss = 0.1734 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9521 \n",
      " loss = 0.1733 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9522 \n",
      " loss = 0.1732 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9522 \n",
      " loss = 0.1730 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9522 \n",
      " loss = 0.1729 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1729 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1728 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1727 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1728 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1727 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1727 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1727 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1727 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1726 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1725 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1723 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1723 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1721 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1720 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1721 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1723 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1722 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1723 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1722 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1721 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1722 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1720 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1722 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1721 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1720 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1721 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1721 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1720 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1719 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1720 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1719 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1722 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1722 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1721 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1720 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1719 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1718 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1717 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1716 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1716 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1715 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1714 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1712 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1712 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1716 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1716 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1715 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1714 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1714 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1714 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1714 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1714 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1713 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1714 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1713 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1712 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1713 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1712 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1711 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1711 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1709 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1711 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1710 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1709 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9530 \n",
      " loss = 0.1709 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9530 \n",
      " loss = 0.1709 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9530 \n",
      " loss = 0.1708 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1713 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1715 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1714 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1713 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1712 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1711 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1718 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1717 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1718 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1717 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1717 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1716 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1717 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1717 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1716 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1719 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1719 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1718 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1719 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1717 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1719 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1721 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1722 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1722 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1725 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1725 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1725 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1725 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1723 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1722 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1721 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1720 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1719 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1718 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1717 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1718 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1717 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1716 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1716 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1715 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1714 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1713 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1712 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1711 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1712 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1712 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1710 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9530 \n",
      " loss = 0.1710 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9530 \n",
      " loss = 0.1709 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9530 \n",
      " loss = 0.1709 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9530 \n",
      " loss = 0.1708 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1710 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1710 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1710 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1712 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1711 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1712 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1713 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1712 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1713 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1713 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1712 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1714 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1715 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1714 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1718 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1716 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1718 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1717 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1716 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1716 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1715 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1714 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1715 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1714 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1714 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1713 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1713 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1714 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1712 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1711 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1710 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1709 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1708 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1710 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1709 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1710 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1710 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1709 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1707 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1708 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1710 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1710 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1709 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1708 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1709 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1709 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1708 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1707 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1706 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1706 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1705 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1704 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1704 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1706 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1709 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1710 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1711 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1711 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1710 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1709 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1709 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1709 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1709 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1708 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1707 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1708 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1707 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1706 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1706 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1705 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1705 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1707 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1710 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1712 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1712 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1711 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1714 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1713 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1714 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1714 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1712 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1711 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1713 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1720 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1721 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1720 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1719 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1718 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1717 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1719 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1718 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1717 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1716 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1716 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1720 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1719 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1719 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1720 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1722 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1723 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1726 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9522 \n",
      " loss = 0.1725 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1724 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9522 \n",
      " loss = 0.1729 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9522 \n",
      " loss = 0.1730 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9522 \n",
      " loss = 0.1730 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9522 \n",
      " loss = 0.1732 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9522 \n",
      " loss = 0.1731 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9522 \n",
      " loss = 0.1730 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9522 \n",
      " loss = 0.1731 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9522 \n",
      " loss = 0.1731 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1730 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1730 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1730 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1729 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1729 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9523 \n",
      " loss = 0.1727 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1726 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1725 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1724 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1724 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1723 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1721 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1721 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1720 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1719 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1722 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1721 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9524 \n",
      " loss = 0.1721 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1720 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1719 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1718 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1718 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1718 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1718 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1718 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1717 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1717 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1715 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1714 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1716 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1717 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1719 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1717 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1716 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1716 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1716 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1716 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1715 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1716 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1715 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1715 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1715 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1717 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1719 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1718 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1720 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1720 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1719 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9525 \n",
      " loss = 0.1719 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1718 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1718 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1717 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1716 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1715 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1714 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1714 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1712 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1712 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1710 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1712 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1712 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1714 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1712 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1713 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1712 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1712 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1715 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1721 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1721 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1722 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1721 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1721 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1720 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1720 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1722 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9526 \n",
      " loss = 0.1721 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1722 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1721 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1720 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1718 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1717 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1716 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1716 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1715 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1716 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1716 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1715 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1718 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1717 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1719 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1718 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1718 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1719 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1718 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1717 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1716 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1717 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1718 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1718 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1717 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1717 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1716 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1715 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1714 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1715 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1714 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1715 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9527 \n",
      " loss = 0.1715 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1714 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1714 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1714 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1713 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1713 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9528 \n",
      " loss = 0.1712 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1711 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1711 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1712 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1712 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1711 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9529 \n",
      " loss = 0.1711 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9530 \n",
      " loss = 0.1710 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9530 \n",
      " loss = 0.1709 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9530 \n",
      " loss = 0.1708 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9530 \n",
      " loss = 0.1707 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9530 \n",
      " loss = 0.1707 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9531 \n",
      " loss = 0.1706 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9531 \n",
      " loss = 0.1705 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9531 \n",
      " loss = 0.1706 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9531 \n",
      " loss = 0.1706 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9531 \n",
      " loss = 0.1705 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9531 \n",
      " loss = 0.1704 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9531 \n",
      " loss = 0.1704 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9531 \n",
      " loss = 0.1703 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9531 \n",
      " loss = 0.1702 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9532 \n",
      " loss = 0.1701 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9532 \n",
      " loss = 0.1700 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9532 \n",
      " loss = 0.1699 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9532 \n",
      " loss = 0.1699 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9531 \n",
      " loss = 0.1700 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9531 \n",
      " loss = 0.1699 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9531 \n",
      " loss = 0.1699 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9531 \n",
      " loss = 0.1699 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9531 \n",
      " loss = 0.1700 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9531 \n",
      " loss = 0.1700 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9531 \n",
      " loss = 0.1699 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9531 \n",
      " loss = 0.1698 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9532 \n",
      " loss = 0.1697 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9532 \n",
      " loss = 0.1696 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9532 \n",
      " loss = 0.1696 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9532 \n",
      " loss = 0.1695 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9532 \n",
      " loss = 0.1694 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9533 \n",
      " loss = 0.1693 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9532 \n",
      " loss = 0.1692 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9533 \n",
      " loss = 0.1691 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9533 \n",
      " loss = 0.1691 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9532 \n",
      " loss = 0.1693 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9533 \n",
      " loss = 0.1692 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9532 \n",
      " loss = 0.1693 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9532 \n",
      " loss = 0.1692 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9532 \n",
      " loss = 0.1693 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9532 \n",
      " loss = 0.1693 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9532 \n",
      " loss = 0.1693 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9532 \n",
      " loss = 0.1692 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9532 \n",
      " loss = 0.1693 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9532 \n",
      " loss = 0.1692 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9532 \n",
      " loss = 0.1692 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9532 \n",
      " loss = 0.1691 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9532 \n",
      " loss = 0.1690 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9533 \n",
      " loss = 0.1689 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9533 \n",
      " loss = 0.1689 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9532 \n",
      " loss = 0.1690 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9533 \n",
      " loss = 0.1689 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9533 \n",
      " loss = 0.1688 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9533 \n",
      " loss = 0.1687 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9534 \n",
      " loss = 0.1686 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9534 \n",
      " loss = 0.1687 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9534 \n",
      " loss = 0.1687 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9534 \n",
      " loss = 0.1687 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9534 \n",
      " loss = 0.1688 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9534 \n",
      " loss = 0.1687 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9534 \n",
      " loss = 0.1686 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9534 \n",
      " loss = 0.1687 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9534 \n",
      " loss = 0.1686 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9534 \n",
      " loss = 0.1686 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9534 \n",
      " loss = 0.1685 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9534 \n",
      " loss = 0.1686 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9534 \n",
      " loss = 0.1684 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9534 \n",
      " loss = 0.1684 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9535 \n",
      " loss = 0.1684 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9534 \n",
      " loss = 0.1683 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9535 \n",
      " loss = 0.1682 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9535 \n",
      " loss = 0.1682 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9535 \n",
      " loss = 0.1681 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9535 \n",
      " loss = 0.1680 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9535 \n",
      " loss = 0.1680 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9536 \n",
      " loss = 0.1679 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9535 \n",
      " loss = 0.1678 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9535 \n",
      " loss = 0.1679 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9535 \n",
      " loss = 0.1678 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9535 \n",
      " loss = 0.1677 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9536 \n",
      " loss = 0.1677 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9536 \n",
      " loss = 0.1677 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9536 \n",
      " loss = 0.1677 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9536 \n",
      " loss = 0.1676 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9536 \n",
      " loss = 0.1676 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9536 \n",
      " loss = 0.1675 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9536 \n",
      " loss = 0.1674 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9536 \n",
      " loss = 0.1674 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9536 \n",
      " loss = 0.1673 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9536 \n",
      " loss = 0.1674 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9536 \n",
      " loss = 0.1673 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9536 \n",
      " loss = 0.1673 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9536 \n",
      " loss = 0.1672 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9537 \n",
      " loss = 0.1671 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9536 \n",
      " loss = 0.1671 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9536 \n",
      " loss = 0.1674 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9536 \n",
      " loss = 0.1674 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9535 \n",
      " loss = 0.1676 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9536 \n",
      " loss = 0.1675 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9536 \n",
      " loss = 0.1674 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9536 \n",
      " loss = 0.1675 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9536 \n",
      " loss = 0.1674 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9536 \n",
      " loss = 0.1673 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9536 \n",
      " loss = 0.1672 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9537 \n",
      " loss = 0.1671 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9537 \n",
      " loss = 0.1670 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9537 \n",
      " loss = 0.1670 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9536 \n",
      " loss = 0.1670 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9536 \n",
      " loss = 0.1670 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9536 \n",
      " loss = 0.1670 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9537 \n",
      " loss = 0.1669 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9537 \n",
      " loss = 0.1668 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9537 \n",
      " loss = 0.1666 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9537 \n",
      " loss = 0.1666 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9538 \n",
      " loss = 0.1665 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9538 \n",
      " loss = 0.1664 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9538 \n",
      " loss = 0.1664 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9538 \n",
      " loss = 0.1663 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9538 \n",
      " loss = 0.1663 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9538 \n",
      " loss = 0.1662 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9538 \n",
      " loss = 0.1662 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9539 \n",
      " loss = 0.1661 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9539 \n",
      " loss = 0.1660 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9539 \n",
      " loss = 0.1659 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9539 \n",
      " loss = 0.1658 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9540 \n",
      " loss = 0.1657 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9540 \n",
      " loss = 0.1658 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9540 \n",
      " loss = 0.1657 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9540 \n",
      " loss = 0.1656 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9540 \n",
      " loss = 0.1655 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9541 \n",
      " loss = 0.1654 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9540 \n",
      " loss = 0.1655 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9541 \n",
      " loss = 0.1655 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9540 \n",
      " loss = 0.1656 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9541 \n",
      " loss = 0.1655 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9541 \n",
      " loss = 0.1654 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9541 \n",
      " loss = 0.1653 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9541 \n",
      " loss = 0.1652 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9542 \n",
      " loss = 0.1651 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9542 \n",
      " loss = 0.1650 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9542 \n",
      " loss = 0.1649 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9543 \n",
      " loss = 0.1648 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9543 \n",
      " loss = 0.1647 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9543 \n",
      " loss = 0.1646 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9544 \n",
      " loss = 0.1645 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9544 \n",
      " loss = 0.1644 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9544 \n",
      " loss = 0.1644 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9544 \n",
      " loss = 0.1643 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9543 \n",
      " loss = 0.1643 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9543 \n",
      " loss = 0.1643 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9543 \n",
      " loss = 0.1642 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9543 \n",
      " loss = 0.1642 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9543 \n",
      " loss = 0.1641 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9544 \n",
      " loss = 0.1640 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9544 \n",
      " loss = 0.1639 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9544 \n",
      " loss = 0.1638 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9544 \n",
      " loss = 0.1638 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9544 \n",
      " loss = 0.1638 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9545 \n",
      " loss = 0.1637 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9544 \n",
      " loss = 0.1646 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9544 \n",
      " loss = 0.1649 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9544 \n",
      " loss = 0.1648 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9544 \n",
      " loss = 0.1647 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9544 \n",
      " loss = 0.1646 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9545 \n",
      " loss = 0.1645 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9545 \n",
      " loss = 0.1648 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9545 \n",
      " loss = 0.1648 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9545 \n",
      " loss = 0.1647 \n",
      "Results at at the end of epoch 1\n",
      " sparse_categorical_accuracy = 0.9545 \n",
      " loss = 0.1646 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 1.0000 \n",
      " loss = 0.0140 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9688 \n",
      " loss = 0.0744 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9688 \n",
      " loss = 0.1215 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9688 \n",
      " loss = 0.1579 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1439 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9531 \n",
      " loss = 0.1527 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9420 \n",
      " loss = 0.2087 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9414 \n",
      " loss = 0.2230 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9444 \n",
      " loss = 0.2080 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9469 \n",
      " loss = 0.1945 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9517 \n",
      " loss = 0.1773 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9531 \n",
      " loss = 0.1770 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9567 \n",
      " loss = 0.1638 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9531 \n",
      " loss = 0.1709 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9563 \n",
      " loss = 0.1603 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9590 \n",
      " loss = 0.1506 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9596 \n",
      " loss = 0.1453 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9601 \n",
      " loss = 0.1429 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1358 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9641 \n",
      " loss = 0.1299 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9643 \n",
      " loss = 0.1270 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9659 \n",
      " loss = 0.1217 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9660 \n",
      " loss = 0.1230 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9635 \n",
      " loss = 0.1312 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9638 \n",
      " loss = 0.1303 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9651 \n",
      " loss = 0.1261 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9653 \n",
      " loss = 0.1255 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9654 \n",
      " loss = 0.1252 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9655 \n",
      " loss = 0.1226 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9646 \n",
      " loss = 0.1226 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9647 \n",
      " loss = 0.1205 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1250 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1281 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9614 \n",
      " loss = 0.1278 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9616 \n",
      " loss = 0.1263 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9618 \n",
      " loss = 0.1243 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9620 \n",
      " loss = 0.1236 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9605 \n",
      " loss = 0.1303 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9615 \n",
      " loss = 0.1282 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1258 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1259 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9635 \n",
      " loss = 0.1230 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9644 \n",
      " loss = 0.1212 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9645 \n",
      " loss = 0.1198 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9646 \n",
      " loss = 0.1190 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9654 \n",
      " loss = 0.1171 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9648 \n",
      " loss = 0.1246 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9648 \n",
      " loss = 0.1250 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9656 \n",
      " loss = 0.1230 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9644 \n",
      " loss = 0.1272 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9638 \n",
      " loss = 0.1267 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1301 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1285 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1324 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9614 \n",
      " loss = 0.1317 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9604 \n",
      " loss = 0.1337 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9611 \n",
      " loss = 0.1321 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9617 \n",
      " loss = 0.1314 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9613 \n",
      " loss = 0.1386 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9620 \n",
      " loss = 0.1363 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9611 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1375 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9603 \n",
      " loss = 0.1415 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9604 \n",
      " loss = 0.1407 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9596 \n",
      " loss = 0.1406 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9598 \n",
      " loss = 0.1390 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9599 \n",
      " loss = 0.1378 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9605 \n",
      " loss = 0.1361 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9606 \n",
      " loss = 0.1349 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9594 \n",
      " loss = 0.1361 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9591 \n",
      " loss = 0.1352 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9596 \n",
      " loss = 0.1342 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9593 \n",
      " loss = 0.1340 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9590 \n",
      " loss = 0.1343 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9592 \n",
      " loss = 0.1353 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9597 \n",
      " loss = 0.1336 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9598 \n",
      " loss = 0.1325 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9595 \n",
      " loss = 0.1326 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9597 \n",
      " loss = 0.1347 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9586 \n",
      " loss = 0.1395 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9583 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9573 \n",
      " loss = 0.1416 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9567 \n",
      " loss = 0.1477 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9561 \n",
      " loss = 0.1504 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9559 \n",
      " loss = 0.1513 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9564 \n",
      " loss = 0.1497 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9562 \n",
      " loss = 0.1492 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9563 \n",
      " loss = 0.1489 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9568 \n",
      " loss = 0.1481 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9566 \n",
      " loss = 0.1473 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9567 \n",
      " loss = 0.1466 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9569 \n",
      " loss = 0.1465 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9570 \n",
      " loss = 0.1463 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9574 \n",
      " loss = 0.1450 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9572 \n",
      " loss = 0.1464 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9577 \n",
      " loss = 0.1450 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9572 \n",
      " loss = 0.1465 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9573 \n",
      " loss = 0.1465 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9571 \n",
      " loss = 0.1464 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9572 \n",
      " loss = 0.1467 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9576 \n",
      " loss = 0.1453 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9577 \n",
      " loss = 0.1483 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9581 \n",
      " loss = 0.1469 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9582 \n",
      " loss = 0.1459 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9580 \n",
      " loss = 0.1460 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9581 \n",
      " loss = 0.1460 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9579 \n",
      " loss = 0.1459 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9575 \n",
      " loss = 0.1470 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9579 \n",
      " loss = 0.1457 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9580 \n",
      " loss = 0.1455 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9581 \n",
      " loss = 0.1463 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9584 \n",
      " loss = 0.1451 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9582 \n",
      " loss = 0.1446 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9586 \n",
      " loss = 0.1434 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9584 \n",
      " loss = 0.1468 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9585 \n",
      " loss = 0.1464 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9581 \n",
      " loss = 0.1463 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9579 \n",
      " loss = 0.1474 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9580 \n",
      " loss = 0.1473 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9581 \n",
      " loss = 0.1465 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9579 \n",
      " loss = 0.1471 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9582 \n",
      " loss = 0.1462 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9581 \n",
      " loss = 0.1463 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9584 \n",
      " loss = 0.1452 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9580 \n",
      " loss = 0.1483 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9581 \n",
      " loss = 0.1479 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9582 \n",
      " loss = 0.1479 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9580 \n",
      " loss = 0.1499 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9576 \n",
      " loss = 0.1514 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9575 \n",
      " loss = 0.1508 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9578 \n",
      " loss = 0.1498 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9576 \n",
      " loss = 0.1499 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9577 \n",
      " loss = 0.1492 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9576 \n",
      " loss = 0.1505 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9579 \n",
      " loss = 0.1496 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9575 \n",
      " loss = 0.1504 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9571 \n",
      " loss = 0.1520 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9570 \n",
      " loss = 0.1519 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9571 \n",
      " loss = 0.1515 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9574 \n",
      " loss = 0.1505 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9572 \n",
      " loss = 0.1501 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9571 \n",
      " loss = 0.1498 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9569 \n",
      " loss = 0.1494 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9564 \n",
      " loss = 0.1509 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9563 \n",
      " loss = 0.1509 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9561 \n",
      " loss = 0.1507 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9558 \n",
      " loss = 0.1512 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9561 \n",
      " loss = 0.1504 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9551 \n",
      " loss = 0.1531 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9548 \n",
      " loss = 0.1560 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9549 \n",
      " loss = 0.1554 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9552 \n",
      " loss = 0.1546 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9551 \n",
      " loss = 0.1543 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9552 \n",
      " loss = 0.1540 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9554 \n",
      " loss = 0.1532 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9555 \n",
      " loss = 0.1525 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9558 \n",
      " loss = 0.1518 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9561 \n",
      " loss = 0.1512 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9560 \n",
      " loss = 0.1511 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9559 \n",
      " loss = 0.1526 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9561 \n",
      " loss = 0.1518 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9558 \n",
      " loss = 0.1517 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9561 \n",
      " loss = 0.1511 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9560 \n",
      " loss = 0.1507 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9559 \n",
      " loss = 0.1514 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9561 \n",
      " loss = 0.1506 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9562 \n",
      " loss = 0.1501 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9561 \n",
      " loss = 0.1504 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9562 \n",
      " loss = 0.1501 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9561 \n",
      " loss = 0.1508 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9561 \n",
      " loss = 0.1502 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9562 \n",
      " loss = 0.1504 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9563 \n",
      " loss = 0.1499 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9565 \n",
      " loss = 0.1491 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9566 \n",
      " loss = 0.1486 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9565 \n",
      " loss = 0.1495 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9567 \n",
      " loss = 0.1487 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9568 \n",
      " loss = 0.1481 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9571 \n",
      " loss = 0.1477 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9569 \n",
      " loss = 0.1484 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9563 \n",
      " loss = 0.1493 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9566 \n",
      " loss = 0.1486 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9565 \n",
      " loss = 0.1494 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9564 \n",
      " loss = 0.1491 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9564 \n",
      " loss = 0.1486 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9565 \n",
      " loss = 0.1503 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9567 \n",
      " loss = 0.1496 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9566 \n",
      " loss = 0.1498 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9563 \n",
      " loss = 0.1508 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9566 \n",
      " loss = 0.1501 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9565 \n",
      " loss = 0.1503 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9565 \n",
      " loss = 0.1504 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9566 \n",
      " loss = 0.1499 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9567 \n",
      " loss = 0.1501 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9569 \n",
      " loss = 0.1494 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9571 \n",
      " loss = 0.1487 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9572 \n",
      " loss = 0.1482 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9572 \n",
      " loss = 0.1476 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9574 \n",
      " loss = 0.1469 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9575 \n",
      " loss = 0.1465 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9577 \n",
      " loss = 0.1458 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9576 \n",
      " loss = 0.1457 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9575 \n",
      " loss = 0.1456 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9577 \n",
      " loss = 0.1449 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9579 \n",
      " loss = 0.1444 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9578 \n",
      " loss = 0.1451 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9579 \n",
      " loss = 0.1451 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9576 \n",
      " loss = 0.1448 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9572 \n",
      " loss = 0.1460 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9573 \n",
      " loss = 0.1456 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9573 \n",
      " loss = 0.1454 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9570 \n",
      " loss = 0.1459 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9569 \n",
      " loss = 0.1457 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9571 \n",
      " loss = 0.1452 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9568 \n",
      " loss = 0.1460 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9569 \n",
      " loss = 0.1459 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9569 \n",
      " loss = 0.1457 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9570 \n",
      " loss = 0.1453 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9568 \n",
      " loss = 0.1458 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9567 \n",
      " loss = 0.1460 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9567 \n",
      " loss = 0.1459 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9566 \n",
      " loss = 0.1467 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9566 \n",
      " loss = 0.1476 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9568 \n",
      " loss = 0.1470 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9569 \n",
      " loss = 0.1466 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9567 \n",
      " loss = 0.1470 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9566 \n",
      " loss = 0.1467 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9567 \n",
      " loss = 0.1464 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9569 \n",
      " loss = 0.1459 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9571 \n",
      " loss = 0.1453 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9571 \n",
      " loss = 0.1449 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9569 \n",
      " loss = 0.1456 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9571 \n",
      " loss = 0.1450 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9570 \n",
      " loss = 0.1448 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9569 \n",
      " loss = 0.1448 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9568 \n",
      " loss = 0.1455 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9570 \n",
      " loss = 0.1449 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9569 \n",
      " loss = 0.1459 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9571 \n",
      " loss = 0.1453 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9573 \n",
      " loss = 0.1448 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9567 \n",
      " loss = 0.1452 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9564 \n",
      " loss = 0.1461 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9561 \n",
      " loss = 0.1465 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9562 \n",
      " loss = 0.1462 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9563 \n",
      " loss = 0.1469 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9563 \n",
      " loss = 0.1466 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9564 \n",
      " loss = 0.1468 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9563 \n",
      " loss = 0.1469 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9562 \n",
      " loss = 0.1468 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9561 \n",
      " loss = 0.1465 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9562 \n",
      " loss = 0.1474 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9562 \n",
      " loss = 0.1472 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9564 \n",
      " loss = 0.1467 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9563 \n",
      " loss = 0.1469 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9565 \n",
      " loss = 0.1464 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9564 \n",
      " loss = 0.1464 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9566 \n",
      " loss = 0.1459 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9568 \n",
      " loss = 0.1454 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9569 \n",
      " loss = 0.1449 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9570 \n",
      " loss = 0.1448 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9568 \n",
      " loss = 0.1465 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9569 \n",
      " loss = 0.1460 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9570 \n",
      " loss = 0.1461 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9570 \n",
      " loss = 0.1458 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9572 \n",
      " loss = 0.1453 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9572 \n",
      " loss = 0.1454 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9574 \n",
      " loss = 0.1449 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9576 \n",
      " loss = 0.1444 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9575 \n",
      " loss = 0.1453 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9575 \n",
      " loss = 0.1452 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9577 \n",
      " loss = 0.1447 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9578 \n",
      " loss = 0.1443 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9578 \n",
      " loss = 0.1443 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9578 \n",
      " loss = 0.1442 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9580 \n",
      " loss = 0.1437 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9579 \n",
      " loss = 0.1436 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9579 \n",
      " loss = 0.1434 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9581 \n",
      " loss = 0.1430 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9582 \n",
      " loss = 0.1425 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9584 \n",
      " loss = 0.1421 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9585 \n",
      " loss = 0.1416 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9587 \n",
      " loss = 0.1412 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9586 \n",
      " loss = 0.1425 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9587 \n",
      " loss = 0.1420 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9587 \n",
      " loss = 0.1427 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9587 \n",
      " loss = 0.1427 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9587 \n",
      " loss = 0.1425 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9589 \n",
      " loss = 0.1422 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9588 \n",
      " loss = 0.1431 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9587 \n",
      " loss = 0.1428 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9588 \n",
      " loss = 0.1426 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9587 \n",
      " loss = 0.1435 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9586 \n",
      " loss = 0.1438 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9585 \n",
      " loss = 0.1436 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9586 \n",
      " loss = 0.1433 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9587 \n",
      " loss = 0.1429 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9585 \n",
      " loss = 0.1439 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9586 \n",
      " loss = 0.1436 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9585 \n",
      " loss = 0.1435 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9585 \n",
      " loss = 0.1440 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9586 \n",
      " loss = 0.1437 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9586 \n",
      " loss = 0.1441 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9586 \n",
      " loss = 0.1437 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9588 \n",
      " loss = 0.1434 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9589 \n",
      " loss = 0.1429 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9589 \n",
      " loss = 0.1429 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9590 \n",
      " loss = 0.1427 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9589 \n",
      " loss = 0.1426 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9590 \n",
      " loss = 0.1422 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9590 \n",
      " loss = 0.1422 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9588 \n",
      " loss = 0.1428 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9589 \n",
      " loss = 0.1423 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9589 \n",
      " loss = 0.1423 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9588 \n",
      " loss = 0.1430 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9587 \n",
      " loss = 0.1432 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9589 \n",
      " loss = 0.1429 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9589 \n",
      " loss = 0.1427 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9586 \n",
      " loss = 0.1437 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9587 \n",
      " loss = 0.1435 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9587 \n",
      " loss = 0.1439 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9587 \n",
      " loss = 0.1437 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9589 \n",
      " loss = 0.1433 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9589 \n",
      " loss = 0.1429 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9589 \n",
      " loss = 0.1433 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9590 \n",
      " loss = 0.1429 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9590 \n",
      " loss = 0.1428 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9589 \n",
      " loss = 0.1427 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9589 \n",
      " loss = 0.1424 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9591 \n",
      " loss = 0.1420 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9591 \n",
      " loss = 0.1421 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9590 \n",
      " loss = 0.1424 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9590 \n",
      " loss = 0.1422 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9589 \n",
      " loss = 0.1424 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9587 \n",
      " loss = 0.1444 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9589 \n",
      " loss = 0.1440 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9588 \n",
      " loss = 0.1444 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9585 \n",
      " loss = 0.1453 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9583 \n",
      " loss = 0.1464 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9582 \n",
      " loss = 0.1466 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9583 \n",
      " loss = 0.1469 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9582 \n",
      " loss = 0.1471 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9582 \n",
      " loss = 0.1470 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9582 \n",
      " loss = 0.1471 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9580 \n",
      " loss = 0.1473 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9581 \n",
      " loss = 0.1472 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9580 \n",
      " loss = 0.1476 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9581 \n",
      " loss = 0.1472 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9581 \n",
      " loss = 0.1476 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9581 \n",
      " loss = 0.1478 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9582 \n",
      " loss = 0.1474 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9582 \n",
      " loss = 0.1475 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9583 \n",
      " loss = 0.1472 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9584 \n",
      " loss = 0.1468 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9584 \n",
      " loss = 0.1467 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9584 \n",
      " loss = 0.1470 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9584 \n",
      " loss = 0.1467 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9584 \n",
      " loss = 0.1466 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9584 \n",
      " loss = 0.1464 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9586 \n",
      " loss = 0.1461 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9587 \n",
      " loss = 0.1457 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9588 \n",
      " loss = 0.1453 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9588 \n",
      " loss = 0.1451 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9587 \n",
      " loss = 0.1468 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9587 \n",
      " loss = 0.1466 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9587 \n",
      " loss = 0.1463 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9588 \n",
      " loss = 0.1463 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9589 \n",
      " loss = 0.1460 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9590 \n",
      " loss = 0.1456 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9590 \n",
      " loss = 0.1454 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9590 \n",
      " loss = 0.1451 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9591 \n",
      " loss = 0.1448 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9590 \n",
      " loss = 0.1449 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9590 \n",
      " loss = 0.1446 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9591 \n",
      " loss = 0.1445 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9590 \n",
      " loss = 0.1446 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9591 \n",
      " loss = 0.1443 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9592 \n",
      " loss = 0.1439 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9593 \n",
      " loss = 0.1436 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9594 \n",
      " loss = 0.1434 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9592 \n",
      " loss = 0.1440 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9592 \n",
      " loss = 0.1438 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9591 \n",
      " loss = 0.1452 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9591 \n",
      " loss = 0.1449 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9591 \n",
      " loss = 0.1450 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9593 \n",
      " loss = 0.1447 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9593 \n",
      " loss = 0.1446 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9594 \n",
      " loss = 0.1442 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9595 \n",
      " loss = 0.1439 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9595 \n",
      " loss = 0.1437 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9596 \n",
      " loss = 0.1434 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9592 \n",
      " loss = 0.1449 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9591 \n",
      " loss = 0.1450 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9590 \n",
      " loss = 0.1465 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9589 \n",
      " loss = 0.1469 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9589 \n",
      " loss = 0.1472 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9590 \n",
      " loss = 0.1471 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9591 \n",
      " loss = 0.1467 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9591 \n",
      " loss = 0.1466 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9590 \n",
      " loss = 0.1466 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9590 \n",
      " loss = 0.1464 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9590 \n",
      " loss = 0.1462 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9591 \n",
      " loss = 0.1459 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9591 \n",
      " loss = 0.1460 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9591 \n",
      " loss = 0.1459 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9592 \n",
      " loss = 0.1455 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9593 \n",
      " loss = 0.1452 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9592 \n",
      " loss = 0.1457 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9593 \n",
      " loss = 0.1453 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9592 \n",
      " loss = 0.1452 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9591 \n",
      " loss = 0.1453 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9592 \n",
      " loss = 0.1449 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9593 \n",
      " loss = 0.1446 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9593 \n",
      " loss = 0.1449 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9594 \n",
      " loss = 0.1446 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9595 \n",
      " loss = 0.1443 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9596 \n",
      " loss = 0.1439 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9596 \n",
      " loss = 0.1437 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9596 \n",
      " loss = 0.1436 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9595 \n",
      " loss = 0.1438 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9596 \n",
      " loss = 0.1435 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9597 \n",
      " loss = 0.1432 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9596 \n",
      " loss = 0.1431 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9597 \n",
      " loss = 0.1428 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9598 \n",
      " loss = 0.1427 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9597 \n",
      " loss = 0.1431 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9597 \n",
      " loss = 0.1430 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9598 \n",
      " loss = 0.1427 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9598 \n",
      " loss = 0.1425 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9599 \n",
      " loss = 0.1424 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9598 \n",
      " loss = 0.1426 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9599 \n",
      " loss = 0.1424 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9600 \n",
      " loss = 0.1421 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9600 \n",
      " loss = 0.1421 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9601 \n",
      " loss = 0.1419 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9601 \n",
      " loss = 0.1419 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9602 \n",
      " loss = 0.1416 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9600 \n",
      " loss = 0.1430 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9601 \n",
      " loss = 0.1427 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9601 \n",
      " loss = 0.1425 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9602 \n",
      " loss = 0.1424 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9600 \n",
      " loss = 0.1426 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9601 \n",
      " loss = 0.1423 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9601 \n",
      " loss = 0.1421 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9601 \n",
      " loss = 0.1419 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9601 \n",
      " loss = 0.1418 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9602 \n",
      " loss = 0.1415 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9600 \n",
      " loss = 0.1422 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9600 \n",
      " loss = 0.1421 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9601 \n",
      " loss = 0.1419 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9601 \n",
      " loss = 0.1416 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9602 \n",
      " loss = 0.1415 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9602 \n",
      " loss = 0.1413 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9602 \n",
      " loss = 0.1411 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9601 \n",
      " loss = 0.1411 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9600 \n",
      " loss = 0.1413 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9600 \n",
      " loss = 0.1415 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9599 \n",
      " loss = 0.1417 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9599 \n",
      " loss = 0.1418 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9600 \n",
      " loss = 0.1420 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9600 \n",
      " loss = 0.1419 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9601 \n",
      " loss = 0.1416 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9601 \n",
      " loss = 0.1414 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9601 \n",
      " loss = 0.1421 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9601 \n",
      " loss = 0.1419 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9602 \n",
      " loss = 0.1417 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9603 \n",
      " loss = 0.1414 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9601 \n",
      " loss = 0.1418 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9602 \n",
      " loss = 0.1416 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9602 \n",
      " loss = 0.1414 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9603 \n",
      " loss = 0.1411 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9604 \n",
      " loss = 0.1408 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9603 \n",
      " loss = 0.1407 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9604 \n",
      " loss = 0.1406 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9604 \n",
      " loss = 0.1403 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9605 \n",
      " loss = 0.1402 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9604 \n",
      " loss = 0.1401 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9605 \n",
      " loss = 0.1399 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9606 \n",
      " loss = 0.1397 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9606 \n",
      " loss = 0.1395 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9607 \n",
      " loss = 0.1393 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9607 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9608 \n",
      " loss = 0.1396 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1393 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1394 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1391 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1402 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1402 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1403 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1402 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1407 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1405 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1403 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1402 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9608 \n",
      " loss = 0.1414 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9608 \n",
      " loss = 0.1414 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1412 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1411 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1408 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1408 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1408 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9608 \n",
      " loss = 0.1406 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9608 \n",
      " loss = 0.1404 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9608 \n",
      " loss = 0.1408 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9608 \n",
      " loss = 0.1407 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9608 \n",
      " loss = 0.1407 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9608 \n",
      " loss = 0.1411 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1409 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1406 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1403 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1406 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1403 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9608 \n",
      " loss = 0.1413 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9607 \n",
      " loss = 0.1417 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9608 \n",
      " loss = 0.1415 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9607 \n",
      " loss = 0.1417 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9607 \n",
      " loss = 0.1429 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9607 \n",
      " loss = 0.1429 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9607 \n",
      " loss = 0.1436 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9607 \n",
      " loss = 0.1433 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9606 \n",
      " loss = 0.1441 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9606 \n",
      " loss = 0.1440 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9607 \n",
      " loss = 0.1437 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9605 \n",
      " loss = 0.1442 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9604 \n",
      " loss = 0.1449 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9605 \n",
      " loss = 0.1446 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9606 \n",
      " loss = 0.1444 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9605 \n",
      " loss = 0.1448 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9605 \n",
      " loss = 0.1464 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9605 \n",
      " loss = 0.1462 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9606 \n",
      " loss = 0.1459 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9607 \n",
      " loss = 0.1457 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9607 \n",
      " loss = 0.1455 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9608 \n",
      " loss = 0.1452 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9608 \n",
      " loss = 0.1450 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1448 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1447 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9607 \n",
      " loss = 0.1460 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9607 \n",
      " loss = 0.1459 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9607 \n",
      " loss = 0.1458 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9606 \n",
      " loss = 0.1462 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9607 \n",
      " loss = 0.1460 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9608 \n",
      " loss = 0.1458 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9608 \n",
      " loss = 0.1457 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1454 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1453 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1452 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9608 \n",
      " loss = 0.1452 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9608 \n",
      " loss = 0.1454 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9608 \n",
      " loss = 0.1454 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9607 \n",
      " loss = 0.1453 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9608 \n",
      " loss = 0.1452 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9607 \n",
      " loss = 0.1453 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9607 \n",
      " loss = 0.1451 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9606 \n",
      " loss = 0.1456 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9606 \n",
      " loss = 0.1457 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9605 \n",
      " loss = 0.1456 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9605 \n",
      " loss = 0.1456 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9605 \n",
      " loss = 0.1457 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9606 \n",
      " loss = 0.1455 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9607 \n",
      " loss = 0.1453 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9607 \n",
      " loss = 0.1450 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9608 \n",
      " loss = 0.1448 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1446 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1444 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1442 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1440 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1443 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1442 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1440 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1438 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1436 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1436 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9611 \n",
      " loss = 0.1433 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9611 \n",
      " loss = 0.1434 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1439 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9608 \n",
      " loss = 0.1440 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1438 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1438 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1436 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1437 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1435 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1434 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1441 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1440 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9608 \n",
      " loss = 0.1446 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1445 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1443 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9608 \n",
      " loss = 0.1445 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1443 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1441 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1439 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1439 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1440 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1439 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1437 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1438 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1437 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1440 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1438 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1437 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1439 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1437 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1435 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1439 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1440 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1441 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1439 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9608 \n",
      " loss = 0.1445 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9608 \n",
      " loss = 0.1444 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1442 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1440 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1440 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1439 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1437 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1438 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1436 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1436 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1436 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1435 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1437 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9608 \n",
      " loss = 0.1436 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1437 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1435 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9608 \n",
      " loss = 0.1438 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9608 \n",
      " loss = 0.1437 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9608 \n",
      " loss = 0.1436 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9608 \n",
      " loss = 0.1437 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9608 \n",
      " loss = 0.1437 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1435 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9608 \n",
      " loss = 0.1435 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1433 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1431 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1431 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9609 \n",
      " loss = 0.1429 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1427 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1425 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1423 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9611 \n",
      " loss = 0.1422 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9611 \n",
      " loss = 0.1420 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1421 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1420 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1419 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1418 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1420 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1419 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9611 \n",
      " loss = 0.1419 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1420 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9611 \n",
      " loss = 0.1418 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9610 \n",
      " loss = 0.1419 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9611 \n",
      " loss = 0.1417 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1415 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1414 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9611 \n",
      " loss = 0.1413 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1413 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1411 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1411 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1410 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1410 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1409 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9611 \n",
      " loss = 0.1410 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9611 \n",
      " loss = 0.1416 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1414 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9611 \n",
      " loss = 0.1424 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9611 \n",
      " loss = 0.1422 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1420 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9611 \n",
      " loss = 0.1424 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1423 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9611 \n",
      " loss = 0.1427 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1425 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1423 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9613 \n",
      " loss = 0.1421 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9613 \n",
      " loss = 0.1420 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9613 \n",
      " loss = 0.1419 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9613 \n",
      " loss = 0.1419 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9613 \n",
      " loss = 0.1421 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9613 \n",
      " loss = 0.1421 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9613 \n",
      " loss = 0.1424 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9611 \n",
      " loss = 0.1431 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1435 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9611 \n",
      " loss = 0.1437 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9611 \n",
      " loss = 0.1436 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9611 \n",
      " loss = 0.1435 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1438 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1437 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1435 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9613 \n",
      " loss = 0.1433 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9613 \n",
      " loss = 0.1433 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9613 \n",
      " loss = 0.1433 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9611 \n",
      " loss = 0.1435 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9611 \n",
      " loss = 0.1435 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1433 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1432 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1432 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1430 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9613 \n",
      " loss = 0.1428 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9613 \n",
      " loss = 0.1429 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1431 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9613 \n",
      " loss = 0.1430 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1431 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1433 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9611 \n",
      " loss = 0.1434 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9611 \n",
      " loss = 0.1434 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9611 \n",
      " loss = 0.1434 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9611 \n",
      " loss = 0.1433 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9611 \n",
      " loss = 0.1432 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9611 \n",
      " loss = 0.1433 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9611 \n",
      " loss = 0.1431 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1430 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9611 \n",
      " loss = 0.1432 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9611 \n",
      " loss = 0.1430 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9611 \n",
      " loss = 0.1430 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9611 \n",
      " loss = 0.1439 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9611 \n",
      " loss = 0.1439 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9611 \n",
      " loss = 0.1438 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9611 \n",
      " loss = 0.1437 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1439 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9611 \n",
      " loss = 0.1440 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1438 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1436 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1434 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1437 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1435 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1434 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1433 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9613 \n",
      " loss = 0.1432 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9613 \n",
      " loss = 0.1430 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9613 \n",
      " loss = 0.1430 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9613 \n",
      " loss = 0.1429 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9613 \n",
      " loss = 0.1429 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9613 \n",
      " loss = 0.1428 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1432 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1431 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1429 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9613 \n",
      " loss = 0.1428 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9612 \n",
      " loss = 0.1428 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9613 \n",
      " loss = 0.1426 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9613 \n",
      " loss = 0.1425 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9613 \n",
      " loss = 0.1424 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9614 \n",
      " loss = 0.1422 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9614 \n",
      " loss = 0.1420 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9615 \n",
      " loss = 0.1421 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9615 \n",
      " loss = 0.1420 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9614 \n",
      " loss = 0.1423 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9615 \n",
      " loss = 0.1421 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9615 \n",
      " loss = 0.1420 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9616 \n",
      " loss = 0.1418 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9616 \n",
      " loss = 0.1417 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9617 \n",
      " loss = 0.1415 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9617 \n",
      " loss = 0.1413 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9618 \n",
      " loss = 0.1411 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9618 \n",
      " loss = 0.1413 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9618 \n",
      " loss = 0.1415 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9618 \n",
      " loss = 0.1414 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9619 \n",
      " loss = 0.1412 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9619 \n",
      " loss = 0.1410 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9619 \n",
      " loss = 0.1409 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9619 \n",
      " loss = 0.1409 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9620 \n",
      " loss = 0.1407 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9620 \n",
      " loss = 0.1406 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9620 \n",
      " loss = 0.1405 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9621 \n",
      " loss = 0.1403 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9621 \n",
      " loss = 0.1402 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9620 \n",
      " loss = 0.1407 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9620 \n",
      " loss = 0.1407 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9621 \n",
      " loss = 0.1405 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9621 \n",
      " loss = 0.1405 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9621 \n",
      " loss = 0.1404 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9621 \n",
      " loss = 0.1403 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9621 \n",
      " loss = 0.1404 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1402 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1405 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1407 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1407 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1407 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1405 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9621 \n",
      " loss = 0.1407 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9620 \n",
      " loss = 0.1409 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9620 \n",
      " loss = 0.1407 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9620 \n",
      " loss = 0.1409 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9619 \n",
      " loss = 0.1409 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9619 \n",
      " loss = 0.1409 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9620 \n",
      " loss = 0.1407 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9620 \n",
      " loss = 0.1408 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9620 \n",
      " loss = 0.1407 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9620 \n",
      " loss = 0.1406 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9620 \n",
      " loss = 0.1406 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9621 \n",
      " loss = 0.1404 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9621 \n",
      " loss = 0.1403 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9621 \n",
      " loss = 0.1406 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9621 \n",
      " loss = 0.1404 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1403 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1402 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1400 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1399 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1397 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1402 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1400 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1399 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1399 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1400 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1404 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1403 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1402 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1401 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1399 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1399 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1400 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1399 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1397 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1400 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1400 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1402 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1401 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1399 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1400 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1399 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1397 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1397 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1395 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1394 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1396 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1397 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1395 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1395 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1394 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1393 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1392 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1390 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1388 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1392 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1391 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1388 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1388 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1387 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1386 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1388 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1390 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1390 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1391 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1392 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1390 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1387 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1390 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1392 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1395 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1399 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1399 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1402 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1401 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1400 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1404 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1403 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1402 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1402 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9621 \n",
      " loss = 0.1403 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9621 \n",
      " loss = 0.1406 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1405 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1404 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9621 \n",
      " loss = 0.1411 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9621 \n",
      " loss = 0.1410 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1408 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1407 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1406 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1405 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1405 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1406 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1405 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1403 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1402 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1400 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1399 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1399 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1399 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1399 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1400 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1399 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1396 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1397 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1395 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1396 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1396 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1395 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1397 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1399 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1397 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1396 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1395 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1396 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1395 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1394 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1393 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1393 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1392 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1391 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1391 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1392 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1391 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1390 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1393 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1400 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1401 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1402 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9621 \n",
      " loss = 0.1402 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1401 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1401 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1399 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1399 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9621 \n",
      " loss = 0.1401 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1400 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1399 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9621 \n",
      " loss = 0.1400 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1399 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1399 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1399 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9622 \n",
      " loss = 0.1397 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1395 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1396 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1396 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1395 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1394 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1395 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1394 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1393 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1393 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1392 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1392 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1390 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1395 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1394 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1393 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1394 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1393 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1396 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1396 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1396 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1396 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1395 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1397 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1396 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1395 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1394 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1394 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1394 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1394 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1395 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1397 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1396 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1395 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1393 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1392 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1394 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1397 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1400 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1400 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1402 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1401 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1401 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1406 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1405 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1406 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1409 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1408 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1407 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1407 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1406 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1406 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1406 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1405 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1404 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1403 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1401 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1400 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1401 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1400 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1401 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1402 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1402 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1401 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1400 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1399 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1397 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1396 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1395 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1394 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1397 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1404 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1403 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1407 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1407 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1409 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1407 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1406 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1406 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1406 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1405 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1404 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1406 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1406 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1406 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1405 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1405 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1407 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1410 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1409 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1408 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1408 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1409 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1408 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1407 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1407 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1406 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1407 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1406 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1405 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1405 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1404 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1404 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1404 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1403 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1402 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1404 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1403 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1402 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1402 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1403 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1402 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1400 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1399 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1397 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1399 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1402 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1401 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1401 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1400 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1399 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1400 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1399 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1397 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1396 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1396 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1396 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1395 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1394 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1395 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1394 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1397 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1397 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1397 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1396 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1395 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1395 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1393 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1392 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9630 \n",
      " loss = 0.1391 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9630 \n",
      " loss = 0.1391 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9630 \n",
      " loss = 0.1390 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9630 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1392 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1391 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1390 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1388 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1388 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1387 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1388 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1388 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1388 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1388 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1387 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1386 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1386 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1385 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1386 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1386 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1385 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1384 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1384 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1385 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1386 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1386 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1386 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1385 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1384 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1383 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1388 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1387 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1390 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1390 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1388 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1387 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1388 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1388 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1387 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1387 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1386 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1388 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1392 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1391 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1392 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1393 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1393 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1392 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1391 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1390 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1388 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1387 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1386 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1385 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1387 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1387 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1387 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1387 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1386 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1385 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1384 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1383 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1382 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1382 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1382 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1381 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1381 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1381 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1380 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1379 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1386 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1386 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1385 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1386 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1385 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1386 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1386 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1385 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1387 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1386 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1385 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1386 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1387 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1386 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1388 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1388 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1387 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1386 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1387 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1390 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1390 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1388 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1387 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1386 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1385 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1384 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1383 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1383 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1382 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1383 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1382 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1381 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1380 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1380 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1382 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1381 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1380 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1380 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1381 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1381 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1380 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1379 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1378 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1377 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1377 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1376 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1375 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1377 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1381 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1380 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1383 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1383 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1382 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1381 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1383 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1382 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1384 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1383 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1382 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1383 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1382 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1380 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1380 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1379 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1378 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1382 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1384 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1386 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1386 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1386 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1388 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1387 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1388 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1387 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1386 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1385 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1388 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1395 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1394 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1393 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1393 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1392 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1391 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1391 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1390 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1388 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1390 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1392 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1396 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1397 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9623 \n",
      " loss = 0.1399 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1401 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1400 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1400 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1400 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1399 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1399 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1397 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1397 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1396 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1395 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1394 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1393 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1393 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1392 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1391 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1391 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1390 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1388 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1390 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1390 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1388 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1387 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1388 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1388 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1388 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1387 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1387 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1387 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1387 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1391 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1391 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1390 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1391 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1390 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1390 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1390 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1391 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1393 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1396 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1395 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1399 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1397 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1396 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1395 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1395 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1394 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1393 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1392 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1391 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1393 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1394 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1394 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1393 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1394 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1393 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1394 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1395 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1400 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1401 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1402 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1401 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1401 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1400 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1399 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1402 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1401 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1402 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1401 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1400 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1399 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1397 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1397 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1396 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1397 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1397 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1397 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9624 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1397 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1396 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1396 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1395 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1396 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1396 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1395 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1397 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1397 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1397 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1396 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1396 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1396 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1398 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1397 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1397 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1397 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1396 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1397 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1396 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1395 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1395 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1395 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1395 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1395 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1395 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1395 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1394 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9625 \n",
      " loss = 0.1393 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1393 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1392 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1392 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1391 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1392 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1392 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1392 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1392 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1392 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1391 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1391 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1391 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1390 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1390 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1390 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9626 \n",
      " loss = 0.1392 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1391 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1390 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1390 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1390 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1389 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1388 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9627 \n",
      " loss = 0.1388 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1387 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1386 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1385 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1386 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1385 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1386 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1385 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1385 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1385 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1384 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1384 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1385 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1384 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1383 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1383 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1382 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1382 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1382 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1385 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1385 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1384 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1383 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1383 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1384 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1383 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1383 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1386 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1385 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1384 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9628 \n",
      " loss = 0.1384 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1383 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1383 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1383 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1383 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1382 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1381 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1381 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1380 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1380 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1379 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1379 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9630 \n",
      " loss = 0.1379 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9630 \n",
      " loss = 0.1378 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9630 \n",
      " loss = 0.1377 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9630 \n",
      " loss = 0.1377 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9630 \n",
      " loss = 0.1377 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9630 \n",
      " loss = 0.1377 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9630 \n",
      " loss = 0.1376 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9631 \n",
      " loss = 0.1375 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9631 \n",
      " loss = 0.1374 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9631 \n",
      " loss = 0.1374 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9631 \n",
      " loss = 0.1373 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9630 \n",
      " loss = 0.1375 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9630 \n",
      " loss = 0.1374 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9631 \n",
      " loss = 0.1373 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9631 \n",
      " loss = 0.1372 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9631 \n",
      " loss = 0.1372 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9631 \n",
      " loss = 0.1372 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9631 \n",
      " loss = 0.1371 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9631 \n",
      " loss = 0.1372 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9631 \n",
      " loss = 0.1371 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9631 \n",
      " loss = 0.1370 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9630 \n",
      " loss = 0.1372 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9630 \n",
      " loss = 0.1374 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9630 \n",
      " loss = 0.1373 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9629 \n",
      " loss = 0.1374 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9630 \n",
      " loss = 0.1374 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9630 \n",
      " loss = 0.1373 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9630 \n",
      " loss = 0.1373 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9630 \n",
      " loss = 0.1372 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9630 \n",
      " loss = 0.1371 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9631 \n",
      " loss = 0.1370 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9631 \n",
      " loss = 0.1369 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9631 \n",
      " loss = 0.1369 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9631 \n",
      " loss = 0.1368 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9631 \n",
      " loss = 0.1368 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9631 \n",
      " loss = 0.1368 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9631 \n",
      " loss = 0.1367 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9631 \n",
      " loss = 0.1367 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9631 \n",
      " loss = 0.1366 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9631 \n",
      " loss = 0.1365 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9631 \n",
      " loss = 0.1364 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9631 \n",
      " loss = 0.1364 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9632 \n",
      " loss = 0.1363 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9632 \n",
      " loss = 0.1364 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9632 \n",
      " loss = 0.1363 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9632 \n",
      " loss = 0.1363 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9632 \n",
      " loss = 0.1362 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9632 \n",
      " loss = 0.1361 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9632 \n",
      " loss = 0.1361 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9633 \n",
      " loss = 0.1360 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9633 \n",
      " loss = 0.1360 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9633 \n",
      " loss = 0.1359 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9633 \n",
      " loss = 0.1358 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9633 \n",
      " loss = 0.1360 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9633 \n",
      " loss = 0.1359 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9633 \n",
      " loss = 0.1358 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9633 \n",
      " loss = 0.1357 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9634 \n",
      " loss = 0.1356 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9633 \n",
      " loss = 0.1357 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9633 \n",
      " loss = 0.1357 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9633 \n",
      " loss = 0.1359 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9633 \n",
      " loss = 0.1358 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9634 \n",
      " loss = 0.1357 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9634 \n",
      " loss = 0.1356 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9634 \n",
      " loss = 0.1355 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9634 \n",
      " loss = 0.1354 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9635 \n",
      " loss = 0.1354 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9635 \n",
      " loss = 0.1353 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9635 \n",
      " loss = 0.1352 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9635 \n",
      " loss = 0.1351 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9635 \n",
      " loss = 0.1350 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9636 \n",
      " loss = 0.1349 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9636 \n",
      " loss = 0.1349 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9636 \n",
      " loss = 0.1350 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9636 \n",
      " loss = 0.1350 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9636 \n",
      " loss = 0.1349 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9636 \n",
      " loss = 0.1350 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9636 \n",
      " loss = 0.1350 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9636 \n",
      " loss = 0.1349 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9636 \n",
      " loss = 0.1349 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9636 \n",
      " loss = 0.1348 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9636 \n",
      " loss = 0.1347 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9636 \n",
      " loss = 0.1346 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9637 \n",
      " loss = 0.1345 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9637 \n",
      " loss = 0.1345 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9637 \n",
      " loss = 0.1344 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9636 \n",
      " loss = 0.1351 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9636 \n",
      " loss = 0.1356 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9636 \n",
      " loss = 0.1356 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9636 \n",
      " loss = 0.1355 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9636 \n",
      " loss = 0.1354 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9636 \n",
      " loss = 0.1353 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9636 \n",
      " loss = 0.1357 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9636 \n",
      " loss = 0.1356 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9637 \n",
      " loss = 0.1355 \n",
      "Results at at the end of epoch 2\n",
      " sparse_categorical_accuracy = 0.9637 \n",
      " loss = 0.1354 \n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    reset_metrics()\n",
    "    for inputs_batch,targets_batch in training_dataset:\n",
    "        \n",
    "        logs = train_step(inputs= inputs_batch,targets= targets_batch)\n",
    "\n",
    "        print(\"Results at at the end of epoch {}\".format(epoch))\n",
    "        for key,value in logs.items():\n",
    "            print(\" {} = {:.4f} \".format(key,value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here’s the evaluation loop: a simple for loop that repeatedly calls a __test_step()__\n",
    "function, which processes a single batch of data. \n",
    "\n",
    "The __test_step()__ function is just a subset of the logic of __train_step()__.  Let __training=False__\n",
    "\n",
    "It omits the code that deals with updating the weights of the model—that is to say, everything involving the GradientTape and the optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing 7.24 Writing a step-by-step evaluation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(inputs,targets):\n",
    "    predictions = model(inputs,training=False)\n",
    "    \n",
    "    loss = loss_fn(targets,predictions)\n",
    "\n",
    "    logs = {}\n",
    "\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets,predictions)\n",
    "        logs[\"val_\"+metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datasets= tf.data.Dataset.from_tensor_slices((val_images,val_labels))\n",
    "val_datasets = val_datasets.batch(32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results\n",
      "val_sparse_categorical_accuracy :0.9661\n",
      "val_loss :0.1321\n"
     ]
    }
   ],
   "source": [
    "reset_metrics()\n",
    "for inputs_batch,output_batch in val_datasets:\n",
    "    logs = test_step(inputs=inputs_batch,targets=output_batch)\n",
    "print(\"Evaluation Results\")\n",
    "for key ,value in logs.items():\n",
    "     print(\"{} :{:.4f}\".format(key,value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats—you’ve just reimplemented fit() and evaluate()! Or almost: fit()\n",
    "and evaluate() support many more features, including large-scale distributed computation, which requires a bit more work. It also includes several key performance\n",
    "optimizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.4 Make it fast with tf.function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that your custom loops are running significantly slower than the\n",
    "built-in fit() and evaluate(), despite implementing essentially the same logic.\n",
    "\n",
    "\n",
    "That’s because, by default, TensorFlow code is __executed line by line__, eagerly, much like\n",
    "NumPy code or regular Python code. Eager execution makes it easier to debug your\n",
    "code, but it is far from optimal from a performance standpoint.\n",
    "\n",
    "\n",
    "It’s more performant to __compile__ your TensorFlow code into a computation graph that\n",
    "can be globally optimized in a way that code interpreted line by line cannot. \n",
    "\n",
    "\n",
    "The syntax to do this is very simple: just __add a @tf.function__ to any function you want to compile before executing, as shown in the following listing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing 7.25 Adding a @tf.function decorator to our evaluation-step function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results\n",
      "val_sparse_categorical_accuracy :0.9661\n",
      "val_loss :0.1321\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "\n",
    "def test_step(inputs,targets):\n",
    "    predictions = model(inputs,training=False)\n",
    "    \n",
    "    loss = loss_fn(targets,predictions)\n",
    "\n",
    "    logs = {}\n",
    "\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets,predictions)\n",
    "        logs[\"val_\"+metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "\n",
    "    return logs\n",
    "\n",
    "val_datasets= tf.data.Dataset.from_tensor_slices((val_images,val_labels))\n",
    "val_datasets = val_datasets.batch(32)\n",
    "\n",
    "reset_metrics()\n",
    "for inputs_batch,output_batch in val_datasets:\n",
    "    logs = test_step(inputs=inputs_batch,targets=output_batch)\n",
    "print(\"Evaluation Results\")\n",
    "for key ,value in logs.items():\n",
    "     print(\"{} :{:.4f}\".format(key,value))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It goes from taking 1.9s to run the evaluation loop to only 0.8s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, while you are debugging your code, prefer running it eagerly, without\n",
    "any @tf.function decorator. \n",
    " \n",
    "It’s easier to track bugs this way. Once your code is working and you want to make it fast, add a __@tf.function__ decorator to your training step\n",
    "and your evaluation step—or any other performance-critical function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.5 Leveraging fit() with a custom training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if you need a custom training algorithm, but you still want to leverage the\n",
    "power of the built-in Keras training logic? \n",
    "\n",
    "There’s actually a middle ground between\n",
    "fit() and a training loop written from scratch: you can provide a custom training\n",
    "step function and let the framework do the rest.\n",
    "\n",
    "\n",
    "You can do this by overriding the __train_step()__ method of the Model class. This is\n",
    "the function that is called by __fit()__ for every batch of data. You will then be able to call\n",
    "__fit()__ as usual, and it will be running your own learning algorithm under the hood.\n",
    " Here’s a simple example:\n",
    "\n",
    "1.  We create a new class that subclasses __keras.Model__. \n",
    "\n",
    "\n",
    "\n",
    "2. We override the method train_step(self, data). Its contents are nearly identical to what we used in the previous section. It returns a dictionary mapping\n",
    "metric names (including the loss) to their current values.\n",
    "\n",
    "\n",
    "3.  We implement a metrics property that tracks the model’s Metric instances.\n",
    "This enables the model to automatically call __reset_state()__ on the model’s\n",
    "metrics at the start of each epoch and at the start of a call to __evaluate()__, so you\n",
    "don’t have to do it by hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing 7.26 Implementing a custom training step to use with fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "loss_tracker = keras.metrics.Mean(name='loss')\n",
    "\n",
    "\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def train_step(self,data):\n",
    "        inputs,targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            ## We use self(inputs, training=True) instead of model(inputs, training=True), since our model is the class itself.\n",
    "            predictions = self(inputs,training = True)\n",
    "            loss = loss_fn(targets, predictions)\n",
    "        gradients = tape.gradient(loss,model.trainable_weights)\n",
    "\n",
    "        ## Here we still lack of optimizer, which should be set in model.compile()\n",
    "        optimizer.apply_gradients(zip(gradients,model.trainable_weights))\n",
    "\n",
    "        loss_tracker.update_state(loss)\n",
    "        return{\"loss\":loss_tracker.result()}\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return[loss_tracker]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The __CustomModel()__ class indeed does the same job as the __model.complie()__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 0.2962\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1641\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1376\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25a2bedda00>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "model.compile(optimizer=keras.optimizers.RMSprop())\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check if the @property works ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.1375791>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics[0].result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple of points to note:\n",
    "\n",
    "\n",
    "+  This pattern does not prevent you from building models with the Functional\n",
    " API. You can do this whether you’re building Sequential models, Functional\n",
    " API models, or subclassed models.\n",
    "\n",
    "\n",
    "+ You don’t need to use a @tf.function decorator when you override train_\n",
    " step—the framework does it for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what about metrics, and what about configuring the loss via compile()?\n",
    "\n",
    " After  you’ve called compile(), you get access to the following:\n",
    "\n",
    "1. __self.compiled_loss__—The loss function you passed to compile().  \n",
    "\n",
    "2. __self.compiled_metrics__—A wrapper for the list of metrics you passed, which\n",
    " allows you to call self.compiled_metrics.update_state() to update all o \n",
    " your metrics at once.\n",
    "\n",
    "3. __self.metrics__—The actual list of metrics you passed to compile(). Note that it\n",
    " also includes a metric that tracks the loss, similar to what we did manually with\n",
    " our loss_tracking_metric earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self,data):\n",
    "        inputs,targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs,training = True)\n",
    "            loss = self.compiled_loss(targets,predictions)\n",
    "            \n",
    "        gradents = tape.gradient(loss,model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(gradents,model.trainable_weights))\n",
    "\n",
    "        ## Update model metrics via self.compiled_metrics\n",
    "        self.compiled_metrics.update_state(targets,predictions)\n",
    "\n",
    "        return { m.name:m.result() for m in self.metrics }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.2944 - sparse_categorical_accuracy: 0.9114\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1643 - sparse_categorical_accuracy: 0.9537\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1405 - sparse_categorical_accuracy: 0.9625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25a2c373340>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "            loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "            metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "    \n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.14047495>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics[0].result()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Keras offers a spectrum of different workflows, based on the principle of progressive disclosure of complexity. They all smoothly inter-operate together.\n",
    "\n",
    "2. You can build models via the Sequential class, via the Functional API, or by subclassing the Model class. Most of the time, you’ll be using the Functional API.\n",
    "\n",
    "3. The simplest way to train and evaluate a model is via the default fit() and\n",
    "evaluate() methods.\n",
    "\n",
    "4. Keras callbacks provide a simple way to monitor models during your call to\n",
    "fit() and automatically take action based on the state of the model.\n",
    "\n",
    "5. You can also fully take control of what fit() does by overriding the train_\n",
    "step() method.\n",
    "\n",
    "6. Beyond fit(), you can also write your own training loops entirely from scratch.\n",
    "This is useful for researchers implementing brand-new training algorithms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.11 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e450050b432e843bda3c41bf3272c133bfc370a7003f3e377e27f87a49ce1127"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
